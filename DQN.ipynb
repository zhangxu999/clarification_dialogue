{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef7c063d-6406-4004-b32e-4d4d831fab90",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import copy\n",
    "from imp import reload\n",
    "import rl_dqn\n",
    "import environment\n",
    "import embedding\n",
    "\n",
    "from rl_dqn import ReplayMemory, DQN, Transition\n",
    "from embedding import EmbeddingModel\n",
    "from environment import OriginAgent, DialougeEnv\n",
    "from transformers import pipeline\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c1217f6-26b9-4b28-8e10-bf0c02300975",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(rl_dqn)\n",
    "reload(environment)\n",
    "reload(embedding)\n",
    "\n",
    "from rl_dqn import ReplayMemory, DQN, Transition\n",
    "from embedding import EmbeddingModel\n",
    "from environment import OriginAgent, DialougeEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e511cb9d-3fd5-4817-82d3-353da3219056",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embedding_model = EmbeddingModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4f7109-db06-4ad1-9e5f-dee20b1f1480",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "unmasker = pipeline('fill-mask', model='xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5c6abf06-e40a-4af9-9075-eb6e1b921b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'embedding' from '/home/xu_zhang01/Thesis/RL/embedding.py'>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(rl_dqn)\n",
    "reload(environment)\n",
    "reload(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb2dac6b-c76a-4dcf-8f83-92c444153299",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "reload(environment)\n",
    "test_agent = environment.OriginAgent('../data/swords/swords-v1.1_dev.json.gz')\n",
    "train_agent = environment.OriginAgent('../data/swords/swords-v1.1_test.json.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e3c9f1-c56a-4544-9d3b-60d1c6e11238",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "daa641eb-938f-4cf1-87d5-08322c3083dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLModel:\n",
    "    \n",
    "    def __init__(self,env,device):\n",
    "        self.BATCH_SIZE = 128\n",
    "        self.TAU = 0.005\n",
    "        self.LR = 1e-4\n",
    "        self.GAMMA = 0.99\n",
    "        # Get number of actions from gym action space\n",
    "        n_actions = env.action_space.n\n",
    "        # Get the number of state observations\n",
    "        state, info = env.reset()\n",
    "        n_observations = len(state)\n",
    "\n",
    "        self.policy_net = rl_dqn.DQN(n_observations, n_actions).to(device)\n",
    "        self.target_net = rl_dqn.DQN(n_observations, n_actions).to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.optimizer = optim.AdamW(self.policy_net.parameters(), lr=self.LR, amsgrad=True)\n",
    "        self.memory = ReplayMemory(10000)\n",
    "        self.env = env\n",
    "        self.device = device\n",
    "        self.steps_done = 0\n",
    "        \n",
    "    def caculate_threshold(self):\n",
    "        EPS_START = 0.9\n",
    "        EPS_END = 0.05\n",
    "        EPS_DECAY = 10000\n",
    "\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "                        math.exp(-1. * self.steps_done / EPS_DECAY)\n",
    "        return eps_threshold\n",
    "        \n",
    "        \n",
    "    def select_action(self, state,eps_threshold=None):\n",
    "        # global steps_done\n",
    "        sample = random.random()\n",
    "        eps_threshold = self.caculate_threshold() if  eps_threshold is None else 0\n",
    "        if sample >= eps_threshold:\n",
    "            with torch.no_grad():\n",
    "                # t.max(1) will return the largest column value of each row.\n",
    "                # second column on max result is index of where max element was\n",
    "                # found, so we pick action with the larger expected reward.\n",
    "                return self.policy_net(state).max(1)[1].view(1, 1), eps_threshold\n",
    "        else:\n",
    "            return torch.tensor([[self.env.action_space.sample()]], device=device, dtype=torch.long), eps_threshold\n",
    "\n",
    "\n",
    "    def optimize_model(self):\n",
    "        if len(self.memory) < self.BATCH_SIZE:\n",
    "            return\n",
    "        transitions = self.memory.sample(self.BATCH_SIZE)\n",
    "        # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "        # detailed explanation). This converts batch-array of Transitions\n",
    "        # to Transition of batch-arrays.\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        # Compute a mask of non-final states and concatenate the batch elements\n",
    "        # (a final state would've been the one after which simulation ended)\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                              batch.next_state)), device=self.device, dtype=torch.bool)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                    if s is not None])\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "        # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "        # columns of actions taken. These are the actions which would've been taken\n",
    "        # for each batch state according to policy_net\n",
    "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # Compute V(s_{t+1}) for all next states.\n",
    "        # Expected values of actions for non_final_next_states are computed based\n",
    "        # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "        # This is merged based on the mask, such that we'll have either the expected\n",
    "        # state value or 0 in case the state was final.\n",
    "        next_state_values = torch.zeros(self.BATCH_SIZE, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            next_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1)[0]\n",
    "        # Compute the expected Q values\n",
    "        expected_state_action_values = (next_state_values * self.GAMMA) + reward_batch\n",
    "\n",
    "        # Compute Huber loss\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # In-place gradient clipping\n",
    "        torch.nn.utils.clip_grad_value_(self.policy_net.parameters(), 100)\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def train(self, num_episodes=3000,start_episodes=0):\n",
    "        \n",
    "        return_list = []\n",
    "        episodes_list = []\n",
    "        \n",
    "        for i_episode in tqdm.tqdm(range(start_episodes,start_episodes+num_episodes),desc='RL Training'):\n",
    "            # Initialize the environment and get it's state\n",
    "            returns = 0\n",
    "            state, info = self.env.reset()\n",
    "            state = torch.tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
    "            \n",
    "            for t in count():\n",
    "                action, eps_threshold = self.select_action(state)\n",
    "                writer.add_scalar('eps_threshold', eps_threshold, self.steps_done)\n",
    "                self.steps_done += 1\n",
    "\n",
    "                observation, reward, terminated, truncated, _ = self.env.step(action.item())\n",
    "                reward = torch.tensor([reward], device=device)\n",
    "                returns += reward\n",
    "                done = terminated or truncated\n",
    "                if terminated:\n",
    "                    next_state = None\n",
    "                else:\n",
    "                    next_state = torch.tensor(observation, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
    "                # Store the transition in memory\n",
    "                self.memory.push(state, action, next_state, reward)\n",
    "                # Move to the next state\n",
    "                state = next_state\n",
    "                # Perform one step of the optimization (on the policy network)\n",
    "                self.optimize_model()\n",
    "                # Soft update of the target network's weights\n",
    "                # θ′ ← τ θ + (1 −τ )θ′\n",
    "                target_net_state_dict = self.target_net.state_dict()\n",
    "                policy_net_state_dict = self.policy_net.state_dict()\n",
    "                for key in policy_net_state_dict:\n",
    "                    target_net_state_dict[key] = policy_net_state_dict[key]*self.TAU + target_net_state_dict[key]*(1-self.TAU)\n",
    "                #self.target_net.load_state_dict(target_net_state_dict)\n",
    "                if done:\n",
    "                    return_list.append(returns)\n",
    "                    episodes_list.append(copy.copy(self.env.history))\n",
    "                    # plot_durations()\n",
    "                    break\n",
    "            \n",
    "            writer.add_scalar('train/returns_episode', returns, i_episode)\n",
    "            if i_episode%500==0:\n",
    "                test_episodes_list, Rewards, accurate_match_rate, loose_match_rate = self.evaluate(test_env,eva_tag='eva test:')\n",
    "                writer.add_scalar('test/Rewards_all', Rewards, self.steps_done)\n",
    "                writer.add_scalar('test/accurate_match_rate', accurate_match_rate, i_episode)\n",
    "                writer.add_scalar('test/loose_match_rate', loose_match_rate, i_episode)\n",
    "                train_episodes_list, Rewards, accurate_match_rate, loose_match_rate = self.evaluate(train_env,eva_tag='eva train:')\n",
    "                writer.add_scalar('train/Rewards_all', Rewards, self.steps_done)\n",
    "                writer.add_scalar('train/accurate_match_rate', accurate_match_rate, i_episode)\n",
    "                writer.add_scalar('train/loose_match_rate', loose_match_rate, i_episode)\n",
    "        return test_episodes_list, train_episodes_list\n",
    "    \n",
    "    def evaluate(self,eva_env,size=None,eva_tag=''):\n",
    "        Rewards = 0\n",
    "        episodes_list = []\n",
    "        if size is None:\n",
    "            size = len(eva_env.OA.context_ids)\n",
    "        for context_id in tqdm.tqdm(eva_env.OA.context_ids[:size],desc=eva_tag,mininterval=3):\n",
    "            state, info = eva_env.reset(context_id)\n",
    "            state = torch.tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
    "            for t in count():\n",
    "                action, _ = self.select_action(state,eps_threshold=0)\n",
    "                observation, reward, terminated, truncated, _ = eva_env.step(action.item())\n",
    "                done = terminated or truncated\n",
    "                if terminated:\n",
    "                    next_state = None\n",
    "                else:\n",
    "                    next_state = torch.tensor(observation, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
    "                # Move to the next state\n",
    "                state = next_state\n",
    "                Rewards += reward\n",
    "                if done:\n",
    "                    episodes_list.append(copy.copy(eva_env.history))\n",
    "                    # plot_durations()\n",
    "                    break\n",
    "        \n",
    "        accurate_match = []\n",
    "        loose_match = []\n",
    "        \n",
    "        for eps in episodes_list:\n",
    "            for i,utter in enumerate(eps):\n",
    "                if 'is_right_action' in utter:\n",
    "                    accurate_match.append(utter['is_right_action'])\n",
    "                    loose_match.append(eps[i-1]['action'] in utter['loose_right_actions'])\n",
    "        accurate_match_rate = np.array(accurate_match).sum() / len(accurate_match)\n",
    "        loose_match_rate = np.array(loose_match).sum() / len(loose_match)\n",
    "        print(Rewards, accurate_match_rate, loose_match_rate)\n",
    "        return episodes_list, Rewards, accurate_match_rate, loose_match_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9408ba39-944d-4533-bc3d-678b0962fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(environment)\n",
    "test_agent = environment.OriginAgent('../data/swords/swords-v1.1_dev.json.gz')\n",
    "train_agent = environment.OriginAgent('../data/swords/swords-v1.1_test.json.gz')\n",
    "\n",
    "test_env = environment.DialougeEnv(test_agent,embedding_model,unmasker)\n",
    "train_env = environment.DialougeEnv(train_agent,embedding_model,unmasker)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2412ee54-7a6d-424e-bcc9-7f80e9b55700",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('rl_log_lemma_words_5num')\n",
    "rl_model = RLModel(train_env,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e7b0db2f-e762-414c-ba50-875fde12d53f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:   0%|                                                                     | 0/3000 [00:00<?, ?it/s]\n",
      "eva test::   0%|                                                                        | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "eva test::  30%|██████████████████▊                                           | 112/370 [00:03<00:07, 35.34it/s]\u001b[A\n",
      "eva test::  59%|████████████████████████████████████▋                         | 219/370 [00:06<00:04, 31.15it/s]\u001b[A\n",
      "eva test:: 100%|██████████████████████████████████████████████████████████████| 370/370 [00:11<00:00, 32.86it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1481.4999999999743 0.06827794561933535 0.8368580060422961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "eva train::   0%|                                                                       | 0/762 [00:00<?, ?it/s]\u001b[A\n",
      "eva train::  20%|████████████▏                                                | 153/762 [00:03<00:12, 50.71it/s]\u001b[A\n",
      "eva train::  40%|████████████████████████▍                                    | 306/762 [00:07<00:11, 38.11it/s]\u001b[A\n",
      "eva train::  56%|██████████████████████████████████                           | 426/762 [00:10<00:08, 38.24it/s]\u001b[A\n",
      "eva train::  71%|███████████████████████████████████████████▌                 | 544/762 [00:14<00:06, 36.06it/s]\u001b[A\n",
      "eva train:: 100%|█████████████████████████████████████████████████████████████| 762/762 [00:19<00:00, 39.95it/s]\u001b[A\n",
      "RL Training:   0%|                                                           | 5/3000 [00:30<3:50:25,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3031.699999999815 0.0691786870768325 0.8110097144539299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  17%|█████████▊                                                 | 499/3000 [01:31<05:37,  7.41it/s]\n",
      "eva test:: 100%|████████████████████████████████████████████████████████████| 370/370 [00:00<00:00, 4346.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352.9999999999995 0.6108108108108108 0.6108108108108108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "eva train:: 100%|████████████████████████████████████████████████████████████| 762/762 [00:01<00:00, 435.14it/s]\u001b[A\n",
      "RL Training:  17%|█████████▉                                                 | 504/3000 [01:33<09:57,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624.7999999999922 0.583989501312336 0.583989501312336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  33%|███████████████████▋                                       | 999/3000 [02:16<03:50,  8.68it/s]\n",
      "eva test:: 100%|████████████████████████████████████████████████████████████| 370/370 [00:00<00:00, 4379.35it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352.9999999999995 0.6108108108108108 0.6108108108108108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "eva train:: 100%|███████████████████████████████████████████████████████████| 762/762 [00:00<00:00, 4420.64it/s]\u001b[A\n",
      "RL Training:  33%|███████████████████▎                                      | 1001/3000 [02:17<04:52,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624.7999999999922 0.583989501312336 0.583989501312336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  50%|████████████████████████████▉                             | 1498/3000 [03:08<02:38,  9.46it/s]\n",
      "eva test:: 100%|████████████████████████████████████████████████████████████| 370/370 [00:00<00:00, 4176.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352.9999999999995 0.6108108108108108 0.6108108108108108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "eva train:: 100%|███████████████████████████████████████████████████████████| 762/762 [00:00<00:00, 4823.81it/s]\u001b[A\n",
      "RL Training:  50%|█████████████████████████████                             | 1501/3000 [03:08<02:32,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624.7999999999922 0.583989501312336 0.583989501312336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  67%|██████████████████████████████████████▋                   | 1999/3000 [03:46<01:01, 16.21it/s]\n",
      "eva test::   0%|                                                                        | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "eva test:: 100%|██████████████████████████████████████████████████████████████| 370/370 [00:04<00:00, 83.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382.9999999999987 0.6128205128205129 0.6512820512820513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "eva train:: 100%|████████████████████████████████████████████████████████████| 762/762 [00:01<00:00, 493.53it/s]\u001b[A\n",
      "RL Training:  67%|██████████████████████████████████████▋                   | 2001/3000 [03:52<11:08,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646.1999999999917 0.5885416666666666 0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  83%|████████████████████████████████████████████████▏         | 2494/3000 [04:26<00:35, 14.42it/s]\n",
      "eva test::   0%|                                                                        | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "eva test::  23%|██████████████▎                                                | 84/370 [00:03<00:10, 26.73it/s]\u001b[A\n",
      "eva test::  45%|███████████████████████████▋                                  | 165/370 [00:06<00:08, 24.24it/s]\u001b[A\n",
      "eva test::  68%|██████████████████████████████████████████▏                   | 252/370 [00:09<00:04, 25.91it/s]\u001b[A\n",
      "eva test:: 100%|██████████████████████████████████████████████████████████████| 370/370 [00:16<00:00, 23.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371.7999999999984 0.5727069351230425 0.6868008948545862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "RL Training:  83%|████████████████████████████████████████████████▏         | 2494/3000 [04:44<00:35, 14.42it/s]\u001b[A\n",
      "eva train::  23%|██████████████                                               | 176/762 [00:03<00:12, 47.12it/s]\u001b[A\n",
      "eva train::  42%|█████████████████████████▍                                   | 318/762 [00:07<00:10, 43.55it/s]\u001b[A\n",
      "eva train::  59%|███████████████████████████████████▉                         | 449/762 [00:10<00:07, 42.09it/s]\u001b[A\n",
      "eva train:: 100%|█████████████████████████████████████████████████████████████| 762/762 [00:16<00:00, 47.18it/s]\u001b[A\n",
      "RL Training:  83%|████████████████████████████████████████████████▎         | 2501/3000 [04:58<18:16,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703.3999999999899 0.5922897196261683 0.655373831775701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training: 100%|██████████████████████████████████████████████████████████| 3000/3000 [05:33<00:00,  9.01it/s]\n"
     ]
    }
   ],
   "source": [
    "test_episodes_list, train_episodes_list = rl_model.train(3000,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da7bf9d9-f6be-4f4d-80af-6303c002e52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7fc0c53d-40e2-4ada-b27d-696f02058383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'He began with small animals\\n                    and moved on to derelicts and Undersiders, people who would never be missed. Now\\n                    he had thought to use vacationers like Tasha and me, and when someone came\\n                    looking, he would say we had gone island-hopping in our windboat. Our boat would\\n                    disappear into the ocean to be found or not as the wind and tides chose.',\n",
       "  'target': 'came',\n",
       "  'lemma_target': 'came',\n",
       "  'substitutes': [('arrive', 0.7),\n",
       "   ('appear', 0.6),\n",
       "   ('begin', 0.4),\n",
       "   ('approach', 0.3),\n",
       "   ('enter', 0.3)],\n",
       "  'lemma_subs': [('arrive', 0.7),\n",
       "   ('appear', 0.6),\n",
       "   ('begin', 0.4),\n",
       "   ('approach', 0.3),\n",
       "   ('enter', 0.3)],\n",
       "  'offset': 219,\n",
       "  'role': 'user',\n",
       "  'option_words': [('exit', 0.39),\n",
       "   ('enter', 0.167),\n",
       "   ('leave', 0.043),\n",
       "   ('end', 0.03),\n",
       "   ('go', 0.021),\n",
       "   ('escape', 0.017),\n",
       "   ('close', 0.016),\n",
       "   ('continue', 0.012),\n",
       "   ('stay', 0.011),\n",
       "   ('stop', 0.01)],\n",
       "  'mask_text': 'He began with small animals\\n                    and moved on to derelicts and Undersiders, people who would never be missed.came\\n                    looking,  arrive\\n                    looking,  appear\\n                    looking,  begin\\n                    looking,  approach\\n                    looking,  enter\\n                    looking,  <mask>\\n                    looking, Our boat would\\n                    disappear into the ocean to be found or not as the wind and tides chose.'}]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,info = train_env.reset()\n",
    "train_env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d86b026-3a4d-4125-9453-2023613a99bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 370/370 [01:39<00:00,  3.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-149.99999999999855, 0.2938775510204082, 0.3489795918367347)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_list, Rewards, accurate_match_rate, loose_match_rate = rl_model.evaluate(env)\n",
    "Rewards, accurate_match_rate, loose_match_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af5830fe-bc38-4a77-abf2-ac896924d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c19cee1-e050-4d62-a044-81f24589ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    for i in tqdm.tqdm(range(100),desc='get nothing',mininterval=3):\n",
    "        i +1\n",
    "        time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7b8098db-03cc-474a-a213-41a707987a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>', '.', '..', '?', 's', \"''\", '!”', '.”', '”', 'nos', 'mr', 've']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_words = '''</s>\n",
    ".\n",
    "..\n",
    "?\n",
    "s\n",
    "''\n",
    "!”\n",
    ".”\n",
    "”\n",
    "nos\n",
    "mr\n",
    "ve\n",
    "'''.split()\n",
    "filter_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8acae861-99fb-4476-bfb8-db9edc2ff361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['said', 'explained', 'reveal', 'announced', 'say']        ['state', 'report', 'declare', 'reveal', 'announce', 'disclose', 'claim', 'note']\n",
      "['crawl', 'slide', 'move', 'climb', 'jump']        ['wriggle', 'slide', 'crawl', 'scoot', 'move', 'glide', 'slip', 'coast']\n",
      "['reasonable', 'sensible', 'rational', 'clear', 'coherent']        ['rational', 'justifiable', 'sensible', 'reasonable', 'clear', 'relevant', 'plausible', 'legit']\n",
      "['producer', 'director', 'manager', 'critic', 'actor']        ['maker', 'producer', 'supervisor', 'controller', 'exec', 'executive', 'key player', 'overseer']\n",
      "['buy', 'get', 'pay', 'find', 'give']        ['secure', 'attain', 'gain', 'procure', 'obtain', 'acquire', 'get hands on', 'be given']\n",
      "['strong', 'powerful', 'big', 'huge', 'certain']        ['big', 'sturdy', 'certain', 'well-established', 'powerful', 'secure', 'firm', 'substantial']\n",
      "['happened', 'happen', 'occur', 'come', 'happens']        ['happen', 'occur', 'come about', 'transpire', 'materialize', 'occure', 'come to pass', 'become of']\n",
      "['society', 'country', 'culture', 'community', 'world']        ['social order', 'culture', 'nation', 'community', 'general public', 'population', 'civilization', 'world']\n",
      "['said', 'declare', 'explained', 'says', 'say']        ['assert', 'remark', 'declare', 'tell', 'mention', 'claim', 'reveal', 'comment']\n",
      "['propose', 'suggest', 'recommend', 'present', 'recommended']        ['suggest', 'advocate', 'present', 'make a proposal', 'recommend', 'proposition', 'put forward', 'make a pitch']\n",
      "['complaint', 'charge', 'investigation', 'charges', 'report']        ['objection', 'allegation', 'charge', 'grievance', 'criticism', 'statement of disagreement', 'protest', 'accusation']\n",
      "['look', 'looked', 'stare', 'gaze', 'smile']        ['gaze', 'glance', 'peer', 'stare', 'eye', 'watch', 'glare', 'gawk']\n",
      "['here', 'this', 'there', 'to', 'in']        ['in this place', 'to this place', 'on this spot', 'hereabouts', 'at this place', 'in this spot', 'around', 'in this direction']\n",
      "['allowed', 'allow', 'permit', 'admit', 'accept']        ['allow', 'authorize', 'give access', 'admit', 'accept', 'let', 'grant', 'let pass']\n",
      "['method', 'way', 'means', 'mode', 'manner']        ['means', 'mode', 'process', 'manner', 'course', 'method', 'form', 'path']\n",
      "['gem', 'rock', 'earth', 'gold', 'seal']        ['pebble', 'rock', 'gem', 'ore', 'hard piece of earths surface', 'mineral', 'gravel', 'stonework']\n",
      "['pub', 'restaurant', 'bar', 'cafe', 'pool']        ['drinking area', 'bartender station', 'pub', 'cocktail lounge', 'barroom', 'beer garden', 'lounge', 'obstacle']\n",
      "['shake', 'move', 'lift', 'roll', 'stroke']        ['jerk', 'flap', 'flitter', 'wave', 'move', 'make waves', 'flutter', 'jolt']\n",
      "['extremely', 'truly', 'incredibly', 'very', 'really']        ['incredibly', 'really', 'extremely', 'highly', 'truly', 'extraordinarily', 'greatly', 'exceedingly']\n",
      "['finish', 'conclude', 'start', 'continue', 'begin']        ['begin', 'initiate', 'go ahead', 'get under way', 'commence', 'set out', 'get going', 'take first step']\n",
      "['food', 'fat', 'fish', 'gluten', 'chicken']        ['red meat', 'flesh of animal consumed as food', 'flesh', 'grub', 'chow', 'subsistence', 'brawn', 'ration']\n",
      "['cook', 'chef', 'cooking', 'producer', 'Chef']        ['gourmet chef', 'culinary artist', 'cook', 'sous chef', 'cuisinier', 'hash slinger', 'cook chief cook and bottle', 'washer']\n",
      "['knows', 'know', 'can', 'say', 'see']        ['can tell', 'can say', 'be sure', 'identify', 'can perceive', 'fathom', 'comprehend', 'be learned']\n",
      "['all', 'al', 'just', 'not', 'good']        ['ok', 'fine', 'alright', 'all right', 'good', 'adequate', 'tolerable', 'satisfactory']\n",
      "['range', 'area', 'size', 'distance', 'scale']        ['proportions', 'area', 'range', 'scope', 'expanse', 'extent', 'magnitude', 'dimensions']\n",
      "['vegetables', 'dressing', 'soup', 'rice', 'chicken']        ['tossed salad', 'dish of vegetables', 'greens', 'mixed greens', 'toss salad', 'mix', 'fruit salad', 'medley']\n",
      "['properly', 'fully', 'effectively', 'clearly', 'seriously']        ['sufficiently', 'satisfactorily', 'thoroughly', 'appropriately', 'properly', 'acceptably', 'completely', 'suitably']\n",
      "['said', 'declare', 'explained', 'says', 'say']        ['assert', 'remark', 'declare', 'tell', 'mention', 'claim', 'reveal', 'comment']\n",
      "['sometimes', 'odd', 'often', 'regular', 'unusual']        ['sometimes', 'infrequent', 'unfrequent', 'sporadic', 'off and on', 'rare', 'intermittent', 'uncommon']\n",
      "['buy', 'get', 'pay', 'find', 'give']        ['secure', 'attain', 'gain', 'procure', 'obtain', 'acquire', 'get hands on', 'be given']\n",
      "['know', 'learn', 'understand', 'comprehend', 'hear']        ['have knowledge of', 'hear', 'learn', 'understand', 'comprehend', 'get the idea', 'be learned', 'be cognizant']\n",
      "['hair', 'head', 'face', 'skull', 'skin']        ['scalp', 'skull', 'hair', 'dome', 'noggin', 'cranium', 'top story', 'forefront']\n",
      "['dead', 'flat', 'empty', 'death', 'cold']        ['dead', 'deathly', 'listless', 'empty', 'flat', 'dull', 'cold', 'spiritless']\n",
      "['idiot', 'stupid', 'racist', 'mean', 'fool']        ['imbecile', 'moron', 'nincompoop', 'simpleton', 'numskull', 'fool', 'blockhead', 'twit']\n",
      "['lecture', 'taught', 'teach', 'teaching', 'learned']        ['instruct', 'lecture on', 'lecture', 'instruct in', 'be a professor of', 'teach', 'tutor', 'give instruction']\n",
      "['said', 'stop', 'call', 'say', 'all']        ['exclaim', 'yell', 'holler', 'scream', 'call out', 'bellow', 'cry out loudly', 'call']\n",
      "['record', 'monitor', 'keep', 'kept', 'check']        ['track', 'under surveillance', 'check', 'observe', 'keep track of', 'record', 'listen to', 'supervise']\n",
      "['turn', 'move', 'turned', 'lean', 'walk']        ['rotate', 'swivel', 'move', 'spin', 'pivot', 'veer', 'swerve', 'shift']\n",
      "['area', 'region', 'section', 'sector', 'district']        ['sector', 'district', 'area', 'region', 'section', 'range', 'strip', 'ground']\n",
      "['few', 'couple', 'some', 'several', 'par']        ['matter of', 'couple', 'not many', 'some', 'scarcely any', 'not too many', 'little', 'hardly any']\n",
      "['dark', 'black', 'white', 'light', 'brown']        ['pitchblack', 'shady', 'gloomy', 'shadowy', 'lightless', 'darkened', 'blackish', 'black']\n"
     ]
    }
   ],
   "source": [
    "for context_id in test_env.OA.context_ids[:50]:\n",
    "    context_id = random.choice(test_env.OA.context_ids)\n",
    "    option_words,prompt_sentence = test_env.get_option_words_by_llm(context_id=context_id,use_cache=True)\n",
    "    state,info = test_env.reset(context_id)\n",
    "    subs = test_env.history[0]['substitutes']\n",
    "    words = [s for s,score in option_words]\n",
    "    if not set(words) & set(filter_words):\n",
    "        print(words,'      ',[s for s,score in subs[:8]])\n",
    "# print('--------------------------------------------------------------------------')\n",
    "# print(subs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cfb825-7394-43fe-a4ea-1ca59ead436c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7ed3c125-355c-4f79-984f-9c305ef8708d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3038056790828705,\n",
       "  'token': 43334,\n",
       "  'token_str': 'dark',\n",
       "  'sequence': 'Her candy lips twisted into a frown.The dark glow grew stronger and larger, filling the air for about a foot around her hands..The pitchblack glow grew stronger and larger, filling the air for about a foot around her hands..The shady glow grew stronger and larger, filling the air for about a foot around her hands..The gloomy glow grew stronger and larger, filling the air for about a foot around her hands..The shadowy glow grew stronger and larger, filling the air for about a foot around her hands..The lightless glow grew stronger and larger, filling the air for about a foot around her hands..The dark glow grew stronger and larger, filling the air for about a foot around her hands.In her palms, the droplets of blood swelled into small pools.'},\n",
       " {'score': 0.08765923231840134,\n",
       "  'token': 22556,\n",
       "  'token_str': 'black',\n",
       "  'sequence': 'Her candy lips twisted into a frown.The dark glow grew stronger and larger, filling the air for about a foot around her hands..The pitchblack glow grew stronger and larger, filling the air for about a foot around her hands..The shady glow grew stronger and larger, filling the air for about a foot around her hands..The gloomy glow grew stronger and larger, filling the air for about a foot around her hands..The shadowy glow grew stronger and larger, filling the air for about a foot around her hands..The lightless glow grew stronger and larger, filling the air for about a foot around her hands..The black glow grew stronger and larger, filling the air for about a foot around her hands.In her palms, the droplets of blood swelled into small pools.'},\n",
       " {'score': 0.07216016948223114,\n",
       "  'token': 35011,\n",
       "  'token_str': 'white',\n",
       "  'sequence': 'Her candy lips twisted into a frown.The dark glow grew stronger and larger, filling the air for about a foot around her hands..The pitchblack glow grew stronger and larger, filling the air for about a foot around her hands..The shady glow grew stronger and larger, filling the air for about a foot around her hands..The gloomy glow grew stronger and larger, filling the air for about a foot around her hands..The shadowy glow grew stronger and larger, filling the air for about a foot around her hands..The lightless glow grew stronger and larger, filling the air for about a foot around her hands..The white glow grew stronger and larger, filling the air for about a foot around her hands.In her palms, the droplets of blood swelled into small pools.'},\n",
       " {'score': 0.047033682465553284,\n",
       "  'token': 22729,\n",
       "  'token_str': 'light',\n",
       "  'sequence': 'Her candy lips twisted into a frown.The dark glow grew stronger and larger, filling the air for about a foot around her hands..The pitchblack glow grew stronger and larger, filling the air for about a foot around her hands..The shady glow grew stronger and larger, filling the air for about a foot around her hands..The gloomy glow grew stronger and larger, filling the air for about a foot around her hands..The shadowy glow grew stronger and larger, filling the air for about a foot around her hands..The lightless glow grew stronger and larger, filling the air for about a foot around her hands..The light glow grew stronger and larger, filling the air for about a foot around her hands.In her palms, the droplets of blood swelled into small pools.'},\n",
       " {'score': 0.04364930838346481,\n",
       "  'token': 119455,\n",
       "  'token_str': 'brown',\n",
       "  'sequence': 'Her candy lips twisted into a frown.The dark glow grew stronger and larger, filling the air for about a foot around her hands..The pitchblack glow grew stronger and larger, filling the air for about a foot around her hands..The shady glow grew stronger and larger, filling the air for about a foot around her hands..The gloomy glow grew stronger and larger, filling the air for about a foot around her hands..The shadowy glow grew stronger and larger, filling the air for about a foot around her hands..The lightless glow grew stronger and larger, filling the air for about a foot around her hands..The brown glow grew stronger and larger, filling the air for about a foot around her hands.In her palms, the droplets of blood swelled into small pools.'},\n",
       " {'score': 0.043574780225753784,\n",
       "  'token': 77233,\n",
       "  'token_str': 'pink',\n",
       "  'sequence': 'Her candy lips twisted into a frown.The dark glow grew stronger and larger, filling the air for about a foot around her hands..The pitchblack glow grew stronger and larger, filling the air for about a foot around her hands..The shady glow grew stronger and larger, filling the air for about a foot around her hands..The gloomy glow grew stronger and larger, filling the air for about a foot around her hands..The shadowy glow grew stronger and larger, filling the air for about a foot around her hands..The lightless glow grew stronger and larger, filling the air for about a foot around her hands..The pink glow grew stronger and larger, filling the air for about a foot around her hands.In her palms, the droplets of blood swelled into small pools.'},\n",
       " {'score': 0.04334995895624161,\n",
       "  'token': 4842,\n",
       "  'token_str': 'red',\n",
       "  'sequence': 'Her candy lips twisted into a frown.The dark glow grew stronger and larger, filling the air for about a foot around her hands..The pitchblack glow grew stronger and larger, filling the air for about a foot around her hands..The shady glow grew stronger and larger, filling the air for about a foot around her hands..The gloomy glow grew stronger and larger, filling the air for about a foot around her hands..The shadowy glow grew stronger and larger, filling the air for about a foot around her hands..The lightless glow grew stronger and larger, filling the air for about a foot around her hands..The red glow grew stronger and larger, filling the air for about a foot around her hands.In her palms, the droplets of blood swelled into small pools.'},\n",
       " {'score': 0.03704666718840599,\n",
       "  'token': 57571,\n",
       "  'token_str': 'blue',\n",
       "  'sequence': 'Her candy lips twisted into a frown.The dark glow grew stronger and larger, filling the air for about a foot around her hands..The pitchblack glow grew stronger and larger, filling the air for about a foot around her hands..The shady glow grew stronger and larger, filling the air for about a foot around her hands..The gloomy glow grew stronger and larger, filling the air for about a foot around her hands..The shadowy glow grew stronger and larger, filling the air for about a foot around her hands..The lightless glow grew stronger and larger, filling the air for about a foot around her hands..The blue glow grew stronger and larger, filling the air for about a foot around her hands.In her palms, the droplets of blood swelled into small pools.'},\n",
       " {'score': 0.025981303304433823,\n",
       "  'token': 124498,\n",
       "  'token_str': 'bright',\n",
       "  'sequence': 'Her candy lips twisted into a frown.The dark glow grew stronger and larger, filling the air for about a foot around her hands..The pitchblack glow grew stronger and larger, filling the air for about a foot around her hands..The shady glow grew stronger and larger, filling the air for about a foot around her hands..The gloomy glow grew stronger and larger, filling the air for about a foot around her hands..The shadowy glow grew stronger and larger, filling the air for about a foot around her hands..The lightless glow grew stronger and larger, filling the air for about a foot around her hands..The bright glow grew stronger and larger, filling the air for about a foot around her hands.In her palms, the droplets of blood swelled into small pools.'},\n",
       " {'score': 0.0246555358171463,\n",
       "  'token': 50997,\n",
       "  'token_str': 'green',\n",
       "  'sequence': 'Her candy lips twisted into a frown.The dark glow grew stronger and larger, filling the air for about a foot around her hands..The pitchblack glow grew stronger and larger, filling the air for about a foot around her hands..The shady glow grew stronger and larger, filling the air for about a foot around her hands..The gloomy glow grew stronger and larger, filling the air for about a foot around her hands..The shadowy glow grew stronger and larger, filling the air for about a foot around her hands..The lightless glow grew stronger and larger, filling the air for about a foot around her hands..The green glow grew stronger and larger, filling the air for about a foot around her hands.In her palms, the droplets of blood swelled into small pools.'}]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(prompt_sentence,top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ac566c99-38e7-4db0-bb81-0e7d05fa3655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/xu_zhang01/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "809809bf-9b4c-4e45-9153-686f57353dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat were chasing mouse\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sentence = \"The cats were chasing mice\"\n",
    "words = sentence.split()\n",
    "\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "lemmatized_sentence = \" \".join(lemmatized_words)\n",
    "\n",
    "print(lemmatized_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63323b-ba5b-4686-8082-61045ef2107b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c0c638d1-8fcd-4d34-b45f-e7c2aaafaec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "# import these modules\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "\n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e4fae8d4-aeef-45aa-a853-9f77f16703db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/xu_zhang01/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0b00047d-30b6-4a2f-912c-e94eb8381a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pull', 0.4),\n",
       " ('bring', 0.4),\n",
       " ('have', 0.3),\n",
       " ('secure', 0.3),\n",
       " ('draw', 0.3),\n",
       " ('capture', 0.3),\n",
       " ('hustle', 0.3),\n",
       " ('acquire', 0.3),\n",
       " ('win', 0.3),\n",
       " ('defeat', 0.3)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,info = test_env.reset(context_id)\n",
    "test_env.history[0]['substitutes'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05420967-0b10-4c39-846b-a63a97918798",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_action    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a64e3e75-f23f-4d8d-b399-0a5873bdc892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 580 0.3017241379310345\n"
     ]
    }
   ],
   "source": [
    "right_action_match = []\n",
    "for eps in eval_episode_list:\n",
    "    for i,utter in enumerate(eps):\n",
    "        if 'right_action' in utter:\n",
    "            right_action_match.append(utter['right_action'][0] == eps[i-1]['action'])\n",
    "cnt_right = np.array(right_action_match).sum()\n",
    "len_right = len(right_action_match)\n",
    "print(cnt_right,len_right,cnt_right/len_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3dac1bf4-af82-4c27-a1ed-d0f48df4558a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_episode_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_episode_list\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_episode_list' is not defined"
     ]
    }
   ],
   "source": [
    "eval_episode_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c3aa5-6657-4612-96c9-0c9a8c0e01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_action_matcht3_episodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a7b9f-d734-4bcf-a8e5-9ad2741b53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[eval_episode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0799c04b-0383-40f1-8911-dde225b30668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "53c5bb96-3ffd-425a-9510-c9799ae6bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9177eecc-a409-4435-994c-739dd6f00c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role            : user\n",
      "text            : “I …I noticed him from across the room when I was looking around for Rachel. He was standing right in front of some blue lights, so I couldn’t see him very well, but I noticed the way that the light set off his pale skin. It almost looked like the light bent around him without actually touching him directly.\n",
      "target          : very\n",
      "option_words    : [('very', 0.275), ('really', 0.258), ('quite', 0.196), ('particularly', 0.135), ('extremely', 0.047), ('rather', 0.023), ('incredibly', 0.007), ('fairly', 0.007), ('especially', 0.006), ('truly', 0.004)]\n",
      "---------------------------------------------------\n",
      "                               role : bot\n",
      "                               text : The word very is not clear to me. Do you mean something like very,really,quite,particularly,extremely,rather,incredibly,fairly,especially,truly ?\n",
      "                       option_words : [('very', 0.275), ('really', 0.258), ('quite', 0.196), ('particularly', 0.135), ('extremely', 0.047), ('rather', 0.023), ('incredibly', 0.007), ('fairly', 0.007), ('especially', 0.006), ('truly', 0.004)]\n",
      "                             action : 2\n",
      "---------------------------------------------------\n",
      "role            : user\n",
      "text            : none of these\n",
      "reward          : -1\n",
      "is_right_action : False\n",
      "loose_right_actions : [0 2]\n",
      "---------------------------------------------------\n",
      "                               role : bot\n",
      "                               text : \n",
      "                       option_words : [('very', 0.275), ('really', 0.258), ('quite', 0.196), ('particularly', 0.135), ('extremely', 0.047), ('rather', 0.023), ('incredibly', 0.007), ('fairly', 0.007), ('especially', 0.006), ('truly', 0.004)]\n",
      "                             action : 0\n",
      "---------------------------------------------------\n",
      "role            : user\n",
      "text            : \n",
      "reward          : 2\n",
      "is_right_action : True\n",
      "loose_right_actions : [0 2]\n",
      "---------------------------------------------------\n",
      "total reward:   1\n"
     ]
    }
   ],
   "source": [
    "keys = ['role','text','target','option_words','reward','is_right_action','action','loose_right_actions']\n",
    "t3_episodes_list = [epi for epi in test_episodes_list if len(epi)>3]\n",
    "\n",
    "episode = random.choice(t3_episodes_list)\n",
    "reward_all = 0\n",
    "for utter in episode:\n",
    "    role = utter['role']\n",
    "    for k in keys:\n",
    "        if k in utter:\n",
    "            if k=='reward':\n",
    "                reward_all += utter[k]\n",
    "            if role=='user':\n",
    "                print(k.ljust(15,' '),':',utter[k])\n",
    "            else:\n",
    "                print(k.rjust(35,' '),':',utter[k])\n",
    "    print(\"---------------------------------------------------\")\n",
    "print(\"total reward:  \", reward_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "45d52fd7-b087-4d31-afa9-0d118d425c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t3_episodes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "c4a3325f-6438-4e87-99ba-f22ff22bb5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"FAMILY PETS are improving recovery rates of patients at Columbia Hospital, Milwaukee. Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more receptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\nTIRED OF TRIMMING?\",\n",
       "  'target': 'receptive',\n",
       "  'substitutes': [('acceptant', 0.7),\n",
       "   ('welcoming', 0.7),\n",
       "   ('approachable', 0.6),\n",
       "   ('acceptive', 0.5),\n",
       "   ('open', 0.5),\n",
       "   ('responsive', 0.4),\n",
       "   ('open to suggestions', 0.3),\n",
       "   ('favorable', 0.3),\n",
       "   ('open-minded', 0.3),\n",
       "   ('open to new ideas', 0.3),\n",
       "   ('persuadable', 0.2),\n",
       "   ('suggestible', 0.2),\n",
       "   ('hospitable', 0.2),\n",
       "   ('influenceable', 0.1),\n",
       "   ('accessible', 0.1),\n",
       "   ('friendly', 0.1),\n",
       "   ('amenable', 0.1),\n",
       "   ('ready', 0.1),\n",
       "   ('quick on the uptake', 0.0),\n",
       "   ('sympathetic', 0.0),\n",
       "   ('sensitive', 0.0),\n",
       "   ('bright', 0.0),\n",
       "   ('perceptive', 0.0),\n",
       "   ('susceptible', 0.0),\n",
       "   ('swayable', 0.0),\n",
       "   ('pushover', 0.0),\n",
       "   ('well-disposed', 0.0),\n",
       "   ('alert', 0.0),\n",
       "   ('observant', 0.0),\n",
       "   ('interested', 0.0),\n",
       "   ('recipient', 0.0)],\n",
       "  'offset': 206,\n",
       "  'role': 'user',\n",
       "  'option_words': [('open', 0.991),\n",
       "   ('willing', 0.002),\n",
       "   ('responsive', 0.001),\n",
       "   ('comfortable', 0.0),\n",
       "   ('tolerant', 0.0)],\n",
       "  'mask_text': \"FAMILY PETS are improving recovery rates of patients at Columbia Hospital, Milwaukee.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more receptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more acceptant to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more welcoming to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more approachable to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more acceptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more open to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more <mask> to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\nTIRED OF TRIMMING?\"},\n",
       " {'text': '',\n",
       "  'option_words': [('open', 0.991),\n",
       "   ('willing', 0.002),\n",
       "   ('responsive', 0.001),\n",
       "   ('comfortable', 0.0),\n",
       "   ('tolerant', 0.0)],\n",
       "  'action': 0,\n",
       "  'role': 'bot'},\n",
       " {'text': ' you misunderstdood my words, I mean...',\n",
       "  'reward': -2,\n",
       "  'is_right_action': False,\n",
       "  'right_action': array([1, 2]),\n",
       "  'role': 'user',\n",
       "  'history_text': \"FAMILY PETS are improving recovery rates of patients at Columbia Hospital, Milwaukee. Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more receptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\nTIRED OF TRIMMING?</s></s> you misunderstdood my words, I mean...\"}]"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "85e65f4e-480d-4a1a-b6dc-6a8e7e72e3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'receptive'"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "31eaf8ed-5991-47cb-b70f-0118302dd594",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'episodes_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_567/4106245537.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'substitutes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'episodes_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(episodes_list[0][0]['target'])\n",
    "\n",
    "print(episodes_list[0][0]['substitutes'][:5])\n",
    "print(\"--------------------\")\n",
    "print(episodes_list[0][0]['mask_text'])\n",
    "\n",
    "print(episodes_list[0][0]['option_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "c58b5670-a4db-47ab-8063-ecd650f2618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.fill_mask.FillMaskPipeline at 0x7f067b69b760>"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.mask_model.encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "b4750d23-6a6f-472f-8953-df9959a01c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3854154944419861,\n",
       "  'token': 3714,\n",
       "  'token_str': 'know',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever know. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.15135060250759125,\n",
       "  'token': 51529,\n",
       "  'token_str': 'known',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever known. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.14298954606056213,\n",
       "  'token': 55950,\n",
       "  'token_str': 'knew',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever knew. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.025355149060487747,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.02500970847904682,\n",
       "  'token': 51592,\n",
       "  'token_str': 'seen',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever seen. At six foot two, she stood a full head taller than even her Arrallin first officer.'}]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.mask_model('''It was not an attractive face right now; her ebony\n",
    "eyes shadowed by hours on the watch, full lips pursed with frustration. She had\n",
    "the look of every leader she had ever known. She had\n",
    "the look of every leader she had ever be acquaint with. She had\n",
    "the look of every leader she had ever know. She had \n",
    "the look of every leader she had ever be acquainted with. She had\n",
    "the look of every leader she had ever have knowledge of. She had\n",
    "the look of every leader she had ever experience. She had\n",
    "the look of every leader she had ever <mask>. At six foot two, she stood a full\n",
    "head taller than even her Arrallin first officer.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "4568a300-74e4-4cde-acea-9512ac6eeacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2613705098628998,\n",
       "  'token': 3714,\n",
       "  'token_str': 'know',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever know.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.1795056164264679,\n",
       "  'token': 51529,\n",
       "  'token_str': 'known',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever known.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.1245126873254776,\n",
       "  'token': 55950,\n",
       "  'token_str': 'knew',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever knew.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.07769811153411865,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.03395156189799309,\n",
       "  'token': 1902,\n",
       "  'token_str': 'had',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever had.At six foot two, she stood a full head taller than even her Arrallin first officer.'}]"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.mask_model(episodes_list[0][0]['mask_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed81a2-a16d-454e-b25f-50c42aeb24f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\n'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eac9303b-1f4d-4631-89ef-e4514f6932d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argwhere([True,False,True,False]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0c61d6b-352a-4e76-bf74-0b1b24c0f6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.',\n",
       "  'target': 'think',\n",
       "  'substitutes': [('have in mind', 0.9),\n",
       "   ('suppose', 0.8),\n",
       "   ('presume', 0.6),\n",
       "   ('reckon', 0.6),\n",
       "   ('conclude', 0.5),\n",
       "   ('speculate', 0.5),\n",
       "   ('suspect', 0.5),\n",
       "   ('feel', 0.4),\n",
       "   ('imagine', 0.4),\n",
       "   ('suggest', 0.4),\n",
       "   ('believe', 0.4),\n",
       "   ('anticipate', 0.3),\n",
       "   ('reflect', 0.3),\n",
       "   ('surmise', 0.3),\n",
       "   ('gather', 0.3),\n",
       "   ('understand', 0.3),\n",
       "   ('foresee', 0.3),\n",
       "   ('deem', 0.3),\n",
       "   ('determine', 0.2),\n",
       "   ('expect', 0.2),\n",
       "   ('fancy', 0.2),\n",
       "   ('ponder', 0.2),\n",
       "   ('consider', 0.2),\n",
       "   ('reason', 0.2),\n",
       "   ('see', 0.2),\n",
       "   ('stop to consider', 0.2),\n",
       "   ('guess', 0.2),\n",
       "   ('intellectualize', 0.2),\n",
       "   ('envision', 0.2),\n",
       "   ('want', 0.2),\n",
       "   ('use ones head', 0.2),\n",
       "   ('estimate', 0.1),\n",
       "   ('appraise', 0.1),\n",
       "   ('sort out', 0.1),\n",
       "   ('contemplate', 0.1),\n",
       "   ('assume', 0.1),\n",
       "   ('discern', 0.1),\n",
       "   ('conceive', 0.1),\n",
       "   ('stew', 0.1),\n",
       "   ('project', 0.1),\n",
       "   ('sense', 0.1),\n",
       "   ('resolve', 0.0),\n",
       "   ('regard', 0.0),\n",
       "   ('realize', 0.0),\n",
       "   ('reminisce', 0.0),\n",
       "   ('study', 0.0),\n",
       "   ('hold', 0.0),\n",
       "   ('weigh', 0.0),\n",
       "   ('meditate', 0.0),\n",
       "   ('take', 0.0),\n",
       "   ('image', 0.0),\n",
       "   ('recall', 0.0),\n",
       "   ('visualize', 0.0),\n",
       "   ('deduce', 0.0),\n",
       "   ('comprehend', 0.0),\n",
       "   ('take under consideration', 0.0),\n",
       "   ('appreciate', 0.0),\n",
       "   ('analyze', 0.0),\n",
       "   ('muse', 0.0),\n",
       "   ('vision', 0.0),\n",
       "   ('rationalize', 0.0),\n",
       "   ('be convinced', 0.0),\n",
       "   ('judge', 0.0),\n",
       "   ('evaluate', 0.0),\n",
       "   ('plan for', 0.0),\n",
       "   ('ideate', 0.0),\n",
       "   ('examine', 0.0),\n",
       "   ('esteem', 0.0),\n",
       "   ('figure out', 0.0),\n",
       "   ('revolve', 0.0),\n",
       "   ('ruminate', 0.0),\n",
       "   ('deliberate', 0.0),\n",
       "   ('turn over', 0.0),\n",
       "   ('credit', 0.0),\n",
       "   ('envisage', 0.0),\n",
       "   ('mull over', 0.0),\n",
       "   ('brood', 0.0),\n",
       "   ('cogitate', 0.0),\n",
       "   ('infer', 0.0),\n",
       "   ('feature', 0.0),\n",
       "   ('logicalize', 0.0),\n",
       "   ('mull', 0.0),\n",
       "   ('factor', 0.0),\n",
       "   ('recollect', 0.0),\n",
       "   ('cerebrate', 0.0),\n",
       "   ('rack ones brains', 0.0),\n",
       "   ('remember call to', 0.0),\n",
       "   ('mind', 0.0)],\n",
       "  'offset': 46,\n",
       "  'role': 'user',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'mask_text': 'Nepthys turned to me.“Well, kid, what do you think?.“Well, kid, what do you have in mind?.“Well, kid, what do you suppose?.“Well, kid, what do you presume?.“Well, kid, what do you reckon?.“Well, kid, what do you conclude?.“Well, kid, what do you <mask>?Remember, this is your quest.'},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_episode_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f270f4d-aaef-492f-9996-468f8b0351c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The word payable is not clear to me. Do you mean something like due,paid,pay,payment,available ?',\n",
       " 'option_words': [('due', 0.81),\n",
       "  ('paid', 0.135),\n",
       "  ('pay', 0.009),\n",
       "  ('payment', 0.003),\n",
       "  ('available', 0.002)],\n",
       " 'action': 2,\n",
       " 'role': 'bot'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_list[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc12dec7-4de1-4de7-b238-952c54645e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# 定义一个枚举类型\n",
    "class Action(Enum):\n",
    "    NO_ACTION = 0\n",
    "    CONFIRM = 1\n",
    "    OPTION = 2\n",
    "    EXPLAIN = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4b2e781-0488-4a8b-9e97-ef0bc063d758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for action in Action:\n",
    "    print(action.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47658a3-8666-457b-bedf-e4c983ac320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "03a68d8c-4e76-4173-ba3b-536e4ded903b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 58, False: 42})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "Counter(pd.DataFrame([e[2] for e in episodes_list[-100:]])['is_right_action'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "20358fbc-4181-4462-be81-b3c3ec2046b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     hello\n"
     ]
    }
   ],
   "source": [
    "print('hello'.rjust(10, ' '))\n",
    "# 输出 '# 输出 'hello   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c6170679-2c66-4070-ac32-074f9b8590d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Months earlier, we might have sought a bed, a couch, or a\\n                    comfortable chair at this point. Instead, I asked, \"Is he handsome?\" \\n                 \"You\\'re jealous.\"',\n",
       "  'target': 'Instead',\n",
       "  'substitutes': [('alternatively', 0.6),\n",
       "   ('however', 0.6),\n",
       "   ('alternately', 0.5),\n",
       "   ('rather', 0.4),\n",
       "   ('on second thought', 0.4),\n",
       "   ('in lieu', 0.3),\n",
       "   ('as a substitute', 0.3),\n",
       "   ('alternative', 0.3),\n",
       "   ('in place of', 0.3),\n",
       "   ('on behalf of', 0.3),\n",
       "   ('rather than', 0.2),\n",
       "   ('preferably', 0.0),\n",
       "   ('in preference', 0.0),\n",
       "   ('quietly', 0.0),\n",
       "   ('actually', 0.0)],\n",
       "  'offset': 111,\n",
       "  'role': 'user'},\n",
       " {'text': 'The word Instead is not clear to me. Do you mean something like how,</s>,then,and,so ?',\n",
       "  'option_words': [('how', 0.254),\n",
       "   ('</s>', 0.131),\n",
       "   ('then', 0.025),\n",
       "   ('and', 0.022),\n",
       "   ('so', 0.021)],\n",
       "  'action': 2,\n",
       "  'role': 'bot'},\n",
       " {'text': 'none of these',\n",
       "  'reward': -1,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user'},\n",
       " {'text': 'The word Instead is not clear to me. Could you please provide me more context?',\n",
       "  'option_words': [('how', 0.254),\n",
       "   ('</s>', 0.131),\n",
       "   ('then', 0.025),\n",
       "   ('and', 0.022),\n",
       "   ('so', 0.021)],\n",
       "  'action': 3,\n",
       "  'role': 'bot'},\n",
       " {'text': 'the explain content',\n",
       "  'reward': 0.5,\n",
       "  'is_right_action': True,\n",
       "  'role': 'user'},\n",
       " {'text': '',\n",
       "  'option_words': [('how', 0.254),\n",
       "   ('</s>', 0.131),\n",
       "   ('then', 0.025),\n",
       "   ('and', 0.022),\n",
       "   ('so', 0.021)],\n",
       "  'action': 0,\n",
       "  'role': 'bot'},\n",
       " {'text': ' you misunderstdood my words, I mean...',\n",
       "  'reward': -2,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2ccbddd4-0a93-407a-a1da-96aa8357ef63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electronic theft by foreign and industrial spies and disgruntled\n",
      "\t\t\t\temployees is costing U.S. companies billions and eroding their\n",
      "\t\t\t\tinternational competitive advantage. That was the message delivered by\n",
      "\t\t\t\tgovernment and private security experts at an all-day conference on\n",
      "\t\t\t\tcorporate electronic espionage. \"Hostile and even friendly nations\n",
      "\t\t\t\troutinely steal information from U.S. companies and share it with their\n",
      "\t\t\t\town companies,\" said Noel D. Matchett, a former staffer at the federal\n",
      "\t\t\t\tNational Security Agency and now president of Information Security Inc.,\n",
      "\t\t\t\tSilver Spring, Md.\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "authority\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "official\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "state\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "government\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "official\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "turn = 0\n",
    "for his in env.history:\n",
    "    space_num = 0 if turn%2==0 else (135-len(his['text']))\n",
    "    # print(turn, space_num) \n",
    "    print(' '*space_num + his['text'])\n",
    "    print('----------------------------------')\n",
    "    turn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3726263f-0d58-46ee-a78b-8e7462ab58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526630f-1db7-49f1-98f5-33da68418946",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "76cab7a6-73b5-40ac-933f-777ec167caaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {True: {'answer': '', 'reward': 2, 'terminated': True},\n",
       "  False: {'answer': ' you misunderstdood my words, I mean...',\n",
       "   'reward': -2,\n",
       "   'terminated': True}},\n",
       " 1: {True: {'answer': 'Yes, it is', 'reward': 1.5, 'terminated': True},\n",
       "  False: {'answer': 'No, it is not ', 'reward': -1.5, 'terminated': False}},\n",
       " 2: {True: {'answer': None, 'reward': 1, 'terminated': True},\n",
       "  False: {'answer': ' none of these', 'reward': -1, 'terminated': False}},\n",
       " 3: {True: {'answer': 'the explain content',\n",
       "   'reward': 0.5,\n",
       "   'terminated': False},\n",
       "  False: {'answer': 'it is obviously, but I will try explain it too',\n",
       "   'reward': -0.5,\n",
       "   'terminated': True}}}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5c9c9504-3277-47e6-8517-b061f06114e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_action(self):\n",
    "    option_words = self.get_option_words_by_llm(self.context_id)\n",
    "    should_no_action = self.should_no_action(option_words)\n",
    "    should_confirm = self.should_confirm(option_words)\n",
    "    should_opt = self.should_opt(option_words)\n",
    "    should_explain = self.should_explain(option_words)\n",
    "\n",
    "    right_action = [should_no_action, should_confirm, should_opt, should_explain]\n",
    "    return right_action.index("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "034bd783-1f67-4274-8982-fefa36a84487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_action(env).index(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8faeee0-e1b7-4faf-8295-465d7e3a9e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option = env.get_option_words_by_llm(context_id)\n",
    "env.get_best_action()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09154a4-0ca2-472d-946d-63117b2faf80",
   "metadata": {},
   "source": [
    "## Expierment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57a7402-23e5-4b51-bbe1-13f54d3816b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info =  env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c62f8eaf-ff49-42bb-a766-574cb871eb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question(text='I imagine that people do not come here for unimportant reasons.”\\n            It hissed thoughtfully. “True, true.', target='hissed', substitutes=[('seethe', 0.4), ('jeer', 0.3), ('make buzzing sound', 0.3), ('whirr', 0.3), ('whistle', 0.2), ('sputter', 0.2), ('mock', 0.2), ('shrill', 0.1), ('boo', 0.1), ('deride', 0.0), ('blow', 0.0), ('whiz', 0.0), ('rasp', 0.0), ('hoot', 0.0), ('say', 0.0), ('wheeze', 0.0), ('disapprove', 0.0), ('damn', 0.0), ('sizzle', 0.0), ('catcall', 0.0), ('buzz', 0.0), ('sibilate', 0.0), ('revile', 0.0), ('ridicule', 0.0), ('spit', 0.0), ('sigh', 0.0), ('condemn', 0.0), ('shout down', 0.0), ('whisper', 0.0), ('decry', 0.0), ('siss', 0.0)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.history[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29e54d-87cd-4092-aa66-cdfb6a04523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "71cea31d-abae-4d73-addd-94c0822dcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = self.history[0]\n",
    "\n",
    "mask_show = ''\n",
    "solo_mask = h0.text.replace(h0.target,'<mask>',1)\n",
    "mask_text = ''\n",
    "for i,(word,score) in enumerate(h0.substitutes[:5]):\n",
    "    if len(h0.text)*6<2100:\n",
    "        text = h0.text\n",
    "    else:\n",
    "        subtract_len = len(h0.text)-350\n",
    "        index = h0.text.index(h0.target)\n",
    "        if i%2==0:\n",
    "            pre_sub_index = min(0+subtract_len,index-20)\n",
    "            text = h0.text[pre_sub_index:]\n",
    "        else:\n",
    "            post_sub_index = max(len(h0.text)-subtract_len,index+20)\n",
    "            text = h0.text[:post_sub_index]\n",
    "    text.replace(h0.target,word,1)\n",
    "    if len(self.model.tokenizer(mask_text+text+solo_mask)['input_ids'])>512:\n",
    "        break\n",
    "    mask_text += text.replace(h0.target,word,1)\n",
    "    # mask_show += text.replace(h0.target,f\"\\033[31m{word}\\033[0m\",1)+'\\033[31m<\\nnewline>\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e17ea-b523-4da8-bd83-77be6850aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "945ecfc1-ab26-4d5e-abb7-06b5a1861159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('even', 0.913),\n",
       " ('and', 0.022),\n",
       " ('particularly', 0.007),\n",
       " ('especially', 0.003),\n",
       " ('although', 0.003)]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "62620618-12bc-47b7-a9c2-c39fc99f95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "5e4b8ab4-9468-4ab5-a1b7-f822d81477d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[question(text='In its center, under a spearing, white light, was a golden table draped with a blue velvet cloth, on which lay a gray, plum-sized rock.\\n            “A marvel, isn’t it?” she said.', target='marvel', substitutes=[('wonder', 0.9), ('phenomenon', 0.6), ('miracle', 0.5), ('amazement', 0.5), ('awed', 0.2), ('be amazed be', 0.1), ('genius', 0.0), ('goggle', 0.0), ('prodigy', 0.0), ('gaze', 0.0), ('feel surprise', 0.0), ('stare', 0.0), ('stand in awe', 0.0), ('be surprised', 0.0), ('sensation', 0.0), ('gape', 0.0)])]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "ecdbb1f6-5df4-4e66-906f-9b13933066cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wonder', 0.686),\n",
       " ('miracle', 0.053),\n",
       " ('magic', 0.03),\n",
       " ('strange', 0.012),\n",
       " ('wonderful', 0.01)]"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_option_words_by_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "235af17a-cfb3-41cd-a99f-0a463ff6280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e578cb-9b1e-419e-aecd-e70796c23ba9",
   "metadata": {},
   "source": [
    "##  evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "1572c057-1a94-4853-98d2-01c1939a73fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'environment' from '/mnt/d/BaiduSyncdisk/intelligent_interactive_system/Thesis/RL/environment.py'>"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "436f4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f53d4f93-e135-4517-a934-e372ef7dc4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context_id_state_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46860cba-b183-42fa-a18a-74891ec04759",
   "metadata": {},
   "source": [
    "# Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7f524ba8-ba44-4b80-b982-b96651ecf469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [18:49<00:00,  1.48s/it]\n",
      "100%|██████████| 370/370 [09:25<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "context_id_state_mapping = {}\n",
    "context_option_mapping = {}\n",
    "for env in [train_env,test_env]:\n",
    "    for context_id in tqdm.tqdm(env.OA.context_ids):\n",
    "        # if (context_id in context_id_state_mapping) and (context_id in context_option_mapping):\n",
    "        #     continue\n",
    "        state,info = env.reset(context_id)\n",
    "        option_words = env.get_option_words_by_llm(context_id,False)\n",
    "        context_id_state_mapping[context_id] = state\n",
    "        context_option_mapping[context_id] = option_words\n",
    "    \n",
    "import pickle\n",
    "with open(\"state.pkl\",\"wb\") as f:\n",
    "    pickle.dump(context_id_state_mapping,f)\n",
    "with open(\"option.pkl\",\"wb\") as  f:\n",
    "    pickle.dump(context_option_mapping,f  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75c2b551-0653-45af-8907-58444162ef23",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have exactly one of create/read/write/append mode and at most one plus",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moption.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m    my_obj \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have exactly one of create/read/write/append mode and at most one plus"
     ]
    }
   ],
   "source": [
    " with open(\"option.pkl\",\"b\") as f:\n",
    "    my_obj = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c8a2c-0bca-4746-b3c8-c96a0b22a5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f3fb291-b69f-4654-9193-354a3c3be667",
   "metadata": {},
   "outputs": [],
   "source": [
    "del context_id_state_mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21147f5b-1cfc-4024-b4aa-c19e2068e0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.34375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(64*768*370)/(1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6799f881-61bd-4c5a-8519-1fcfe953b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_id_state_mapping['c:c28336fbaeb6942c1454706a864cdf89c4535313'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59527332-e5f1-4605-a797-714aa2282a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "265873fe-c8eb-4cd2-a5c7-b6c57a282843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_option_words_by_llm(self,context_id):\n",
    "    # state, info = test_env.reset()\n",
    "    # h0 =self.history[0]\n",
    "\n",
    "\n",
    "    def repeat_part(sent,target,substitutes,trunck=False):\n",
    "        rep_list = []\n",
    "        substitutes = [w for w,s in substitutes[:5]]\n",
    "        for sub in [target]+substitutes+['<mask>']:\n",
    "            start = offset-30 if trunck else 0\n",
    "            post_start = offset-sent.start_char+len(target)\n",
    "            post_end = post_start+30 if trunck else  100000000\n",
    "            repeat_part = f\"{sent.text[start:offset-sent.start_char]}{sub}{sent.text[post_start:post_end]}\"\n",
    "            rep_list.append(repeat_part)\n",
    "        return '.'.join(rep_list)\n",
    "\n",
    "    h0,_ = self.OA.sample(context_id)\n",
    "    # h0 = self.history[0]\n",
    "\n",
    "    offset = h0['offset']\n",
    "    mask_sentence_list = []\n",
    "    for sent in nlp(h0['text']).sents:\n",
    "        print(sent.start_char, offset ,sent.end_char)\n",
    "        if sent.start_char <= offset <sent.end_char:\n",
    "            sent_text = repeat_part(sent, h0['target'], h0['substitutes'])\n",
    "            mask_sentence_list.append(sent_text)\n",
    "        else:\n",
    "            mask_sentence_list.append(sent.text)\n",
    "\n",
    "    mask_text = ''.join(mask_sentence_list)\n",
    "    token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "\n",
    "    if token_lens>512:\n",
    "        mask_sentence_list = []\n",
    "        for sent in nlp(h0['text']).sents:\n",
    "            if sent.start_char <= offset <sent.end_char:\n",
    "                sent_text = repeat_part(sent, h0['target'], h0['substitutes'],True)\n",
    "                # print('-------------')\n",
    "                mask_sentence_list.append(sent_text)\n",
    "            else:\n",
    "                mask_sentence_list.append(sent.text)\n",
    "        mask_text = ''.join(mask_sentence_list)\n",
    "        token_lens = len(tokenizer(''.join(mask_text))['input_ids'])                \n",
    "    # words = [(token['token_str'],round(token['score'],3)) for token in self.mask_model(mask_text)]\n",
    "    return mask_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f31c0a99-ba06-4c0d-ae62-3de2c7da34d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Let’s go.”\\n            As we headed down the sidewalk, I said, “What is your name, anyway?”'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "h0['text'][h0['offset']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7fd005a-dc4a-4b37-bf68-6fd1f5605093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 128 95\n",
      "96 128 445\n",
      "446 128 499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 87, 1902, 959, 90698, 450, 87, 13648, 959, 33022, 47, 30698, 4, 1284, 47, 1992, 4745, 35978, 5, 3827, 45188, 70, 5551, 77968, 67, 28302, 23, 6, 5, 7077, 16065, 70, 5551, 77968, 67, 28302, 23, 6, 5, 107, 75161, 70, 5551, 77968, 67, 28302, 23, 6, 5, 43866, 107, 70, 5551, 77968, 67, 28302, 23, 6, 5, 3827, 38931, 70, 5551, 77968, 67, 28302, 23, 6, 5, 987, 19, 16065, 70, 5551, 77968, 67, 28302, 23, 6, 5, 250001, 70, 5551, 77968, 67, 28302, 23, 47009, 642, 23409, 1810, 100, 10, 72399, 186857, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(get_option_words_by_llm(test_env,context_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e64e23-e3a6-4a80-8eef-e7a151ce8df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4848b7ff-b2ab-4a7a-b558-6644c88b0cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': 'It was last February, after the winter break, that we moved in together. Now spring was back, under the concrete, and I could smell it even here.\\n            “Isn’t it an amazing night, Rache?',\n",
       "  'target': 'even',\n",
       "  'substitutes': [('still', 0.4),\n",
       "   ('as well as', 0.2),\n",
       "   ('so much as', 0.1),\n",
       "   ('much', 0.1),\n",
       "   ('in spite of', 0.0),\n",
       "   ('yet', 0.0),\n",
       "   ('despite', 0.0),\n",
       "   ('notwithstanding', 0.0),\n",
       "   ('indeed', 0.0),\n",
       "   ('actually', 0.0),\n",
       "   ('disregarding', 0.0),\n",
       "   ('more', 0.0),\n",
       "   ('yet all the', 0.0)],\n",
       "  'offset': 135},\n",
       " 'c:8449d1484b624c8db76ae3d9c60a000f677a244d')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.OA.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "0ec6bbc4-2192-449b-963a-dfde0704267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                   | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_142/1917932590.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 200/200 [18:37<00:00,  5.59s/it]\n"
     ]
    }
   ],
   "source": [
    "returns = 0\n",
    "action_list = []\n",
    "turns_list = []\n",
    "reward_list = []\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    context_id = test_env.OA.context_ids[i]\n",
    "    state, info = test_env.reset(context_id)\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    episode_returns = 0\n",
    "    for t in count():\n",
    "        action = select_action(state,eps_threshold=None)\n",
    "        action_list.append(action.item())\n",
    "        observation, reward, terminated, truncated, _ = test_env.step(action.item())\n",
    "        state = observation.reshape((1,-1))\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        episode_returns += reward\n",
    "        # returns += reward\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        if done:\n",
    "            turns_list.append(t)\n",
    "            reward_list.append(episode_returns)\n",
    "            # plot_durations()\n",
    "\n",
    "\n",
    "            turn = 0\n",
    "            for his in env.history:\n",
    "                space_num = 0 if turn%2==0 else (135-len(his.text))\n",
    "                role = \"User:\" if  turn%2==0 else  \"Bot:\"\n",
    "                # print(role)\n",
    "                # print(his.text)\n",
    "                # print('----------------------------------')\n",
    "                turn += 1\n",
    "            break\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "9a206ff2-7e06-4536-8f45-eae09192638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "695f4f0e-ac66-48fd-a6b0-7ce31c1db5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 919, 1: 16, 3: 21, 0: 13})"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "13494357-7186-4ac7-a1f5-3dd0510dcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "6ef6b0b9-7a14-4843-9833-b3fb9fc6a6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of occurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>options</th>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confirm</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more info</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no action</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           number of occurance\n",
       "options                    919\n",
       "confirm                     16\n",
       "more info                   21\n",
       "no action                   13"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_act = Counter(action_list) # = \n",
    "name_map = {0:'no action',1:'confirm',2:'options',3:'more info'}\n",
    "pd.DataFrame([data_act],index=['number of occurance']).rename(name_map,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "f70f76bb-0e1e-4fc6-a7dd-971d87fcb058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turns</th>\n",
       "      <th>Number of Occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   turns  Number of Occurrence\n",
       "0      5                   188\n",
       "1      2                     4\n",
       "2      3                     2\n",
       "3      1                     3\n",
       "4      4                     3"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame([Counter(turns_list)]).T.reset_index()\n",
    "df2.columns = ['turns','Number of Occurrence']\n",
    "df2['turns'] += 1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735458b7-9d8d-413e-a047-2e275cb36a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "16039882-513f-4eb2-9f22-b1c3c3f7a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0423d0f7-19db-48d2-95c4-a980273ce4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4036247594865046"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c83fc-a12d-47dd-a435-fb18daf8c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = origin_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afc7f6e2-6abf-40c1-88ad-588efc7773b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_id = random.choice(self.context_ids)\n",
    "context = self.contexts[context_id]['context']\n",
    "target = self.contexts[context_id]['targets'][0]\n",
    "target_text = target['target']\n",
    "substitutes = [(sub['substitute'],sub['label_score']) for sub in target['substitutes']]\n",
    "sorted_subs = sorted(substitutes,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55ffad1c-2582-46b8-94e3-1c1483af2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d38a4cd-c0bc-40f3-9a26-d657504ccfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.1000])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a617918-e081-4a3c-8b58-7ccea316b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_return = []\n",
    "len_avg = 10\n",
    "for i in range(len(return_list)-len_avg):\n",
    "    average_return.append(np.mean([s.item() for s in return_list[i:i + len_avg]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd4b046c-0d80-4bf4-be7a-472eb7053d24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_268/136110296.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturn_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.mean([s.item() for s in return_list[i:i+10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5101dc4a-8af9-4411-a084-fc42f316549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc207554-12b6-4aea-8d22-e32efc26c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d78b0368-9ada-42ee-9e74-3b11feb8201a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "00cabcfd-0895-4f2b-ae98-9c955fe3142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_part(sent,target,substitutes,trunck=False):\n",
    "    rep_list = []\n",
    "    substitutes = [w for w,s in substitutes[:5]]\n",
    "    for sub in [target]+substitutes+['<mask>']:\n",
    "        start = offset-30 if trunck else 0\n",
    "        repeat_part = f\"{sent.text[start:offset-sent.start_char]}{sub}{sent.text[offset-sent.start_char+len(target):]}\"\n",
    "        rep_list.append(repeat_part)\n",
    "    return '.'.join(rep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f0eeffd-4530-4993-97f0-c99033882847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f28f0698-a870-44de-9c8c-931402e76afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_origin_agent = OriginAgent(file_path='../data/swords/swords-v1.1_test.json.gz')\n",
    "test_env = environment.DialougeEnv(test_origin_agent,embedding_model,unmasker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8651b23c-b870-45ff-86b7-2ac8478b0e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 370/370 [00:34<00:00, 10.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for con in tqdm.tqdm(env.OA.context_ids):\n",
    "    state,info = env.reset(con)\n",
    "    h0 = env.history[0]\n",
    "    offset = h0['offset']\n",
    "    mask_sentence_list = []\n",
    "    for sent in nlp(h0['text']).sents:\n",
    "        if sent.start_char < offset <sent.end_char:\n",
    "            sent_text = repeat_part(sent, h0['target'], h0['substitutes'])\n",
    "            # print('-------------')\n",
    "            mask_sentence_list.append(sent_text)\n",
    "        else:\n",
    "            mask_sentence_list.append(sent.text)\n",
    "\n",
    "    mask_text = ''.join(mask_sentence_list)\n",
    "    token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "    token_lens, mask_text\n",
    "    \n",
    "    if token_lens>512:\n",
    "        mask_sentence_list = []\n",
    "        for sent in nlp(h0['text']).sents:\n",
    "            if sent.start_char < offset <sent.end_char:\n",
    "                sent_text = repeat_part(sent, h0['target'], h0['substitutes'],True)\n",
    "                # print('-------------')\n",
    "                mask_sentence_list.append(sent_text)\n",
    "            else:\n",
    "                mask_sentence_list.append(sent.text)\n",
    "        mask_text = ''.join(mask_sentence_list)\n",
    "        token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "        if token_lens>512:\n",
    "            print(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "681914b8-a4d2-4d2f-94df-a4ccfe7e11d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "The FBI cited a vivid conversation with Anissina's mother in\n",
      "which Tokhtakhounov assured her that even if her daughter \"falls,\n",
      "we will make sure she is No. 1.\"\n",
      "\n",
      "\n",
      "   After the Winter Olympics, a French judge, Marie-Reine Le\n",
      "Gougne, was suspended by the International Skating Union for not\n",
      "reporting pressure she said was put on her by Didier Gailhaguet,\n",
      "president of the French Skating Federation, to vote for the Russian\n",
      "pairs team.\n",
      "\n",
      "\n",
      "   \n",
      "-----------\n",
      "She later recanted and said that Canadian officials had\n",
      "pressured her.\n"
     ]
    }
   ],
   "source": [
    "for sent in nlp(h0['text']).sents:\n",
    "    print(\"-----------\")\n",
    "    print(sent)\n",
    "    print(sent)\n",
    "# print(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bee743a-345f-4b7f-bfd3-03744fb63efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.text[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2d9e29a-186d-4e98-b3e4-b48b3eb043cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \";1 W;2 e;3  ;4 w;5 e;6 r;7 e;8  ;9 a;10 l;11 l;12  ;13 a;14 p;15 p;16 a;17 l;18 l;"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(text[0:19]):\n",
    "    print(i,t,end=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecb0d3d8-2d9f-4daa-877c-910423c9f288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.start_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26eafd0f-24ee-43a5-8fcc-f05f4bd2dd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Span.as_doc>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.as_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "863497a7-1519-431b-adcf-1ffe8507f150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<environment.OriginAgent at 0x7fc5603b8b80>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c0ed589-045e-4fd3-ac03-6e1a18d55955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# 加载英文语言模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16c53a-1d45-4fd0-8fd8-e841a6fa6d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncat(text):\n",
    "    text_list = []\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b15f6c93-38ab-43c5-99b9-945c2560daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "034d4b53-60f4-44c3-b1ca-dce988626082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-------------------------------------\n",
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of the wise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of knowledge\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of advice\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of astuteness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of sageness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of enlightenment\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of expertise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of <mask>\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-----------wisdom--------------\n",
      "[('the wise', 0.6), ('knowledge', 0.5), ('advice', 0.5), ('astuteness', 0.5), ('sageness', 0.5), ('enlightenment', 0.4), ('expertise', 0.4), ('intelligence', 0.4), ('shrewdness', 0.4), ('wise thinking', 0.3), ('experience', 0.3), ('insight', 0.3), ('judiciousness', 0.3), ('clear thinking', 0.2), ('good judgment', 0.2), ('reason', 0.2), ('caution', 0.2), ('comprehension', 0.2), ('foresight', 0.2), ('discernment', 0.2), ('acumen', 0.2), ('perspicacity', 0.1), ('sanity', 0.1), ('prudence', 0.1), ('savvy', 0.1), ('sagacity', 0.1), ('horse sense', 0.0), ('common sense', 0.0), ('poise', 0.0), ('discrimination', 0.0), ('penetration', 0.0), ('gumption', 0.0), ('balance', 0.0), ('judgment', 0.0), ('solidity', 0.0), ('practicality', 0.0), ('savoir faire', 0.0), ('sophistication', 0.0), ('information', 0.0), ('circumspection', 0.0), ('pansophy', 0.0), ('sapience', 0.0), ('stability', 0.0), ('understanding', 0.0), ('a sage', 0.0), ('erudition', 0.0), ('learning', 0.0), ('brains', 0.0)]\n",
      "-------------------------\n",
      "[('wisdom', 0.575), ('knowledge', 0.056), ('advice', 0.051), ('inspiration', 0.029), ('confidence', 0.023)]\n",
      "-------------------------\n",
      "[('said', 0.411), ('says', 0.121), ('was', 0.071), ('replied', 0.035), ('answered', 0.029)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "mask_text_doc = nlp(h0.text)\n",
    "mask_text = ''\n",
    "# 遍历每个句子并打印\n",
    "for sentence in mask_text_doc.sents:\n",
    "    # print(sentence.text)\n",
    "    if h0.target in sentence.text:\n",
    "        words = [h0.tarnlp = spacy.load(\"en_core_web_sm\")get,*[w for w,score in h0.substitutes[:5]],'<mask>']\n",
    "        sub_sentence_text = \".\".join([sentence.text.replace(h0.target,w,1) for w in words])\n",
    "        mask_text += sub_sentence_text\n",
    "    else:\n",
    "        mask_text += sentence.text\n",
    "if len(tokenizer(mask_text)['input_ids'])>10:\n",
    "    mask_text = ''\n",
    "    # 遍历每个句子并打印\n",
    "    for sentence in mask_text_doc.sents:\n",
    "        # print(sentence.text)\n",
    "        if h0.target in sentence.text:\n",
    "            parts = sentence.text.split(\",\")\n",
    "            mask_idx = [i for i,p in enumerate(parts) if (h0.target in p)][0]\n",
    "            words = [h0.target,*[w for w,score in h0.substitutes[:7]],'<mask>']\n",
    "            sub_sentence_text = \",\".join([parts[mask_idx].replace(h0.target,w,1) for w in words])\n",
    "            parts[mask_idx] = sub_sentence_text\n",
    "            mask_text += ' '.join(parts)\n",
    "        else:\n",
    "            mask_text += sentence.text\n",
    "\n",
    "print(h0.text)\n",
    "print(\"-------------------------------------\")\n",
    "print(mask_text)\n",
    "print(f\"-----------{h0.target}--------------\")\n",
    "print(h0.substitutes)\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(mask_text)])\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(solo_mask)])\n",
    "\n",
    "len(tokenizer(h0.text)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35dabde9-234b-419a-be2a-ba1db0a9971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-------------------------------------\n",
      "list>   \n",
      "\n",
      "Words of sageness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of knowledge\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of astuteness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of <mask>\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of advice\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of the wise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of expertise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of enlightenment\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-----------wisdom--------------\n",
      "[('the wise', 0.6), ('knowledge', 0.5), ('advice', 0.5), ('astuteness', 0.5), ('sageness', 0.5), ('enlightenment', 0.4), ('expertise', 0.4), ('intelligence', 0.4), ('shrewdness', 0.4), ('wise thinking', 0.3), ('experience', 0.3), ('insight', 0.3), ('judiciousness', 0.3), ('clear thinking', 0.2), ('good judgment', 0.2), ('reason', 0.2), ('caution', 0.2), ('comprehension', 0.2), ('foresight', 0.2), ('discernment', 0.2), ('acumen', 0.2), ('perspicacity', 0.1), ('sanity', 0.1), ('prudence', 0.1), ('savvy', 0.1), ('sagacity', 0.1), ('horse sense', 0.0), ('common sense', 0.0), ('poise', 0.0), ('discrimination', 0.0), ('penetration', 0.0), ('gumption', 0.0), ('balance', 0.0), ('judgment', 0.0), ('solidity', 0.0), ('practicality', 0.0), ('savoir faire', 0.0), ('sophistication', 0.0), ('information', 0.0), ('circumspection', 0.0), ('pansophy', 0.0), ('sapience', 0.0), ('stability', 0.0), ('understanding', 0.0), ('a sage', 0.0), ('erudition', 0.0), ('learning', 0.0), ('brains', 0.0)]\n",
      "-------------------------\n",
      "[('wisdom', 0.634), ('knowledge', 0.036), ('confidence', 0.028), ('inspiration', 0.02), ('patience', 0.016)]\n",
      "-------------------------\n",
      "[('said', 0.411), ('says', 0.121), ('was', 0.071), ('replied', 0.035), ('answered', 0.029)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "mask_text_doc = nlp(h0.text)\n",
    "mask_text = ''\n",
    "# 遍历每个句子并打印\n",
    "for sentence in mask_text_doc.sents:\n",
    "    # print(sentence.text)\n",
    "    if h0.target in sentence.text:\n",
    "        words = [h0.target,*[w for w,score in h0.substitutes[:7]],'<mask>']\n",
    "        random.shuffle(words)\n",
    "        sub_sentence_text = \".\".join([sentence.text.replace(h0.target,w,1) for w in words])\n",
    "        mask_text += sub_sentence_text\n",
    "    else:\n",
    "        mask_text += sentence.text\n",
    "if len(tokenizer(mask_text)['input_ids'])>512:\n",
    "    mask_text = ''\n",
    "    # 遍历每个句子并打印\n",
    "    for sentence in mask_text_doc.sents:\n",
    "        # print(sentence.text)\n",
    "        if h0.target in sentence.text:\n",
    "            parts = sentence.text.split(\",\")\n",
    "            mask_idx = [i for i,p in enumerate(parts) if (h0.target in p)][0]\n",
    "            words = [h0.target,*[w for w,score in h0.substitutes[:5]],'<mask>']\n",
    "            random.shuffle(words)\n",
    "            sub_sentence_text = \",\".join([parts[mask_idx].replace(h0.target,w,1) for w in words])\n",
    "            parts[mask_idx] = sub_sentence_text\n",
    "            mask_text += ' '.join(parts)\n",
    "        else:\n",
    "            mask_text += sentence.text\n",
    "\n",
    "print(h0.text)\n",
    "print(\"-------------------------------------\")\n",
    "print(mask_text)\n",
    "print(f\"-----------{h0.target}--------------\")\n",
    "print(h0.substitutes)\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(mask_text)])\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(solo_mask)])\n",
    "\n",
    "len(tokenizer(h0.text)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9151c40d-be9b-4906-92bb-b90334a05081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c4ad17a1-d1c4-4cb3-98cb-b8d9130fcee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['listless', '<mask>', 'lifeless', 'empty', 'dead', 'flat', 'deathly']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16ef9b55-9816-4030-9c30-5e09ba7162c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(mask_text)['input_ids'])>512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8cf6f4-2f01-4113-a3db-cf4aa1d6626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if there is target in the top masks :\n",
    "    that means LLM could predict well, the ambiagrous is less\n",
    "    \n",
    "    No action\n",
    "\n",
    "if top mask's score is high ,and in':\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "96753649-2f02-41e3-a3ab-aa6fcafec692",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 31 3.77\n",
      "276 77 3.58\n",
      "142 41 3.46\n",
      "404 106 3.81\n",
      "258 70 3.69\n",
      "129 36 3.58\n",
      "89 20 4.45\n",
      "358 96 3.73\n",
      "294 61 4.82\n",
      "313 81 3.86\n",
      "426 119 3.58\n",
      "213 41 5.2\n",
      "292 65 4.49\n",
      "152 29 5.24\n",
      "204 62 3.29\n",
      "251 59 4.25\n",
      "425 106 4.01\n",
      "266 65 4.09\n",
      "280 61 4.59\n",
      "321 67 4.79\n",
      "65 16 4.06\n",
      "375 84 4.46\n",
      "546 116 4.71\n",
      "194 45 4.31\n",
      "148 30 4.93\n",
      "183 42 4.36\n",
      "134 31 4.32\n",
      "207 48 4.31\n",
      "510 105 4.86\n",
      "297 58 5.12\n",
      "277 64 4.33\n",
      "242 53 4.57\n",
      "219 46 4.76\n",
      "243 59 4.12\n",
      "369 87 4.24\n",
      "420 76 5.53\n",
      "226 60 3.77\n",
      "296 73 4.05\n",
      "131 35 3.74\n",
      "111 26 4.27\n",
      "192 45 4.27\n",
      "164 42 3.9\n",
      "93 28 3.32\n",
      "446 106 4.21\n",
      "336 96 3.5\n",
      "420 76 5.53\n",
      "245 61 4.02\n",
      "258 70 3.69\n",
      "290 64 4.53\n",
      "154 34 4.53\n",
      "293 69 4.25\n",
      "197 52 3.79\n",
      "224 58 3.86\n",
      "195 44 4.43\n",
      "153 35 4.37\n",
      "112 27 4.15\n",
      "129 36 3.58\n",
      "386 93 4.15\n",
      "226 47 4.81\n",
      "270 69 3.91\n",
      "343 77 4.45\n",
      "422 113 3.73\n",
      "171 45 3.8\n",
      "540 134 4.03\n",
      "335 73 4.59\n",
      "259 63 4.11\n",
      "293 69 4.25\n",
      "103 27 3.81\n",
      "185 43 4.3\n",
      "153 35 4.37\n",
      "325 79 4.11\n",
      "277 65 4.26\n",
      "73 20 3.65\n",
      "433 109 3.97\n",
      "245 61 4.02\n",
      "354 74 4.78\n",
      "129 36 3.58\n",
      "376 98 3.84\n",
      "232 58 4.0\n",
      "595 132 4.51\n",
      "267 52 5.13\n",
      "475 96 4.95\n",
      "154 34 4.53\n",
      "201 50 4.02\n",
      "259 63 4.11\n",
      "83 23 3.61\n",
      "112 22 5.09\n",
      "187 41 4.56\n",
      "327 89 3.67\n",
      "143 41 3.49\n",
      "480 108 4.44\n",
      "380 94 4.04\n",
      "391 89 4.39\n",
      "166 36 4.61\n",
      "440 118 3.73\n",
      "160 41 3.9\n",
      "123 29 4.24\n",
      "141 30 4.7\n",
      "181 40 4.53\n",
      "392 107 3.66\n"
     ]
    }
   ],
   "source": [
    "l0s = 0\n",
    "l1s=0\n",
    "for i in  range(100):\n",
    "    state,info = test_env.reset()\n",
    "    h0 = test_env.history[0]\n",
    "    l1 = len(tokenizer(h0.text)['input_ids'])\n",
    "    l0 = len(h0.text)\n",
    "    l0s+=l0\n",
    "    l1s+=l1\n",
    "    print(l0,l1,round(l0/l1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "5233ed7c-4d59-46a6-bd24-9fe5ea2e2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2502\n",
      "2502\n",
      "2502\n",
      "2502\n",
      "2502\n"
     ]
    }
   ],
   "source": [
    "state,info = test_env.reset()\n",
    "h0 = test_env.history[0]\n",
    "solo_mask = h0.text.replace(h0.target,'<mask>',1)\n",
    "mask_text = ''\n",
    "for i,(word,score) in enumerate(h0.substitutes[:5]):\n",
    "    print(len(h0.text)*6)\n",
    "    if len(h0.text)*6<2100:\n",
    "        text = h0.text\n",
    "    else:\n",
    "        subtract_len = len(h0.text)-350\n",
    "        index = h0.text.index(h0.target)\n",
    "        post_sub_index = max(len(h0.text)-subtract_len,index+20)\n",
    "        if i%2==0:\n",
    "            pre_sub_index = min(0+subtract_len,index-20)\n",
    "            text = h0.text[pre_sub_index:]\n",
    "    if len(tokenizer(mask_text+text+solo_mask)['input_ids'])>512:\n",
    "        break\n",
    "    mask_text += text\n",
    "mask_text  += solo_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "82fe1ec7-6e32-4a45-a3af-dd1ac4c72bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.The problem was that I have trouble distinguishing between\\n                    compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, <mask> only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.\""
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "a34ff1be-25f3-450e-a345-2f3e42b1f199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2084"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "92cce71c-9380-4bfb-bf49-d7d497adef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "acef1d04-5afd-491b-8882-a39718b6a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "07d3f2ac-4b8b-4503-9e36-ef8473b70c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "400e399a-712b-4bc1-878c-67fa88ce211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_text = (text*12)[:-23]+ '<mask>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "cb1ea2f5-1ae4-4cdb-809d-85a6e1e6a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer(m_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "d36a8682-3794-460b-9f02-ee20fc081ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "6f7cd642-860d-4a5d-a5f6-c5af65e6e2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8441550135612488,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,'},\n",
       " {'score': 0.11659591645002365,\n",
       "  'token': 4,\n",
       "  'token_str': ',',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,,'},\n",
       " {'score': 0.008581217378377914,\n",
       "  'token': 27,\n",
       "  'token_str': '...',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,...'},\n",
       " {'score': 0.0016685021109879017,\n",
       "  'token': 122880,\n",
       "  'token_str': 'More',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,More'},\n",
       " {'score': 0.001654961844906211,\n",
       "  'token': 19659,\n",
       "  'token_str': 'As',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,As'}]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(m_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f43a9a71-cd1b-4ce5-be49-376b1d21795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2099.2"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512*4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7e0f3d33-64be-455f-b6d8-9e29feb2848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350.0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2100/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a4836d14-a1ea-4461-a11c-476147523d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.199420569773056"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l0s/l1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "11799913-5c24-48ab-91a4-68674483d867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1559"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a3cf02aa-f675-42ed-bab0-2c43ef855d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 387)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0.text.index(h0.target),len(h0.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6e6f55e4-1516-45d2-8fd6-6fb2aaa3c438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512 - len(h0.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6faa4248-9c78-45b0-92f2-d30372e16b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3b4cd41-1196-4772-a0e5-547df069f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3f9ee-abf3-49c9-93ea-239e125c6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.AutoModelForMaskedLM("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3658acbe-810b-4309-8b68-b44b1ee0792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbe8242b-0ea8-499c-a7f0-e1481ceec8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe3d9fe6-ff6e-465b-b5f5-8ca8c458e9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea3f62a5-5adf-4a81-87a3-26692355288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# forward pass\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b19e111f-be61-47dc-b9c9-5f1cc09850f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ 6.4861e+01,  1.6882e-02,  3.7656e+01,  ...,  2.1584e+01,\n",
       "           1.4380e+01,  1.8790e+01],\n",
       "         [ 2.7493e+01, -1.4091e+00,  6.4847e+01,  ...,  4.0234e+01,\n",
       "           1.6296e+01,  3.0925e+01],\n",
       "         [ 1.9604e+01, -1.2597e+00,  4.8981e+01,  ...,  3.5830e+01,\n",
       "           1.7145e+01,  2.7173e+01],\n",
       "         ...,\n",
       "         [ 2.2920e+01, -1.4657e+00,  5.1211e+01,  ...,  3.8495e+01,\n",
       "           1.6508e+01,  2.7687e+01],\n",
       "         [ 2.8598e+01, -1.2868e+00,  6.7706e+01,  ...,  4.4857e+01,\n",
       "           1.8004e+01,  3.5004e+01],\n",
       "         [ 4.4955e+01, -2.1554e-01,  4.9643e+01,  ...,  2.8253e+01,\n",
       "           1.6841e+01,  2.3610e+01]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5db2c37a-a78d-49d1-9a6b-f9f3ab131b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForMaskedLM"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e735b-0ede-4ec2-be41-1da2b2ffca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    predictions = outputs.logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "65983169-e35a-422e-8062-6df8d1f9398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 16:07:54.349083: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-17 16:07:54.349119: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import FillMaskPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a8f49495-ce6e-4f29-80ea-6a75bbb84950",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EmbeddingModel' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142/1315868084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFillMaskPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, image_processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m     ):\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_framework_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EmbeddingModel' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "mask_pipeline = FillMaskPipeline(model=env.model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d0b98934-a79b-4ddd-b4a9-5685596f5cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.07687385380268097,\n",
       "  'token': 34923,\n",
       "  'token_str': 'beautiful',\n",
       "  'sequence': 'this is a beautiful car'},\n",
       " {'score': 0.04615773260593414,\n",
       "  'token': 29681,\n",
       "  'token_str': 'sports',\n",
       "  'sequence': 'this is a sports car'},\n",
       " {'score': 0.03222648799419403,\n",
       "  'token': 54704,\n",
       "  'token_str': 'classic',\n",
       "  'sequence': 'this is a classic car'},\n",
       " {'score': 0.031460631638765335,\n",
       "  'token': 6782,\n",
       "  'token_str': 'great',\n",
       "  'sequence': 'this is a great car'},\n",
       " {'score': 0.030774081125855446,\n",
       "  'token': 26267,\n",
       "  'token_str': 'nice',\n",
       "  'sequence': 'this is a nice car'}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_pipeline(\"this is a <mask> car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db5c451f-564e-43aa-aeb2-6dfaa73e9c45",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaModel(\n",
       "  (embeddings): XLMRobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): XLMRobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): XLMRobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a481806c-5179-4fdf-aaec-d99a73a87260",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForMaskedLM(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): XLMRobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=250002, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ace047-ea17-4956-9370-fec2002d8018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
