{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7c063d-6406-4004-b32e-4d4d831fab90",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_735/1876905766.py:15: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "2023-05-30 13:52:49.473732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-30 13:52:49.473771: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-30 13:52:52.735911: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-05-30 13:52:52.735956: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-30 13:52:52.736016: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (squirrel): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "# import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "\n",
    "from imp import reload\n",
    "import rl_dqn\n",
    "import environment\n",
    "import embedding\n",
    "\n",
    "from rl_dqn import ReplayMemory, DQN, Transition\n",
    "from embedding import EmbeddingModel\n",
    "from environment import OriginAgent, DialougeEnv\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c1217f6-26b9-4b28-8e10-bf0c02300975",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(rl_dqn)\n",
    "reload(environment)\n",
    "reload(embedding)\n",
    "\n",
    "from rl_dqn import ReplayMemory, DQN, Transition\n",
    "from embedding import EmbeddingModel\n",
    "from environment import OriginAgent, DialougeEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21382b94-13e6-4445-996d-b118c61d5c5b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embedding_model = EmbeddingModel()\n",
    "unmasker = pipeline('fill-mask', model='xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb2dac6b-c76a-4dcf-8f83-92c444153299",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "origin_agent = OriginAgent()\n",
    "env = environment.DialougeEnv(origin_agent,embedding_model,unmasker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa984cbc-b694-418c-b07f-782435762157",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bfcfaf-fd17-448e-900c-430167c2931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9254a892-b7d1-4bc4-8a47-208d629c448b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                              | 0/3000 [00:00<?, ?it/s]/tmp/ipykernel_575/2957816014.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
      "/tmp/ipykernel_575/2957816014.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
      "  0%|▏                                                                                                   | 5/3000 [00:11<1:51:42,  2.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_575/2957816014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mreturns\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/BaiduSyncdisk/intelligent_interactive_system/Thesis/RL/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0msubstitutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'substitutes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mbot_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbot_utterance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mbot_utter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbot_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'option_words'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moption_words\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0manswer_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_utterance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/BaiduSyncdisk/intelligent_interactive_system/Thesis/RL/environment.py\u001b[0m in \u001b[0;36mbot_utterance\u001b[0;34m(self, action, target)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbot_utterance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0moption_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_option_words_by_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mAction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNO_ACTION\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/BaiduSyncdisk/intelligent_interactive_system/Thesis/RL/environment.py\u001b[0m in \u001b[0;36mget_option_words_by_llm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mmask_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_sentence_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mtoken_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_str'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             )\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1107\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         )\n\u001b[0;32m--> 854\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    855\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    526\u001b[0m                 )\n\u001b[1;32m    527\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    529\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state,eps_threshold=None):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    if  eps_threshold is not None:\n",
    "        eps_threshold = 0\n",
    "    else:\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "            math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "\n",
    "num_episodes = 3000\n",
    "return_list = []\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "for i_episode in tqdm.tqdm(range(num_episodes)):\n",
    "    # Initialize the environment and get it's state\n",
    "    returns = 0\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        returns += reward\n",
    "        done = terminated or truncated\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "        if done:\n",
    "            return_list.append(returns)\n",
    "            # plot_durations()\n",
    "            break\n",
    "\n",
    "turn = 0\n",
    "for his in env.history:\n",
    "    space_num = 0 if turn%2==0 else (135-len(his.text))\n",
    "    print(turn, space_num) \n",
    "    print(' '*space_num + his.text)\n",
    "    print('----------------------------------')\n",
    "    turn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8faeee0-e1b7-4faf-8295-465d7e3a9e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'U.S. Representative Tony Hall arrived in Jordan on\\n\\t\\t\\t\\tSaturday en route to Iraq, where he is expected to look into the plight\\n\\t\\t\\t\\tof Iraqis after nearly 10 years of U.N. trade sanctions.\\n\\t\\t\\tHall, an Ohio Democrat and one of very few U.S. congressmen to visit\\n\\t\\t\\t\\tIraq since the 1991 Gulf War over Kuwait, is scheduled to embark Sunday\\n\\t\\t\\t\\tthe 12-hour overland trip to the Iraqi capital, Baghdad.\\n\\t\\t\\tHe did not speak to reporters in Jordan, but he told The Associated\\n\\t\\t\\t\\tPress before leaving the United States that he hopes to \"separate the\\n\\t\\t\\t\\thumanitarian work from the political issues.\"', 'target': 'trip', 'substitutes': [('journey', 0.8), ('voyage', 0.5), ('trek', 0.5), ('excursion', 0.5), ('visit', 0.4), ('expedition', 0.4), ('tour', 0.3), ('outing', 0.3), ('travel', 0.2), ('errand', 0.1), ('peregrination', 0.1), ('quest', 0.1), ('swing', 0.0), ('indiscretion', 0.0), ('mistake', 0.0), ('ramble', 0.0), ('cruise', 0.0), ('blunder', 0.0), ('overnight', 0.0), ('false step', 0.0), ('error', 0.0), ('bungle', 0.0), ('false move', 0.0), ('jaunt', 0.0), ('weekend', 0.0), ('run', 0.0), ('junket', 0.0), ('foray', 0.0), ('slip', 0.0), ('faux pas', 0.0), ('fall', 0.0), ('lapse', 0.0), ('misstep', 0.0), ('hop', 0.0), ('stumble', 0.0)], 'offset': 361}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('trip', 0.455),\n",
       " ('journey', 0.222),\n",
       " ('visit', 0.114),\n",
       " ('trek', 0.089),\n",
       " ('voyage', 0.089)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,info =  env.reset()\n",
    "print(env.history[0])\n",
    "env.get_option_words_by_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09154a4-0ca2-472d-946d-63117b2faf80",
   "metadata": {},
   "source": [
    "## Expierment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57a7402-23e5-4b51-bbe1-13f54d3816b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info =  env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c62f8eaf-ff49-42bb-a766-574cb871eb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question(text='I imagine that people do not come here for unimportant reasons.”\\n            It hissed thoughtfully. “True, true.', target='hissed', substitutes=[('seethe', 0.4), ('jeer', 0.3), ('make buzzing sound', 0.3), ('whirr', 0.3), ('whistle', 0.2), ('sputter', 0.2), ('mock', 0.2), ('shrill', 0.1), ('boo', 0.1), ('deride', 0.0), ('blow', 0.0), ('whiz', 0.0), ('rasp', 0.0), ('hoot', 0.0), ('say', 0.0), ('wheeze', 0.0), ('disapprove', 0.0), ('damn', 0.0), ('sizzle', 0.0), ('catcall', 0.0), ('buzz', 0.0), ('sibilate', 0.0), ('revile', 0.0), ('ridicule', 0.0), ('spit', 0.0), ('sigh', 0.0), ('condemn', 0.0), ('shout down', 0.0), ('whisper', 0.0), ('decry', 0.0), ('siss', 0.0)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.history[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29e54d-87cd-4092-aa66-cdfb6a04523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "71cea31d-abae-4d73-addd-94c0822dcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = self.history[0]\n",
    "\n",
    "mask_show = ''\n",
    "solo_mask = h0.text.replace(h0.target,'<mask>',1)\n",
    "mask_text = ''\n",
    "for i,(word,score) in enumerate(h0.substitutes[:5]):\n",
    "    if len(h0.text)*6<2100:\n",
    "        text = h0.text\n",
    "    else:\n",
    "        subtract_len = len(h0.text)-350\n",
    "        index = h0.text.index(h0.target)\n",
    "        if i%2==0:\n",
    "            pre_sub_index = min(0+subtract_len,index-20)\n",
    "            text = h0.text[pre_sub_index:]\n",
    "        else:\n",
    "            post_sub_index = max(len(h0.text)-subtract_len,index+20)\n",
    "            text = h0.text[:post_sub_index]\n",
    "    text.replace(h0.target,word,1)\n",
    "    if len(self.model.tokenizer(mask_text+text+solo_mask)['input_ids'])>512:\n",
    "        break\n",
    "    mask_text += text.replace(h0.target,word,1)\n",
    "    # mask_show += text.replace(h0.target,f\"\\033[31m{word}\\033[0m\",1)+'\\033[31m<\\nnewline>\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e17ea-b523-4da8-bd83-77be6850aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "945ecfc1-ab26-4d5e-abb7-06b5a1861159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('even', 0.913),\n",
       " ('and', 0.022),\n",
       " ('particularly', 0.007),\n",
       " ('especially', 0.003),\n",
       " ('although', 0.003)]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "62620618-12bc-47b7-a9c2-c39fc99f95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "5e4b8ab4-9468-4ab5-a1b7-f822d81477d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[question(text='In its center, under a spearing, white light, was a golden table draped with a blue velvet cloth, on which lay a gray, plum-sized rock.\\n            “A marvel, isn’t it?” she said.', target='marvel', substitutes=[('wonder', 0.9), ('phenomenon', 0.6), ('miracle', 0.5), ('amazement', 0.5), ('awed', 0.2), ('be amazed be', 0.1), ('genius', 0.0), ('goggle', 0.0), ('prodigy', 0.0), ('gaze', 0.0), ('feel surprise', 0.0), ('stare', 0.0), ('stand in awe', 0.0), ('be surprised', 0.0), ('sensation', 0.0), ('gape', 0.0)])]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "ecdbb1f6-5df4-4e66-906f-9b13933066cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wonder', 0.686),\n",
       " ('miracle', 0.053),\n",
       " ('magic', 0.03),\n",
       " ('strange', 0.012),\n",
       " ('wonderful', 0.01)]"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_option_words_by_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "235af17a-cfb3-41cd-a99f-0a463ff6280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e578cb-9b1e-419e-aecd-e70796c23ba9",
   "metadata": {},
   "source": [
    "##  evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "1572c057-1a94-4853-98d2-01c1939a73fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'environment' from '/mnt/d/BaiduSyncdisk/intelligent_interactive_system/Thesis/RL/environment.py'>"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "436f4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agent = environment.OriginAgent('../data/swords/swords-v1.1_test.json.gz')\n",
    "test_env = environment.DialougeEnv(test_agent,embedding_model,unmasker)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5df04f47-0a77-4e03-94da-255dfbd79084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▉                                                                                            | 36/370 [00:25<05:11,  1.07it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n",
      " 35%|███████████████████████████████████▏                                                                 | 129/370 [01:42<03:12,  1.25it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 327002616 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_575/616515104.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcontext_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moption_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_option_words_by_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcontext_id_state_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcontext_option_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moption_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/BaiduSyncdisk/intelligent_interactive_system/Thesis/RL/environment.py\u001b[0m in \u001b[0;36mget_option_words_by_llm\u001b[0;34m(self, context_id)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmask_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_sentence_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mtoken_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_str'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             )\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/fill_mask.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         )\n\u001b[1;32m   1119\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mprediction_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0mmasked_lm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;31m# project back to size of vocabulary with bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 327002616 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "context_id_state_mapping = {}\n",
    "context_option_mapping = {}\n",
    "for context_id in tqdm.tqdm(env.OA.context_ids):\n",
    "    state,info = env.reset(context_id)\n",
    "    option_words = env.get_option_words_by_llm(context_id)\n",
    "    context_id_state_mapping[context_id] = state\n",
    "    context_option_mapping[context_id] = option_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6799f881-61bd-4c5a-8519-1fcfe953b866",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'context_id_state_mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_735/1806646017.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontext_id_state_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'context_id_state_mapping' is not defined"
     ]
    }
   ],
   "source": [
    "context_id_state_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59527332-e5f1-4605-a797-714aa2282a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "265873fe-c8eb-4cd2-a5c7-b6c57a282843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_option_words_by_llm(self,context_id):\n",
    "    # state, info = test_env.reset()\n",
    "    # h0 =self.history[0]\n",
    "\n",
    "\n",
    "    def repeat_part(sent,target,substitutes,trunck=False):\n",
    "        rep_list = []\n",
    "        substitutes = [w for w,s in substitutes[:5]]\n",
    "        for sub in [target]+substitutes+['<mask>']:\n",
    "            start = offset-30 if trunck else 0\n",
    "            repeat_part = f\"{sent.text[start:offset-sent.start_char]}{sub}{sent.text[offset-sent.start_char+len(target):]}\"\n",
    "            rep_list.append(repeat_part)\n",
    "        return '.'.join(rep_list)\n",
    "\n",
    "    h0,_ = self.OA.sample(context_id)\n",
    "    # h0 = self.history[0]\n",
    "\n",
    "    offset = h0['offset']\n",
    "    mask_sentence_list = []\n",
    "    for sent in nlp(h0['text']).sents:\n",
    "        print(sent.start_char, offset ,sent.end_char)\n",
    "        if sent.start_char <= offset <sent.end_char:\n",
    "            sent_text = repeat_part(sent, h0['target'], h0['substitutes'])\n",
    "            mask_sentence_list.append(sent_text)\n",
    "        else:\n",
    "            mask_sentence_list.append(sent.text)\n",
    "\n",
    "    mask_text = ''.join(mask_sentence_list)\n",
    "    token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "\n",
    "    if token_lens>512:\n",
    "        mask_sentence_list = []\n",
    "        for sent in nlp(h0['text']).sents:\n",
    "            if sent.start_char <= offset <sent.end_char:\n",
    "                sent_text = repeat_part(sent, h0['target'], h0['substitutes'],True)\n",
    "                # print('-------------')\n",
    "                mask_sentence_list.append(sent_text)\n",
    "            else:\n",
    "                mask_sentence_list.append(sent.text)\n",
    "        mask_text = ''.join(mask_sentence_list)\n",
    "        token_lens = len(tokenizer(''.join(mask_text))['input_ids'])                \n",
    "    # words = [(token['token_str'],round(token['score'],3)) for token in self.mask_model(mask_text)]\n",
    "    return mask_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f31c0a99-ba06-4c0d-ae62-3de2c7da34d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Let’s go.”\\n            As we headed down the sidewalk, I said, “What is your name, anyway?”'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "h0['text'][h0['offset']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7fd005a-dc4a-4b37-bf68-6fd1f5605093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20 19\n",
      "20 20 43\n",
      "43 20 111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'“You’ve got a deal.Let’s go.”\\n            .off we’s go.”\\n            .allow’s go.”\\n            .we will’s go.”\\n            .enable’s go.”\\n            .live with’s go.”\\n            .<mask>’s go.”\\n            As we headed down the sidewalk, I said, “What is your name, anyway?”'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_option_words_by_llm(env,context_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4848b7ff-b2ab-4a7a-b558-6644c88b0cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': 'It was last February, after the winter break, that we moved in together. Now spring was back, under the concrete, and I could smell it even here.\\n            “Isn’t it an amazing night, Rache?',\n",
       "  'target': 'even',\n",
       "  'substitutes': [('still', 0.4),\n",
       "   ('as well as', 0.2),\n",
       "   ('so much as', 0.1),\n",
       "   ('much', 0.1),\n",
       "   ('in spite of', 0.0),\n",
       "   ('yet', 0.0),\n",
       "   ('despite', 0.0),\n",
       "   ('notwithstanding', 0.0),\n",
       "   ('indeed', 0.0),\n",
       "   ('actually', 0.0),\n",
       "   ('disregarding', 0.0),\n",
       "   ('more', 0.0),\n",
       "   ('yet all the', 0.0)],\n",
       "  'offset': 135},\n",
       " 'c:8449d1484b624c8db76ae3d9c60a000f677a244d')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.OA.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "0ec6bbc4-2192-449b-963a-dfde0704267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                   | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_142/1917932590.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 200/200 [18:37<00:00,  5.59s/it]\n"
     ]
    }
   ],
   "source": [
    "returns = 0\n",
    "action_list = []\n",
    "turns_list = []\n",
    "reward_list = []\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    context_id = test_env.OA.context_ids[i]\n",
    "    state, info = test_env.reset(context_id)\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    episode_returns = 0\n",
    "    for t in count():\n",
    "        action = select_action(state,eps_threshold=None)\n",
    "        action_list.append(action.item())\n",
    "        observation, reward, terminated, truncated, _ = test_env.step(action.item())\n",
    "        state = observation.reshape((1,-1))\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        episode_returns += reward\n",
    "        # returns += reward\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        if done:\n",
    "            turns_list.append(t)\n",
    "            reward_list.append(episode_returns)\n",
    "            # plot_durations()\n",
    "\n",
    "\n",
    "            turn = 0\n",
    "            for his in env.history:\n",
    "                space_num = 0 if turn%2==0 else (135-len(his.text))\n",
    "                role = \"User:\" if  turn%2==0 else  \"Bot:\"\n",
    "                # print(role)\n",
    "                # print(his.text)\n",
    "                # print('----------------------------------')\n",
    "                turn += 1\n",
    "            break\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "9a206ff2-7e06-4536-8f45-eae09192638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "695f4f0e-ac66-48fd-a6b0-7ce31c1db5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 919, 1: 16, 3: 21, 0: 13})"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "13494357-7186-4ac7-a1f5-3dd0510dcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "6ef6b0b9-7a14-4843-9833-b3fb9fc6a6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of occurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>options</th>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confirm</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more info</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no action</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           number of occurance\n",
       "options                    919\n",
       "confirm                     16\n",
       "more info                   21\n",
       "no action                   13"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_act = Counter(action_list) # = \n",
    "name_map = {0:'no action',1:'confirm',2:'options',3:'more info'}\n",
    "pd.DataFrame([data_act],index=['number of occurance']).rename(name_map,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "f70f76bb-0e1e-4fc6-a7dd-971d87fcb058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turns</th>\n",
       "      <th>Number of Occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   turns  Number of Occurrence\n",
       "0      5                   188\n",
       "1      2                     4\n",
       "2      3                     2\n",
       "3      1                     3\n",
       "4      4                     3"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame([Counter(turns_list)]).T.reset_index()\n",
    "df2.columns = ['turns','Number of Occurrence']\n",
    "df2['turns'] += 1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735458b7-9d8d-413e-a047-2e275cb36a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "16039882-513f-4eb2-9f22-b1c3c3f7a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0423d0f7-19db-48d2-95c4-a980273ce4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4036247594865046"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c83fc-a12d-47dd-a435-fb18daf8c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = origin_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afc7f6e2-6abf-40c1-88ad-588efc7773b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_id = random.choice(self.context_ids)\n",
    "context = self.contexts[context_id]['context']\n",
    "target = self.contexts[context_id]['targets'][0]\n",
    "target_text = target['target']\n",
    "substitutes = [(sub['substitute'],sub['label_score']) for sub in target['substitutes']]\n",
    "sorted_subs = sorted(substitutes,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55ffad1c-2582-46b8-94e3-1c1483af2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d38a4cd-c0bc-40f3-9a26-d657504ccfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.1000])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a617918-e081-4a3c-8b58-7ccea316b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_return = []\n",
    "len_avg = 10\n",
    "for i in range(len(return_list)-len_avg):\n",
    "    average_return.append(np.mean([s.item() for s in return_list[i:i + len_avg]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd4b046c-0d80-4bf4-be7a-472eb7053d24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_268/136110296.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturn_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.mean([s.item() for s in return_list[i:i+10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5101dc4a-8af9-4411-a084-fc42f316549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc207554-12b6-4aea-8d22-e32efc26c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d78b0368-9ada-42ee-9e74-3b11feb8201a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "00cabcfd-0895-4f2b-ae98-9c955fe3142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_part(sent,target,substitutes,trunck=False):\n",
    "    rep_list = []\n",
    "    substitutes = [w for w,s in substitutes[:5]]\n",
    "    for sub in [target]+substitutes+['<mask>']:\n",
    "        start = offset-30 if trunck else 0\n",
    "        repeat_part = f\"{sent.text[start:offset-sent.start_char]}{sub}{sent.text[offset-sent.start_char+len(target):]}\"\n",
    "        rep_list.append(repeat_part)\n",
    "    return '.'.join(rep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f0eeffd-4530-4993-97f0-c99033882847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f28f0698-a870-44de-9c8c-931402e76afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_origin_agent = OriginAgent(file_path='../data/swords/swords-v1.1_test.json.gz')\n",
    "test_env = environment.DialougeEnv(test_origin_agent,embedding_model,unmasker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8651b23c-b870-45ff-86b7-2ac8478b0e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 370/370 [00:34<00:00, 10.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for con in tqdm.tqdm(env.OA.context_ids):\n",
    "    state,info = env.reset(con)\n",
    "    h0 = env.history[0]\n",
    "    offset = h0['offset']\n",
    "    mask_sentence_list = []\n",
    "    for sent in nlp(h0['text']).sents:\n",
    "        if sent.start_char < offset <sent.end_char:\n",
    "            sent_text = repeat_part(sent, h0['target'], h0['substitutes'])\n",
    "            # print('-------------')\n",
    "            mask_sentence_list.append(sent_text)\n",
    "        else:\n",
    "            mask_sentence_list.append(sent.text)\n",
    "\n",
    "    mask_text = ''.join(mask_sentence_list)\n",
    "    token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "    token_lens, mask_text\n",
    "    \n",
    "    if token_lens>512:\n",
    "        mask_sentence_list = []\n",
    "        for sent in nlp(h0['text']).sents:\n",
    "            if sent.start_char < offset <sent.end_char:\n",
    "                sent_text = repeat_part(sent, h0['target'], h0['substitutes'],True)\n",
    "                # print('-------------')\n",
    "                mask_sentence_list.append(sent_text)\n",
    "            else:\n",
    "                mask_sentence_list.append(sent.text)\n",
    "        mask_text = ''.join(mask_sentence_list)\n",
    "        token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "        if token_lens>512:\n",
    "            print(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "681914b8-a4d2-4d2f-94df-a4ccfe7e11d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "The FBI cited a vivid conversation with Anissina's mother in\n",
      "which Tokhtakhounov assured her that even if her daughter \"falls,\n",
      "we will make sure she is No. 1.\"\n",
      "\n",
      "\n",
      "   After the Winter Olympics, a French judge, Marie-Reine Le\n",
      "Gougne, was suspended by the International Skating Union for not\n",
      "reporting pressure she said was put on her by Didier Gailhaguet,\n",
      "president of the French Skating Federation, to vote for the Russian\n",
      "pairs team.\n",
      "\n",
      "\n",
      "   \n",
      "-----------\n",
      "She later recanted and said that Canadian officials had\n",
      "pressured her.\n"
     ]
    }
   ],
   "source": [
    "for sent in nlp(h0['text']).sents:\n",
    "    print(\"-----------\")\n",
    "    print(sent)\n",
    "    print(sent)\n",
    "# print(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bee743a-345f-4b7f-bfd3-03744fb63efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.text[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2d9e29a-186d-4e98-b3e4-b48b3eb043cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \";1 W;2 e;3  ;4 w;5 e;6 r;7 e;8  ;9 a;10 l;11 l;12  ;13 a;14 p;15 p;16 a;17 l;18 l;"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(text[0:19]):\n",
    "    print(i,t,end=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecb0d3d8-2d9f-4daa-877c-910423c9f288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.start_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26eafd0f-24ee-43a5-8fcc-f05f4bd2dd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Span.as_doc>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.as_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "863497a7-1519-431b-adcf-1ffe8507f150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<environment.OriginAgent at 0x7fc5603b8b80>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c0ed589-045e-4fd3-ac03-6e1a18d55955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# 加载英文语言模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16c53a-1d45-4fd0-8fd8-e841a6fa6d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncat(text):\n",
    "    text_list = []\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b15f6c93-38ab-43c5-99b9-945c2560daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "034d4b53-60f4-44c3-b1ca-dce988626082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-------------------------------------\n",
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of the wise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of knowledge\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of advice\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of astuteness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of sageness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of enlightenment\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of expertise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of <mask>\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-----------wisdom--------------\n",
      "[('the wise', 0.6), ('knowledge', 0.5), ('advice', 0.5), ('astuteness', 0.5), ('sageness', 0.5), ('enlightenment', 0.4), ('expertise', 0.4), ('intelligence', 0.4), ('shrewdness', 0.4), ('wise thinking', 0.3), ('experience', 0.3), ('insight', 0.3), ('judiciousness', 0.3), ('clear thinking', 0.2), ('good judgment', 0.2), ('reason', 0.2), ('caution', 0.2), ('comprehension', 0.2), ('foresight', 0.2), ('discernment', 0.2), ('acumen', 0.2), ('perspicacity', 0.1), ('sanity', 0.1), ('prudence', 0.1), ('savvy', 0.1), ('sagacity', 0.1), ('horse sense', 0.0), ('common sense', 0.0), ('poise', 0.0), ('discrimination', 0.0), ('penetration', 0.0), ('gumption', 0.0), ('balance', 0.0), ('judgment', 0.0), ('solidity', 0.0), ('practicality', 0.0), ('savoir faire', 0.0), ('sophistication', 0.0), ('information', 0.0), ('circumspection', 0.0), ('pansophy', 0.0), ('sapience', 0.0), ('stability', 0.0), ('understanding', 0.0), ('a sage', 0.0), ('erudition', 0.0), ('learning', 0.0), ('brains', 0.0)]\n",
      "-------------------------\n",
      "[('wisdom', 0.575), ('knowledge', 0.056), ('advice', 0.051), ('inspiration', 0.029), ('confidence', 0.023)]\n",
      "-------------------------\n",
      "[('said', 0.411), ('says', 0.121), ('was', 0.071), ('replied', 0.035), ('answered', 0.029)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "mask_text_doc = nlp(h0.text)\n",
    "mask_text = ''\n",
    "# 遍历每个句子并打印\n",
    "for sentence in mask_text_doc.sents:\n",
    "    # print(sentence.text)\n",
    "    if h0.target in sentence.text:\n",
    "        words = [h0.tarnlp = spacy.load(\"en_core_web_sm\")get,*[w for w,score in h0.substitutes[:5]],'<mask>']\n",
    "        sub_sentence_text = \".\".join([sentence.text.replace(h0.target,w,1) for w in words])\n",
    "        mask_text += sub_sentence_text\n",
    "    else:\n",
    "        mask_text += sentence.text\n",
    "if len(tokenizer(mask_text)['input_ids'])>10:\n",
    "    mask_text = ''\n",
    "    # 遍历每个句子并打印\n",
    "    for sentence in mask_text_doc.sents:\n",
    "        # print(sentence.text)\n",
    "        if h0.target in sentence.text:\n",
    "            parts = sentence.text.split(\",\")\n",
    "            mask_idx = [i for i,p in enumerate(parts) if (h0.target in p)][0]\n",
    "            words = [h0.target,*[w for w,score in h0.substitutes[:7]],'<mask>']\n",
    "            sub_sentence_text = \",\".join([parts[mask_idx].replace(h0.target,w,1) for w in words])\n",
    "            parts[mask_idx] = sub_sentence_text\n",
    "            mask_text += ' '.join(parts)\n",
    "        else:\n",
    "            mask_text += sentence.text\n",
    "\n",
    "print(h0.text)\n",
    "print(\"-------------------------------------\")\n",
    "print(mask_text)\n",
    "print(f\"-----------{h0.target}--------------\")\n",
    "print(h0.substitutes)\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(mask_text)])\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(solo_mask)])\n",
    "\n",
    "len(tokenizer(h0.text)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35dabde9-234b-419a-be2a-ba1db0a9971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-------------------------------------\n",
      "list>   \n",
      "\n",
      "Words of sageness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of knowledge\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of astuteness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of <mask>\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of advice\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of the wise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of expertise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of enlightenment\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-----------wisdom--------------\n",
      "[('the wise', 0.6), ('knowledge', 0.5), ('advice', 0.5), ('astuteness', 0.5), ('sageness', 0.5), ('enlightenment', 0.4), ('expertise', 0.4), ('intelligence', 0.4), ('shrewdness', 0.4), ('wise thinking', 0.3), ('experience', 0.3), ('insight', 0.3), ('judiciousness', 0.3), ('clear thinking', 0.2), ('good judgment', 0.2), ('reason', 0.2), ('caution', 0.2), ('comprehension', 0.2), ('foresight', 0.2), ('discernment', 0.2), ('acumen', 0.2), ('perspicacity', 0.1), ('sanity', 0.1), ('prudence', 0.1), ('savvy', 0.1), ('sagacity', 0.1), ('horse sense', 0.0), ('common sense', 0.0), ('poise', 0.0), ('discrimination', 0.0), ('penetration', 0.0), ('gumption', 0.0), ('balance', 0.0), ('judgment', 0.0), ('solidity', 0.0), ('practicality', 0.0), ('savoir faire', 0.0), ('sophistication', 0.0), ('information', 0.0), ('circumspection', 0.0), ('pansophy', 0.0), ('sapience', 0.0), ('stability', 0.0), ('understanding', 0.0), ('a sage', 0.0), ('erudition', 0.0), ('learning', 0.0), ('brains', 0.0)]\n",
      "-------------------------\n",
      "[('wisdom', 0.634), ('knowledge', 0.036), ('confidence', 0.028), ('inspiration', 0.02), ('patience', 0.016)]\n",
      "-------------------------\n",
      "[('said', 0.411), ('says', 0.121), ('was', 0.071), ('replied', 0.035), ('answered', 0.029)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "mask_text_doc = nlp(h0.text)\n",
    "mask_text = ''\n",
    "# 遍历每个句子并打印\n",
    "for sentence in mask_text_doc.sents:\n",
    "    # print(sentence.text)\n",
    "    if h0.target in sentence.text:\n",
    "        words = [h0.target,*[w for w,score in h0.substitutes[:7]],'<mask>']\n",
    "        random.shuffle(words)\n",
    "        sub_sentence_text = \".\".join([sentence.text.replace(h0.target,w,1) for w in words])\n",
    "        mask_text += sub_sentence_text\n",
    "    else:\n",
    "        mask_text += sentence.text\n",
    "if len(tokenizer(mask_text)['input_ids'])>512:\n",
    "    mask_text = ''\n",
    "    # 遍历每个句子并打印\n",
    "    for sentence in mask_text_doc.sents:\n",
    "        # print(sentence.text)\n",
    "        if h0.target in sentence.text:\n",
    "            parts = sentence.text.split(\",\")\n",
    "            mask_idx = [i for i,p in enumerate(parts) if (h0.target in p)][0]\n",
    "            words = [h0.target,*[w for w,score in h0.substitutes[:5]],'<mask>']\n",
    "            random.shuffle(words)\n",
    "            sub_sentence_text = \",\".join([parts[mask_idx].replace(h0.target,w,1) for w in words])\n",
    "            parts[mask_idx] = sub_sentence_text\n",
    "            mask_text += ' '.join(parts)\n",
    "        else:\n",
    "            mask_text += sentence.text\n",
    "\n",
    "print(h0.text)\n",
    "print(\"-------------------------------------\")\n",
    "print(mask_text)\n",
    "print(f\"-----------{h0.target}--------------\")\n",
    "print(h0.substitutes)\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(mask_text)])\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(solo_mask)])\n",
    "\n",
    "len(tokenizer(h0.text)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9151c40d-be9b-4906-92bb-b90334a05081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c4ad17a1-d1c4-4cb3-98cb-b8d9130fcee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['listless', '<mask>', 'lifeless', 'empty', 'dead', 'flat', 'deathly']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16ef9b55-9816-4030-9c30-5e09ba7162c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(mask_text)['input_ids'])>512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8cf6f4-2f01-4113-a3db-cf4aa1d6626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if there is target in the top masks :\n",
    "    that means LLM could predict well, the ambiagrous is less\n",
    "    \n",
    "    No action\n",
    "\n",
    "if top mask's score is high ,and in':\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "96753649-2f02-41e3-a3ab-aa6fcafec692",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 31 3.77\n",
      "276 77 3.58\n",
      "142 41 3.46\n",
      "404 106 3.81\n",
      "258 70 3.69\n",
      "129 36 3.58\n",
      "89 20 4.45\n",
      "358 96 3.73\n",
      "294 61 4.82\n",
      "313 81 3.86\n",
      "426 119 3.58\n",
      "213 41 5.2\n",
      "292 65 4.49\n",
      "152 29 5.24\n",
      "204 62 3.29\n",
      "251 59 4.25\n",
      "425 106 4.01\n",
      "266 65 4.09\n",
      "280 61 4.59\n",
      "321 67 4.79\n",
      "65 16 4.06\n",
      "375 84 4.46\n",
      "546 116 4.71\n",
      "194 45 4.31\n",
      "148 30 4.93\n",
      "183 42 4.36\n",
      "134 31 4.32\n",
      "207 48 4.31\n",
      "510 105 4.86\n",
      "297 58 5.12\n",
      "277 64 4.33\n",
      "242 53 4.57\n",
      "219 46 4.76\n",
      "243 59 4.12\n",
      "369 87 4.24\n",
      "420 76 5.53\n",
      "226 60 3.77\n",
      "296 73 4.05\n",
      "131 35 3.74\n",
      "111 26 4.27\n",
      "192 45 4.27\n",
      "164 42 3.9\n",
      "93 28 3.32\n",
      "446 106 4.21\n",
      "336 96 3.5\n",
      "420 76 5.53\n",
      "245 61 4.02\n",
      "258 70 3.69\n",
      "290 64 4.53\n",
      "154 34 4.53\n",
      "293 69 4.25\n",
      "197 52 3.79\n",
      "224 58 3.86\n",
      "195 44 4.43\n",
      "153 35 4.37\n",
      "112 27 4.15\n",
      "129 36 3.58\n",
      "386 93 4.15\n",
      "226 47 4.81\n",
      "270 69 3.91\n",
      "343 77 4.45\n",
      "422 113 3.73\n",
      "171 45 3.8\n",
      "540 134 4.03\n",
      "335 73 4.59\n",
      "259 63 4.11\n",
      "293 69 4.25\n",
      "103 27 3.81\n",
      "185 43 4.3\n",
      "153 35 4.37\n",
      "325 79 4.11\n",
      "277 65 4.26\n",
      "73 20 3.65\n",
      "433 109 3.97\n",
      "245 61 4.02\n",
      "354 74 4.78\n",
      "129 36 3.58\n",
      "376 98 3.84\n",
      "232 58 4.0\n",
      "595 132 4.51\n",
      "267 52 5.13\n",
      "475 96 4.95\n",
      "154 34 4.53\n",
      "201 50 4.02\n",
      "259 63 4.11\n",
      "83 23 3.61\n",
      "112 22 5.09\n",
      "187 41 4.56\n",
      "327 89 3.67\n",
      "143 41 3.49\n",
      "480 108 4.44\n",
      "380 94 4.04\n",
      "391 89 4.39\n",
      "166 36 4.61\n",
      "440 118 3.73\n",
      "160 41 3.9\n",
      "123 29 4.24\n",
      "141 30 4.7\n",
      "181 40 4.53\n",
      "392 107 3.66\n"
     ]
    }
   ],
   "source": [
    "l0s = 0\n",
    "l1s=0\n",
    "for i in  range(100):\n",
    "    state,info = test_env.reset()\n",
    "    h0 = test_env.history[0]\n",
    "    l1 = len(tokenizer(h0.text)['input_ids'])\n",
    "    l0 = len(h0.text)\n",
    "    l0s+=l0\n",
    "    l1s+=l1\n",
    "    print(l0,l1,round(l0/l1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "5233ed7c-4d59-46a6-bd24-9fe5ea2e2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2502\n",
      "2502\n",
      "2502\n",
      "2502\n",
      "2502\n"
     ]
    }
   ],
   "source": [
    "state,info = test_env.reset()\n",
    "h0 = test_env.history[0]\n",
    "solo_mask = h0.text.replace(h0.target,'<mask>',1)\n",
    "mask_text = ''\n",
    "for i,(word,score) in enumerate(h0.substitutes[:5]):\n",
    "    print(len(h0.text)*6)\n",
    "    if len(h0.text)*6<2100:\n",
    "        text = h0.text\n",
    "    else:\n",
    "        subtract_len = len(h0.text)-350\n",
    "        index = h0.text.index(h0.target)\n",
    "        post_sub_index = max(len(h0.text)-subtract_len,index+20)\n",
    "        if i%2==0:\n",
    "            pre_sub_index = min(0+subtract_len,index-20)\n",
    "            text = h0.text[pre_sub_index:]\n",
    "    if len(tokenizer(mask_text+text+solo_mask)['input_ids'])>512:\n",
    "        break\n",
    "    mask_text += text\n",
    "mask_text  += solo_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "82fe1ec7-6e32-4a45-a3af-dd1ac4c72bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.The problem was that I have trouble distinguishing between\\n                    compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, <mask> only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.\""
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "a34ff1be-25f3-450e-a345-2f3e42b1f199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2084"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "92cce71c-9380-4bfb-bf49-d7d497adef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "acef1d04-5afd-491b-8882-a39718b6a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "07d3f2ac-4b8b-4503-9e36-ef8473b70c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "400e399a-712b-4bc1-878c-67fa88ce211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_text = (text*12)[:-23]+ '<mask>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "cb1ea2f5-1ae4-4cdb-809d-85a6e1e6a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer(m_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "d36a8682-3794-460b-9f02-ee20fc081ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "6f7cd642-860d-4a5d-a5f6-c5af65e6e2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8441550135612488,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,'},\n",
       " {'score': 0.11659591645002365,\n",
       "  'token': 4,\n",
       "  'token_str': ',',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,,'},\n",
       " {'score': 0.008581217378377914,\n",
       "  'token': 27,\n",
       "  'token_str': '...',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,...'},\n",
       " {'score': 0.0016685021109879017,\n",
       "  'token': 122880,\n",
       "  'token_str': 'More',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,More'},\n",
       " {'score': 0.001654961844906211,\n",
       "  'token': 19659,\n",
       "  'token_str': 'As',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,As'}]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(m_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f43a9a71-cd1b-4ce5-be49-376b1d21795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2099.2"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512*4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7e0f3d33-64be-455f-b6d8-9e29feb2848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350.0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2100/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a4836d14-a1ea-4461-a11c-476147523d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.199420569773056"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l0s/l1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "11799913-5c24-48ab-91a4-68674483d867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1559"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a3cf02aa-f675-42ed-bab0-2c43ef855d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 387)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0.text.index(h0.target),len(h0.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6e6f55e4-1516-45d2-8fd6-6fb2aaa3c438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512 - len(h0.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6faa4248-9c78-45b0-92f2-d30372e16b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3b4cd41-1196-4772-a0e5-547df069f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3f9ee-abf3-49c9-93ea-239e125c6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.AutoModelForMaskedLM("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3658acbe-810b-4309-8b68-b44b1ee0792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbe8242b-0ea8-499c-a7f0-e1481ceec8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe3d9fe6-ff6e-465b-b5f5-8ca8c458e9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea3f62a5-5adf-4a81-87a3-26692355288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# forward pass\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b19e111f-be61-47dc-b9c9-5f1cc09850f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ 6.4861e+01,  1.6882e-02,  3.7656e+01,  ...,  2.1584e+01,\n",
       "           1.4380e+01,  1.8790e+01],\n",
       "         [ 2.7493e+01, -1.4091e+00,  6.4847e+01,  ...,  4.0234e+01,\n",
       "           1.6296e+01,  3.0925e+01],\n",
       "         [ 1.9604e+01, -1.2597e+00,  4.8981e+01,  ...,  3.5830e+01,\n",
       "           1.7145e+01,  2.7173e+01],\n",
       "         ...,\n",
       "         [ 2.2920e+01, -1.4657e+00,  5.1211e+01,  ...,  3.8495e+01,\n",
       "           1.6508e+01,  2.7687e+01],\n",
       "         [ 2.8598e+01, -1.2868e+00,  6.7706e+01,  ...,  4.4857e+01,\n",
       "           1.8004e+01,  3.5004e+01],\n",
       "         [ 4.4955e+01, -2.1554e-01,  4.9643e+01,  ...,  2.8253e+01,\n",
       "           1.6841e+01,  2.3610e+01]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5db2c37a-a78d-49d1-9a6b-f9f3ab131b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForMaskedLM"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e735b-0ede-4ec2-be41-1da2b2ffca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    predictions = outputs.logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "65983169-e35a-422e-8062-6df8d1f9398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 16:07:54.349083: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-17 16:07:54.349119: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import FillMaskPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a8f49495-ce6e-4f29-80ea-6a75bbb84950",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EmbeddingModel' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142/1315868084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFillMaskPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, image_processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m     ):\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_framework_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EmbeddingModel' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "mask_pipeline = FillMaskPipeline(model=env.model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d0b98934-a79b-4ddd-b4a9-5685596f5cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.07687385380268097,\n",
       "  'token': 34923,\n",
       "  'token_str': 'beautiful',\n",
       "  'sequence': 'this is a beautiful car'},\n",
       " {'score': 0.04615773260593414,\n",
       "  'token': 29681,\n",
       "  'token_str': 'sports',\n",
       "  'sequence': 'this is a sports car'},\n",
       " {'score': 0.03222648799419403,\n",
       "  'token': 54704,\n",
       "  'token_str': 'classic',\n",
       "  'sequence': 'this is a classic car'},\n",
       " {'score': 0.031460631638765335,\n",
       "  'token': 6782,\n",
       "  'token_str': 'great',\n",
       "  'sequence': 'this is a great car'},\n",
       " {'score': 0.030774081125855446,\n",
       "  'token': 26267,\n",
       "  'token_str': 'nice',\n",
       "  'sequence': 'this is a nice car'}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_pipeline(\"this is a <mask> car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db5c451f-564e-43aa-aeb2-6dfaa73e9c45",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaModel(\n",
       "  (embeddings): XLMRobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): XLMRobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): XLMRobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a481806c-5179-4fdf-aaec-d99a73a87260",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForMaskedLM(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): XLMRobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=250002, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ace047-ea17-4956-9370-fec2002d8018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
