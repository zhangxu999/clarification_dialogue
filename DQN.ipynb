{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce38283-09c8-447a-9693-bde6760a5848",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1386/1432153755.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/zhangdapao5130/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/zhangdapao5130/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import gymnasium as gym\n",
    "from imp import reload\n",
    "\n",
    "import rl_dqn\n",
    "import environment\n",
    "import embedding\n",
    "import rl_utils\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "from rl_dqn import ReplayMemory, DQN, Transition, RLModel\n",
    "from embedding import EmbeddingModel\n",
    "from environment import Dataset, DialougeEnv, User, Agent\n",
    "import rl_dqn\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "reload(embedding)\n",
    "from embedding import EmbeddingModel\n",
    "\n",
    "embedding_model = EmbeddingModel(device)\n",
    "\n",
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='xlm-roberta-base',framework='pt', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "100ce60b-de12-4398-9f04-04d572b68057",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/zhangdapao5130/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/zhangdapao5130/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/zhangdapao5130/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/zhangdapao5130/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "reload(rl_dqn)\n",
    "reload(environment)\n",
    "reload(embedding)\n",
    "\n",
    "\n",
    "import environment\n",
    "reload(environment)\n",
    "\n",
    "test_data = environment.Dataset('data/swords-v1.1_dev.json.gz')\n",
    "train_data = environment.Dataset('data/swords-v1.1_test.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7431a43e-f1ca-40c5-8217-61a11ae060c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/zhangdapao5130/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/zhangdapao5130/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "reload(environment)\n",
    "reload(rl_utils)\n",
    "reload(constant)\n",
    "\n",
    "test_env = environment.DialougeEnv(test_data,embedding_model, unmasker,device,Debug=False)\n",
    "train_env = environment.DialougeEnv(train_data, embedding_model, unmasker,device,Debug=FaL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "73ee14b5-6f7a-4b10-ad04-a45d9673fe3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "radio radio\n",
      "[('broadcasting', 0.7), ('am-fm', 0.6), ('stereo', 0.4), ('transmission', 0.2), ('airwave', 0.2), ('shortwave', 0.1), ('receiver', 0.1), ('radiotelephone', 0.0), ('telegraphy', 0.0), ('medium', 0.0)]\n",
      "[('radio', 0.511), ('television', 0.078), ('broadcast', 0.031), ('TV', 0.025), ('internet', 0.02), ('sound', 0.016), ('audio', 0.014), ('cable', 0.011), ('recording', 0.01), ('tv', 0.008)]\n"
     ]
    }
   ],
   "source": [
    "reload(rl_dqn)\n",
    "rl_model = rl_dqn.RLModel(train_env,test_env, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b0c92e42-6bef-4e35-ab5c-e5d95fc515c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "gave gave\n",
      "[('surrender', 0.6), ('relinquish', 0.5), ('donate', 0.4), ('cede', 0.4), ('yield', 0.2), ('remit', 0.2), ('leave', 0.2), ('concede', 0.2), ('let', 0.2), ('award', 0.1)]\n",
      "[('give', 0.566), ('take', 0.088), ('hold', 0.026), ('keep', 0.018), ('leave', 0.017), ('gave', 0.011), ('save', 0.011), ('sell', 0.009), ('buy', 0.007), ('end', 0.006)]\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word gave is not clear to me. Could you please provide me more context?', 'option_words': ['give'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word gave is not clear to me. Do you mean something like take by this?', 'option_words': ['take'], 'role': 'bot'}\n",
      "{'reward': -2.5, 'terminated': False, 'text': 'No, it is not', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -2, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word gave is not clear to me. Do you mean something like hold by this?', 'option_words': ['hold'], 'role': 'bot'}\n",
      "{'reward': -2.5, 'terminated': False, 'text': 'No, it is not', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -2, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word gave is not clear to me. Could you please provide me more context?', 'option_words': ['keep'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word gave is not clear to me. Could you please provide me more context?', 'option_words': ['leave'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': True, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:   3%|▎         | 1/30 [00:03<01:35,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "partnership partnership\n",
      "[('combination', 0.5), ('cooperative', 0.5), ('affiliation', 0.5), ('union', 0.5), ('hookup', 0.5), ('corporation', 0.5), ('cooperation', 0.5), ('conjunction', 0.5), ('team', 0.5), ('partner', 0.4)]\n",
      "[('partnership', 0.152), ('company', 0.042), ('union', 0.034), ('division', 0.023), ('association', 0.022), ('affiliate', 0.017), ('exchange', 0.015), ('partner', 0.015), ('service', 0.014), ('joint', 0.014)]\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word partnership is not clear to me. Do you mean something like partnership by this?', 'option_words': ['partnership'], 'role': 'bot'}\n",
      "{'reward': 4.5, 'terminated': True, 'text': 'Yes, it is', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 2, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:   7%|▋         | 2/30 [00:03<00:46,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "get get\n",
      "[('move', 0.8), ('pull', 0.7), ('leave', 0.3), ('advance', 0.3), ('come', 0.3), ('clear', 0.3), ('go', 0.3), ('cop', 0.2), ('transfer', 0.2), ('urge', 0.1)]\n",
      "[('get', 0.189), ('move', 0.13), ('go', 0.128), ('stay', 0.072), ('come', 0.061), ('leave', 0.049), ('walk', 0.022), ('run', 0.021), ('fall', 0.019), ('break', 0.017)]\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word get is not clear to me. Do you mean something like get by this?', 'option_words': ['get'], 'role': 'bot'}\n",
      "{'reward': 4.5, 'terminated': True, 'text': 'Yes, it is', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 2, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  10%|█         | 3/30 [00:04<00:34,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "shares share\n",
      "[('stock', 0.8), ('portion', 0.3), ('claim', 0.2), ('part', 0.2), ('chunk', 0.2), ('dose', 0.2), ('lot', 0.2), ('percentage', 0.2), ('contribution', 0.2), ('dividend', 0.2)]\n",
      "[('share', 0.087), ('dividend', 0.084), ('margin', 0.043), ('total', 0.037), ('stock', 0.03), ('value', 0.027), ('part', 0.021), ('balance', 0.02), ('half', 0.015), ('capital', 0.014)]\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word shares is not clear to me. Do you mean something like share by this?', 'option_words': ['share'], 'role': 'bot'}\n",
      "{'reward': 4.5, 'terminated': True, 'text': 'Yes, it is', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 2, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  13%|█▎        | 4/30 [00:05<00:27,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "use use\n",
      "[('try', 0.9), ('utilize', 0.8), ('apply', 0.6), ('employ', 0.5), ('attempt', 0.4), ('expend', 0.4), ('implement', 0.3), ('operate', 0.3), ('exercise', 0.3), ('handle', 0.2)]\n",
      "[('use', 0.231), ('employ', 0.198), ('apply', 0.185), ('try', 0.131), ('utilize', 0.069), ('attempt', 0.019), ('do', 0.01), ('perform', 0.008), ('test', 0.008), ('implement', 0.007)]\n",
      "-------------------\n",
      "{'action': 0, 'text': \"I'm pretty sure of the meaning of the word use . \", 'option_words': ['use'], 'role': 'bot'}\n",
      "{'reward': 5.5, 'terminated': True, 'text': '', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 3, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  17%|█▋        | 5/30 [00:05<00:22,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "walls wall\n",
      "[('paneling', 0.4), ('sidewall', 0.4), ('divider', 0.3), ('panel', 0.3), ('board', 0.3), ('partition', 0.3), ('restriction', 0.2), ('fortification', 0.2), ('blockade', 0.2), ('side', 0.2)]\n",
      "[('wall', 0.096), ('floor', 0.06), ('furniture', 0.058), ('door', 0.045), ('window', 0.03), ('panel', 0.029), ('frame', 0.023), ('light', 0.021), ('paint', 0.017), ('decor', 0.014)]\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word walls is not clear to me. Do you mean something like wall by this?', 'option_words': ['wall'], 'role': 'bot'}\n",
      "{'reward': 4.5, 'terminated': True, 'text': 'Yes, it is', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 2, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  20%|██        | 6/30 [00:06<00:17,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "person person\n",
      "[('individual', 0.7), ('human', 0.6), ('personality', 0.5), ('body', 0.5), ('figure', 0.5), ('character', 0.5), ('man', 0.5), ('celebrity', 0.4), ('creature', 0.4), ('woman', 0.4)]\n",
      "[('person', 0.571), ('celebrity', 0.041), ('individual', 0.04), ('character', 0.035), ('woman', 0.033), ('man', 0.027), ('figure', 0.024), ('persona', 0.016), ('artist', 0.012), ('guy', 0.008)]\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word person is not clear to me. Could you please provide me more context?', 'option_words': ['person'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'it is obviously, but I will try explain it too', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word person is not clear to me. Could you please provide me more context?', 'option_words': ['celebrity'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word person is not clear to me. Do you mean something like individual,character,woman by this?', 'option_words': ['individual', 'character', 'woman'], 'role': 'bot'}\n",
      "{'reward': 3.5, 'terminated': True, 'text': 'individual', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 1, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  23%|██▎       | 7/30 [00:07<00:22,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "thought thought\n",
      "[('guess', 0.7), ('reckon', 0.6), ('consider', 0.6), ('judge', 0.5), ('know', 0.5), ('believe', 0.4), ('determine', 0.4), ('realize', 0.4), ('assume', 0.4), ('sense', 0.4)]\n",
      "[('think', 0.28), ('thought', 0.179), ('suppose', 0.124), ('know', 0.092), ('guess', 0.08), ('doubt', 0.04), ('believe', 0.027), ('consider', 0.019), ('knew', 0.017), ('feel', 0.015)]\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word thought is not clear to me. Do you mean something like think,thought,suppose by this?', 'option_words': ['think', 'thought', 'suppose'], 'role': 'bot'}\n",
      "{'reward': 3.5, 'terminated': True, 'text': 'thought', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 1, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  27%|██▋       | 8/30 [00:08<00:17,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "thoughts thought\n",
      "[('thinking', 0.5), ('mindwork', 0.5), ('rumination', 0.4), ('introspection', 0.4), ('rationalizing', 0.4), ('deliberation', 0.4), ('hypothesis', 0.4), ('attentiveness', 0.4), ('contemplation', 0.3), ('reflection', 0.3)]\n",
      "[('and', 0.234), ('2', 0.018), ('4', 0.018), ('5', 0.018), ('etc', 0.017), ('3', 0.017), ('1', 0.012), ('6', 0.011), ('-', 0.01), ('and', 0.009)]\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word thoughts is not clear to me. Could you please provide me more context?', 'option_words': ['and'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 0, 'text': \"I'm pretty sure of the meaning of the word thoughts . \", 'option_words': ['2'], 'role': 'bot'}\n",
      "{'reward': -3.5, 'terminated': True, 'text': ' you misunderstdood my words, I mean...', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -3, 'length_penalty': 0.5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  30%|███       | 9/30 [00:09<00:20,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "ugly ugly\n",
      "[('unpleasant', 0.9), ('unattractive', 0.9), ('bad-looking', 0.9), ('unsightly', 0.8), ('repulsive', 0.8), ('uncomely', 0.7), ('disfigured', 0.7), ('grotesque', 0.7), ('hideous', 0.7), ('gross', 0.6)]\n",
      "[('sexy', 0.026), ('...', 0.024), ('arrogant', 0.023), ('weird', 0.022), ('cute', 0.021), ('...', 0.018), ('crazy', 0.018), ('funny', 0.016), ('attractive', 0.015), ('dramatic', 0.015)]\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word ugly is not clear to me. Do you mean something like sexy by this?', 'option_words': ['sexy'], 'role': 'bot'}\n",
      "{'reward': -2.5, 'terminated': False, 'text': 'No, it is not', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -2, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word ugly is not clear to me. Do you mean something like ... by this?', 'option_words': ['...'], 'role': 'bot'}\n",
      "{'reward': -2.5, 'terminated': False, 'text': 'No, it is not', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -2, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word ugly is not clear to me. Do you mean something like arrogant by this?', 'option_words': ['arrogant'], 'role': 'bot'}\n",
      "{'reward': -2.5, 'terminated': False, 'text': 'No, it is not', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -2, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word ugly is not clear to me. Do you mean something like weird,cute,... by this?', 'option_words': ['weird', 'cute', '...'], 'role': 'bot'}\n",
      "{'reward': -1.5, 'terminated': False, 'text': 'none of these', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -1, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word ugly is not clear to me. Could you please provide me more context?', 'option_words': ['crazy'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': True, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  33%|███▎      | 10/30 [00:11<00:27,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "move move\n",
      "[('proceed', 0.7), ('go', 0.7), ('enter', 0.5), ('travel', 0.5), ('step', 0.5), ('relocate', 0.5), ('migrate', 0.4), ('transfer', 0.4), ('run', 0.4), ('push', 0.4)]\n",
      "[('fall', 0.16), ('enter', 0.088), ('walk', 0.069), ('go', 0.05), ('break', 0.043), ('get', 0.038), ('move', 0.037), ('journey', 0.028), ('return', 0.024), ('turn', 0.02)]\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word move is not clear to me. Could you please provide me more context?', 'option_words': ['fall'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word move is not clear to me. Do you mean something like enter,walk,go by this?', 'option_words': ['enter', 'walk', 'go'], 'role': 'bot'}\n",
      "{'reward': 3.5, 'terminated': True, 'text': 'enter,go', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 1, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  37%|███▋      | 11/30 [00:12<00:22,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "responsibility responsibility\n",
      "[('accountability', 0.8), ('credit', 0.6), ('blameworthiness', 0.5), ('culpability', 0.5), ('blame', 0.5), ('fault', 0.4), ('duty', 0.4), ('obligation', 0.4), ('answerability', 0.4), ('dependability', 0.4)]\n",
      "[('responsibility', 0.862), ('credit', 0.122), ('charge', 0.002), ('risk', 0.001), ('responsible', 0.001), ('care', 0.001), ('fault', 0.001), ('consequence', 0.001), ('judgment', 0.0), ('action', 0.0)]\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word responsibility is not clear to me. Do you mean something like responsibility,credit,charge by this?', 'option_words': ['responsibility', 'credit', 'charge'], 'role': 'bot'}\n",
      "{'reward': 3.5, 'terminated': True, 'text': 'responsibility,credit', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 1, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  40%|████      | 12/30 [00:13<00:18,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "gray gray\n",
      "[('grey', 0.7), ('granite', 0.5), ('charcoal', 0.4), ('clouded', 0.4), ('smoky', 0.4), ('silvered', 0.3), ('ash', 0.3), ('silver', 0.3), ('ashen', 0.3), ('slate', 0.3)]\n",
      "[('black', 0.139), ('brown', 0.082), ('green', 0.072), ('white', 0.067), ('blue', 0.057), ('red', 0.048), ('pink', 0.04), ('dark', 0.038), ('yellow', 0.03), ('light', 0.027)]\n",
      "-------------------\n",
      "{'action': 0, 'text': \"I'm pretty sure of the meaning of the word gray . \", 'option_words': ['black'], 'role': 'bot'}\n",
      "{'reward': -3.5, 'terminated': True, 'text': ' you misunderstdood my words, I mean...', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -3, 'length_penalty': 0.5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  43%|████▎     | 13/30 [00:13<00:15,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "blow blow\n",
      "[('botch', 0.8), ('squander', 0.7), ('spoil', 0.7), ('ruin', 0.7), ('wreck', 0.7), ('waste', 0.6), ('lose', 0.6), ('foil', 0.5), ('miss', 0.5), ('fail', 0.5)]\n",
      "[('break', 0.097), ('destroy', 0.093), ('hurt', 0.056), ('kill', 0.035), ('burn', 0.032), ('crush', 0.03), ('damage', 0.022), ('sell', 0.02), ('attack', 0.018), ('ruin', 0.018)]\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word blow is not clear to me. Could you please provide me more context?', 'option_words': ['break'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word blow is not clear to me. Could you please provide me more context?', 'option_words': ['destroy'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word blow is not clear to me. Do you mean something like hurt by this?', 'option_words': ['hurt'], 'role': 'bot'}\n",
      "{'reward': -2.5, 'terminated': False, 'text': 'No, it is not', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -2, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word blow is not clear to me. Could you please provide me more context?', 'option_words': ['kill'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word blow is not clear to me. Could you please provide me more context?', 'option_words': ['burn'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': True, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  47%|████▋     | 14/30 [00:15<00:19,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "cleared cleared\n",
      "[('pas', 0.4), ('approve', 0.4), ('receive', 0.2), ('wipe', 0.2), ('eliminate', 0.2), ('relieve', 0.2), ('empty', 0.2), ('brighten', 0.1), ('vindicate', 0.1), ('cleanse', 0.1)]\n",
      "[('pas', 0.102), ('accept', 0.084), ('cancel', 0.076), ('end', 0.047), ('close', 0.033), ('exit', 0.03), ('withdraw', 0.023), ('leave', 0.022), ('ignore', 0.021), ('suspend', 0.021)]\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word cleared is not clear to me. Do you mean something like pas by this?', 'option_words': ['pas'], 'role': 'bot'}\n",
      "{'reward': 4.5, 'terminated': True, 'text': 'Yes, it is', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 2, 'length_penalty': 0.5, 'find_subs': 3}}\n",
      "#################################################################\n",
      "Published Published\n",
      "[('print', 0.7), ('issue', 0.4), ('circulate', 0.4), ('publicize', 0.4), ('produce', 0.4), ('broadcast', 0.3), ('spotlight', 0.2), ('disclose', 0.2), ('advertise', 0.2), ('declare', 0.2)]\n",
      "[('published', 0.212), ('produced', 0.09), ('publish', 0.088), ('print', 0.08), ('issue', 0.069), ('produce', 0.052), ('Published', 0.033), ('publication', 0.016), ('released', 0.012), ('release', 0.012)]\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word Published is not clear to me. Do you mean something like published,produced,publish by this?', 'option_words': ['published', 'produced', 'publish'], 'role': 'bot'}\n",
      "{'reward': -1.5, 'terminated': False, 'text': 'none of these', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -1, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 0, 'text': \"I'm pretty sure of the meaning of the word Published . \", 'option_words': ['print'], 'role': 'bot'}\n",
      "{'reward': -3.5, 'terminated': True, 'text': ' you misunderstdood my words, I mean...', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -3, 'length_penalty': 0.5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  53%|█████▎    | 16/30 [00:16<00:12,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "together together\n",
      "[('together', 1.0), ('simultaneously', 0.6), ('jointly', 0.5), ('mutually', 0.4), ('synchronically', 0.4), ('conjointly', 0.4), ('concurrently', 0.3), ('collectively', 0.3), ('pair', 0.3), ('consecutively', 0.2)]\n",
      "[('together', 0.195), ('then', 0.082), ('Then', 0.046), ('--', 0.038), (',', 0.03), ('again', 0.024), ('-', 0.017), ('each', 0.013), ('immediately', 0.01), ('now', 0.009)]\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word together is not clear to me. Do you mean something like together,then,Then by this?', 'option_words': ['together', 'then', 'Then'], 'role': 'bot'}\n",
      "{'reward': 3.5, 'terminated': True, 'text': 'together', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 1, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  57%|█████▋    | 17/30 [00:17<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "brief brief\n",
      "[('small', 0.8), ('short', 0.8), ('tiny', 0.7), ('quick', 0.6), ('little', 0.5), ('abrupt', 0.3), ('succinct', 0.3), ('fast', 0.3), ('concise', 0.3), ('transitory', 0.3)]\n",
      "[('big', 0.338), ('sweet', 0.079), ('large', 0.065), ('long', 0.048), ('hard', 0.03), ('heavy', 0.022), ('small', 0.02), ('medium', 0.02), ('huge', 0.015), ('short', 0.015)]\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word brief is not clear to me. Do you mean something like big by this?', 'option_words': ['big'], 'role': 'bot'}\n",
      "{'reward': -2.5, 'terminated': False, 'text': 'No, it is not', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -2, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word brief is not clear to me. Could you please provide me more context?', 'option_words': ['sweet'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word brief is not clear to me. Could you please provide me more context?', 'option_words': ['large'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word brief is not clear to me. Do you mean something like long,hard,heavy by this?', 'option_words': ['long', 'hard', 'heavy'], 'role': 'bot'}\n",
      "{'reward': -1.5, 'terminated': False, 'text': 'none of these', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -1, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word brief is not clear to me. Do you mean something like small by this?', 'option_words': ['small'], 'role': 'bot'}\n",
      "{'reward': 4.5, 'terminated': True, 'text': 'Yes, it is', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 2, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  60%|██████    | 18/30 [00:20<00:15,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "thoughts thought\n",
      "[('thinking', 0.5), ('mindwork', 0.5), ('rumination', 0.4), ('introspection', 0.4), ('rationalizing', 0.4), ('deliberation', 0.4), ('hypothesis', 0.4), ('attentiveness', 0.4), ('contemplation', 0.3), ('reflection', 0.3)]\n",
      "[('and', 0.234), ('2', 0.018), ('4', 0.018), ('5', 0.018), ('etc', 0.017), ('3', 0.017), ('1', 0.012), ('6', 0.011), ('-', 0.01), ('and', 0.009)]\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word thoughts is not clear to me. Could you please provide me more context?', 'option_words': ['and'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 0, 'text': \"I'm pretty sure of the meaning of the word thoughts . \", 'option_words': ['2'], 'role': 'bot'}\n",
      "{'reward': -3.5, 'terminated': True, 'text': ' you misunderstdood my words, I mean...', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -3, 'length_penalty': 0.5}}\n",
      "#################################################################\n",
      "nice nice\n",
      "[('pleasant', 0.8), ('friendly', 0.7), ('kind', 0.7), ('lovely', 0.7), ('cordial', 0.6), ('delightful', 0.6), ('good', 0.6), ('amiable', 0.6), ('well-mannered', 0.6), ('kindly', 0.6)]\n",
      "[('nice', 0.244), ('pleasant', 0.122), ('kind', 0.117), ('cordial', 0.067), ('friendly', 0.043), ('good', 0.025), ('very', 0.021), ('sweet', 0.018), ('\"', 0.016), ('lovely', 0.016)]\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word nice is not clear to me. Do you mean something like nice,pleasant,kind by this?', 'option_words': ['nice', 'pleasant', 'kind'], 'role': 'bot'}\n",
      "{'reward': 3.5, 'terminated': True, 'text': 'nice,pleasant,kind', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 1, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  67%|██████▋   | 20/30 [00:20<00:08,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "eliminates eliminates\n",
      "[('cancel', 0.7), ('erase', 0.7), ('terminate', 0.5), ('drop', 0.5), ('discard', 0.5), ('stop', 0.5), ('avoid', 0.4), ('remove', 0.4), ('oust', 0.4), ('omit', 0.4)]\n",
      "[('reduce', 0.247), ('remove', 0.118), ('decrease', 0.102), ('stop', 0.028), ('drop', 0.027), ('cancel', 0.022), ('cut', 0.018), ('lower', 0.017), ('end', 0.017), ('dy', 0.013)]\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word eliminates is not clear to me. Do you mean something like reduce,remove,decrease by this?', 'option_words': ['reduce', 'remove', 'decrease'], 'role': 'bot'}\n",
      "{'reward': -1.5, 'terminated': False, 'text': 'none of these', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -1, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word eliminates is not clear to me. Could you please provide me more context?', 'option_words': ['stop'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word eliminates is not clear to me. Could you please provide me more context?', 'option_words': ['drop'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'it is obviously, but I will try explain it too', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word eliminates is not clear to me. Do you mean something like cancel by this?', 'option_words': ['cancel'], 'role': 'bot'}\n",
      "{'reward': 4.5, 'terminated': True, 'text': 'Yes, it is', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 2, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  70%|███████   | 21/30 [00:22<00:10,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "run run\n",
      "[('bolt', 0.9), ('rush', 0.8), ('dash', 0.7), ('sprint', 0.7), ('scramble', 0.7), ('race', 0.7), ('hurry', 0.6), ('spring', 0.6), ('scurry', 0.6), ('speed', 0.5)]\n",
      "[('run', 0.244), ('walk', 0.083), ('wait', 0.031), ('fall', 0.025), ('jump', 0.022), ('look', 0.017), ('cry', 0.017), ('go', 0.015), ('crawl', 0.013), ('drive', 0.012)]\n",
      "-------------------\n",
      "{'action': 0, 'text': \"I'm pretty sure of the meaning of the word run . \", 'option_words': ['run'], 'role': 'bot'}\n",
      "{'reward': 5.5, 'terminated': True, 'text': '', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 3, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  73%|███████▎  | 22/30 [00:23<00:08,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "raised raised\n",
      "[('lift', 0.7), ('elevate', 0.5), ('cock', 0.3), ('up', 0.2), ('boost', 0.2), ('awaken', 0.2), ('escalate', 0.2), ('aggravate', 0.2), ('magnify', 0.2), ('erect', 0.1)]\n",
      "[('raise', 0.565), ('raised', 0.224), ('lift', 0.062), ('lower', 0.012), ('cut', 0.009), ('rose', 0.005), ('up', 0.004), ('drop', 0.004), ('down', 0.003), ('held', 0.002)]\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word raised is not clear to me. Do you mean something like raise by this?', 'option_words': ['raise'], 'role': 'bot'}\n",
      "{'reward': -2.5, 'terminated': False, 'text': 'No, it is not', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -2, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 0, 'text': \"I'm pretty sure of the meaning of the word raised . \", 'option_words': ['raised'], 'role': 'bot'}\n",
      "{'reward': 5.5, 'terminated': True, 'text': '', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 3, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  77%|███████▋  | 23/30 [00:24<00:07,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "merchant merchant\n",
      "[('retailer', 0.5), ('shopkeeper', 0.4), ('trader', 0.4), ('commercial', 0.4), ('tradesperson', 0.3), ('salesperson', 0.3), ('operator', 0.3), ('broker', 0.3), ('vendor', 0.3), ('businessperson', 0.2)]\n",
      "[('broker', 0.134), ('consumer', 0.12), ('distributor', 0.043), ('investment', 0.041), ('corporate', 0.035), ('bank', 0.03), ('retail', 0.03), ('commercial', 0.029), ('business', 0.023), ('trader', 0.019)]\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word merchant is not clear to me. Could you please provide me more context?', 'option_words': ['broker'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word merchant is not clear to me. Do you mean something like consumer by this?', 'option_words': ['consumer'], 'role': 'bot'}\n",
      "{'reward': -2.5, 'terminated': False, 'text': 'No, it is not', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -2, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word merchant is not clear to me. Could you please provide me more context?', 'option_words': ['distributor'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word merchant is not clear to me. Could you please provide me more context?', 'option_words': ['investment'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'the explain content', 'is_right_action': True, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 0, 'text': \"I'm pretty sure of the meaning of the word merchant . \", 'option_words': ['corporate'], 'role': 'bot'}\n",
      "{'reward': -3.5, 'terminated': True, 'text': ' you misunderstdood my words, I mean...', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': -3, 'length_penalty': 0.5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  80%|████████  | 24/30 [00:27<00:09,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "issue issue\n",
      "[('matter', 0.7), ('problem', 0.6), ('question', 0.6), ('topic', 0.5), ('reason', 0.5), ('point', 0.4), ('subject', 0.3), ('culmination', 0.2), ('effect', 0.2), ('issuing', 0.2)]\n",
      "[('question', 0.611), ('issue', 0.152), ('reason', 0.043), ('problem', 0.041), ('matter', 0.027), ('topic', 0.026), ('cause', 0.018), ('question', 0.005), ('reason', 0.004), ('purpose', 0.003)]\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word issue is not clear to me. Do you mean something like question by this?', 'option_words': ['question'], 'role': 'bot'}\n",
      "{'reward': 4.5, 'terminated': True, 'text': 'Yes, it is', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 2, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  83%|████████▎ | 25/30 [00:27<00:06,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "company company\n",
      "[('corporation', 0.8), ('organization', 0.8), ('firm', 0.7), ('team', 0.6), ('association', 0.6), ('enterprise', 0.6), ('establishment', 0.5), ('business', 0.4), ('assemblage', 0.3), ('club', 0.3)]\n",
      "[('company', 0.185), ('association', 0.141), ('corporation', 0.095), ('agency', 0.043), ('organization', 0.028), ('firm', 0.025), ('union', 0.023), ('board', 0.019), ('team', 0.016), ('group', 0.015)]\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word company is not clear to me. Do you mean something like company,association,corporation by this?', 'option_words': ['company', 'association', 'corporation'], 'role': 'bot'}\n",
      "{'reward': 3.5, 'terminated': True, 'text': 'company,association,corporation', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 1, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  87%|████████▋ | 26/30 [00:28<00:04,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "sound sound\n",
      "[('noise', 0.6), ('voice', 0.5), ('tone', 0.5), ('word', 0.4), ('utterance', 0.4), ('melody', 0.3), ('music', 0.2), ('note', 0.2), ('tenor', 0.2), ('intonation', 0.2)]\n",
      "[('voice', 0.124), ('sound', 0.105), ('word', 0.054), ('speech', 0.034), ('light', 0.027), ('expression', 0.027), ('word', 0.022), ('touch', 0.021), ('color', 0.02), ('language', 0.018)]\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word sound is not clear to me. Could you please provide me more context?', 'option_words': ['voice'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'it is obviously, but I will try explain it too', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 0, 'text': \"I'm pretty sure of the meaning of the word sound . \", 'option_words': ['sound'], 'role': 'bot'}\n",
      "{'reward': 5.5, 'terminated': True, 'text': '', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 3, 'length_penalty': 0.5, 'find_subs': 3}}\n",
      "#################################################################\n",
      "team team\n",
      "[('group', 0.9), ('squad', 0.7), ('band', 0.7), ('circle', 0.6), ('crew', 0.6), ('gang', 0.5), ('club', 0.5), ('unit', 0.5), ('member', 0.4), ('organization', 0.4)]\n",
      "[('crew', 0.433), ('group', 0.097), ('team', 0.063), ('band', 0.04), ('club', 0.012), ('cast', 0.008), ('committee', 0.008), ('company', 0.007), ('class', 0.006), ('family', 0.005)]\n",
      "-------------------\n",
      "{'action': 3, 'text': 'The word team is not clear to me. Could you please provide me more context?', 'option_words': ['crew'], 'role': 'bot'}\n",
      "{'reward': -0.5, 'terminated': False, 'text': 'it is obviously, but I will try explain it too', 'is_right_action': False, 'find_subs': False, 'role': 'user', 'reward_detail': {'action_reward': 0, 'length_penalty': 0.5}}\n",
      "-------------------\n",
      "{'action': 1, 'text': 'The word team is not clear to me. Do you mean something like group by this?', 'option_words': ['group'], 'role': 'bot'}\n",
      "{'reward': 4.5, 'terminated': True, 'text': 'Yes, it is', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 2, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  93%|█████████▎| 28/30 [00:30<00:02,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "too too\n",
      "[('exceedingly', 0.7), ('overly', 0.6), ('excessively', 0.6), ('immensely', 0.5), ('extremely', 0.5), ('very', 0.5), ('also', 0.4), ('more', 0.4), ('inordinately', 0.3), ('beyond', 0.3)]\n",
      "[('extremely', 0.412), ('very', 0.161), ('too', 0.119), ('highly', 0.043), ('incredibly', 0.034), ('totally', 0.015), ('really', 0.013), ('super', 0.011), ('quite', 0.01), ('so', 0.009)]\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word too is not clear to me. Do you mean something like extremely,very,too by this?', 'option_words': ['extremely', 'very', 'too'], 'role': 'bot'}\n",
      "{'reward': 3.5, 'terminated': True, 'text': 'extremely,too', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 1, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:  97%|█████████▋| 29/30 [00:31<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "offer offer\n",
      "[('proposal', 0.6), ('offering', 0.4), ('bid', 0.4), ('pitch', 0.3), ('endeavor', 0.3), ('presentation', 0.2), ('rendition', 0.2), ('submission', 0.2), ('asking', 0.2), ('provision', 0.0)]\n",
      "[('proposal', 0.163), ('offer', 0.106), ('opportunity', 0.051), ('tender', 0.039), ('bid', 0.033), ('offering', 0.024), ('competition', 0.014), ('project', 0.013), ('contract', 0.012), ('pitch', 0.011)]\n",
      "-------------------\n",
      "{'action': 2, 'text': 'The word offer is not clear to me. Do you mean something like proposal,offer,opportunity by this?', 'option_words': ['proposal', 'offer', 'opportunity'], 'role': 'bot'}\n",
      "{'reward': 3.5, 'terminated': True, 'text': 'proposal,offer', 'is_right_action': True, 'find_subs': True, 'role': 'user', 'reward_detail': {'action_reward': 1, 'length_penalty': 0.5, 'find_subs': 3}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training: 100%|██████████| 30/30 [00:32<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "test_episodes_list, train_episodes_list = rl_model.train(30,0,evaluate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7cefb97a-444f-4f01-9a81-c080df30e4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.022, 'sing')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.agent.option_words.smallest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da7bf9d9-f6be-4f4d-80af-6303c002e52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Meridian National Corp. said it sold 750,000 shares of its common stock to the McAlpine family interests, for $1 million, or $1.35 a share. The sale represents 10.2% of Meridian's shares outstanding.  \\n\\nThe McAlpine family, which operates a number of multinational companies, including a London-based engineering and construction company, also lent to Meridian National $500,000.\",\n",
       "  'target': 'outstanding',\n",
       "  'lemma_target': 'outstanding',\n",
       "  'substitutes': [('remaining', 0.6),\n",
       "   ('unclaimed', 0.4),\n",
       "   ('payable', 0.4),\n",
       "   ('uncollected', 0.4),\n",
       "   ('owing', 0.4)],\n",
       "  'lemma_subs': [('remaining', 0.6),\n",
       "   ('unclaimed', 0.4),\n",
       "   ('payable', 0.4),\n",
       "   ('uncollected', 0.4),\n",
       "   ('owing', 0.4)],\n",
       "  'offset': 187,\n",
       "  'role': 'user',\n",
       "  'option_words': [('to', 0.113),\n",
       "   ('and', 0.052),\n",
       "   ('interest', 0.033),\n",
       "   ('or', 0.025),\n",
       "   ('of', 0.025),\n",
       "   ('for', 0.022),\n",
       "   ('debt', 0.016),\n",
       "   ('on', 0.013),\n",
       "   ('asset', 0.011),\n",
       "   ('tax', 0.01)],\n",
       "  'mask_text': 'Meridian National Corp. said it sold 750,000 shares of its common stock to the McAlpine family interests, for $1 million, or $1.35 a share.outstanding.  \\n\\n remaining.  \\n\\n unclaimed.  \\n\\n payable.  \\n\\n uncollected.  \\n\\n owing.  \\n\\n <mask>.  \\n\\nThe McAlpine family, which operates a number of multinational companies, including a London-based engineering and construction company, also lent to Meridian National $500,000.'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,info = train_env.reset()\n",
    "train_env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fc0c53d-40e2-4ada-b27d-696f02058383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'At Christie\\'s, a folio of 21 prints from Alfred Stieglitz\\'s \"Equivalents\" series sold for $396,000, a single-lot record. Other works also have been exceeding price estimates. In part, prices reflect development of a market structure based on such variables as the number of prints.',\n",
       "  'target': 'works',\n",
       "  'lemma_target': 'work',\n",
       "  'substitutes': [('item', 0.6),\n",
       "   ('print', 0.6),\n",
       "   ('creation', 0.4),\n",
       "   ('product', 0.4),\n",
       "   ('object', 0.4)],\n",
       "  'lemma_subs': [('item', 0.6),\n",
       "   ('print', 0.6),\n",
       "   ('creation', 0.4),\n",
       "   ('product', 0.4),\n",
       "   ('object', 0.4)],\n",
       "  'offset': 127,\n",
       "  'role': 'user',\n",
       "  'option_words': [('object', 0.29),\n",
       "   ('item', 0.182),\n",
       "   ('product', 0.108),\n",
       "   ('item', 0.04),\n",
       "   ('product', 0.023),\n",
       "   ('creation', 0.018),\n",
       "   ('creator', 0.013),\n",
       "   ('collection', 0.008),\n",
       "   ('project', 0.008),\n",
       "   ('it', 0.008)],\n",
       "  'mask_text': 'At Christie\\'s, a folio of 21 prints from Alfred Stieglitz\\'s \"Equivalents\" series sold for $396,000, a single-lot record.works also have been exceeding pric item also have been exceeding pric print also have been exceeding pric creation also have been exceeding pric product also have been exceeding pric object also have been exceeding pric <mask> also have been exceeding pricIn part, prices reflect development of a market structure based on such variables as the number of prints.'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,info = train_env.reset()\n",
    "train_env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d86b026-3a4d-4125-9453-2023613a99bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 370/370 [01:39<00:00,  3.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-149.99999999999855, 0.2938775510204082, 0.3489795918367347)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_list, Rewards, accurate_match_rate, loose_match_rate = rl_model.evaluate(env)\n",
    "Rewards, accurate_match_rate, loose_match_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af5830fe-bc38-4a77-abf2-ac896924d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c19cee1-e050-4d62-a044-81f24589ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    for i in tqdm.tqdm(range(100),desc='get nothing',mininterval=3):\n",
    "        i +1\n",
    "        time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7b8098db-03cc-474a-a213-41a707987a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>', '.', '..', '?', 's', \"''\", '!”', '.”', '”', 'nos', 'mr', 've']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_words = '''</s>\n",
    ".\n",
    "..\n",
    "?\n",
    "s\n",
    "''\n",
    "!”\n",
    ".”\n",
    "”\n",
    "nos\n",
    "mr\n",
    "ve\n",
    "'''.split()\n",
    "filter_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4b96dc2c-e5cf-4fa4-a50b-0b4fd8c6e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3084967a-5c86-410e-a5ef-da0da7b1be66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.043, 0, ('hair', 0.043)),\n",
       " (-0.028, 1, ('wear', 0.028)),\n",
       " (-0.026, 2, ('wrinkle', 0.026))]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heapq.nsmallest(3,train_env.agent.option_words._queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9f83381f-3def-4233-b386-06643b8f1222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hair', 'wear', 'wrinkle']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest = heapq.nsmallest(3,train_env.agent.option_words._queue)\n",
    "[w for (p,idx,(w,s)) in option_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acae861-99fb-4476-bfb8-db9edc2ff361",
   "metadata": {},
   "outputs": [],
   "source": [
    "for context_id in test_env.OA.context_ids[:50]:\n",
    "    context_id = random.choice(test_env.OA.context_ids)\n",
    "    option_words,prompt_sentence = test_env.get_option_words_by_llm(context_id=context_id,use_cache=True)\n",
    "    state,info = test_env.reset(context_id)\n",
    "    subs = test_env.history[0]['substitutes']\n",
    "    words = [s for s,score in option_words]\n",
    "    if not set(words) & set(filter_words):\n",
    "        print(words,'      ',[s for s,score in subs[:8]])\n",
    "# print('--------------------------------------------------------------------------')\n",
    "# print(subs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for context_id in test_env.dataset.context_ids:\n",
    "    state, info = test_env.reset(context_id)\n",
    "    score = test_env.substitutes[min(4,len(test_env.substitutes))][1]\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1b691112-06b6-44da-9308-1e10264bddf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.6: 40,\n",
       "         0.5: 59,\n",
       "         0.3: 55,\n",
       "         0.4: 48,\n",
       "         0.2: 38,\n",
       "         0.7: 25,\n",
       "         0.0: 15,\n",
       "         0.1: 13,\n",
       "         0.8: 5})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0ecc3267-ec65-4957-a43f-748efb846ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('demand', 0.5),\n",
       " ('requirement', 0.5),\n",
       " ('desire', 0.3),\n",
       " ('urgency', 0.3),\n",
       " ('want', 0.3),\n",
       " ('inadequacy', 0.2),\n",
       " ('wish', 0.2),\n",
       " ('exigency', 0.1),\n",
       " ('poverty', 0.1),\n",
       " ('must', 0.0),\n",
       " ('obligation', 0.0),\n",
       " ('extremity', 0.0),\n",
       " ('longing', 0.0),\n",
       " ('charge', 0.0),\n",
       " ('insufficiency', 0.0)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ac566c99-38e7-4db0-bb81-0e7d05fa3655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/xu_zhang01/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "809809bf-9b4c-4e45-9153-686f57353dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat were chasing mouse\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sentence = \"The cats were chasing mice\"\n",
    "words = sentence.split()\n",
    "\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "lemmatized_sentence = \" \".join(lemmatized_words)\n",
    "\n",
    "print(lemmatized_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63323b-ba5b-4686-8082-61045ef2107b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c0c638d1-8fcd-4d34-b45f-e7c2aaafaec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "# import these modules\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "\n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e4fae8d4-aeef-45aa-a853-9f77f16703db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/xu_zhang01/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0b00047d-30b6-4a2f-912c-e94eb8381a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pull', 0.4),\n",
       " ('bring', 0.4),\n",
       " ('have', 0.3),\n",
       " ('secure', 0.3),\n",
       " ('draw', 0.3),\n",
       " ('capture', 0.3),\n",
       " ('hustle', 0.3),\n",
       " ('acquire', 0.3),\n",
       " ('win', 0.3),\n",
       " ('defeat', 0.3)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,info = test_env.reset(context_id)\n",
    "test_env.history[0]['substitutes'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05420967-0b10-4c39-846b-a63a97918798",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_action    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a64e3e75-f23f-4d8d-b399-0a5873bdc892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 580 0.3017241379310345\n"
     ]
    }
   ],
   "source": [
    "right_action_match = []\n",
    "for eps in eval_episode_list:\n",
    "    for i,utter in enumerate(eps):\n",
    "        if 'right_action' in utter:\n",
    "            right_action_match.append(utter['right_action'][0] == eps[i-1]['action'])\n",
    "cnt_right = np.array(right_action_match).sum()\n",
    "len_right = len(right_action_match)\n",
    "print(cnt_right,len_right,cnt_right/len_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3dac1bf4-af82-4c27-a1ed-d0f48df4558a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_episode_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_episode_list\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_episode_list' is not defined"
     ]
    }
   ],
   "source": [
    "eval_episode_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c3aa5-6657-4612-96c9-0c9a8c0e01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_action_matcht3_episodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a7b9f-d734-4bcf-a8e5-9ad2741b53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[eval_episode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0799c04b-0383-40f1-8911-dde225b30668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "53c5bb96-3ffd-425a-9510-c9799ae6bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9177eecc-a409-4435-994c-739dd6f00c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role            : user\n",
      "text            : “I …I noticed him from across the room when I was looking around for Rachel. He was standing right in front of some blue lights, so I couldn’t see him very well, but I noticed the way that the light set off his pale skin. It almost looked like the light bent around him without actually touching him directly.\n",
      "target          : very\n",
      "option_words    : [('very', 0.275), ('really', 0.258), ('quite', 0.196), ('particularly', 0.135), ('extremely', 0.047), ('rather', 0.023), ('incredibly', 0.007), ('fairly', 0.007), ('especially', 0.006), ('truly', 0.004)]\n",
      "---------------------------------------------------\n",
      "                               role : bot\n",
      "                               text : The word very is not clear to me. Do you mean something like very,really,quite,particularly,extremely,rather,incredibly,fairly,especially,truly ?\n",
      "                       option_words : [('very', 0.275), ('really', 0.258), ('quite', 0.196), ('particularly', 0.135), ('extremely', 0.047), ('rather', 0.023), ('incredibly', 0.007), ('fairly', 0.007), ('especially', 0.006), ('truly', 0.004)]\n",
      "                             action : 2\n",
      "---------------------------------------------------\n",
      "role            : user\n",
      "text            : none of these\n",
      "reward          : -1\n",
      "is_right_action : False\n",
      "loose_right_actions : [0 2]\n",
      "---------------------------------------------------\n",
      "                               role : bot\n",
      "                               text : \n",
      "                       option_words : [('very', 0.275), ('really', 0.258), ('quite', 0.196), ('particularly', 0.135), ('extremely', 0.047), ('rather', 0.023), ('incredibly', 0.007), ('fairly', 0.007), ('especially', 0.006), ('truly', 0.004)]\n",
      "                             action : 0\n",
      "---------------------------------------------------\n",
      "role            : user\n",
      "text            : \n",
      "reward          : 2\n",
      "is_right_action : True\n",
      "loose_right_actions : [0 2]\n",
      "---------------------------------------------------\n",
      "total reward:   1\n"
     ]
    }
   ],
   "source": [
    "keys = ['role','text','target','option_words','reward','is_right_action','action']\n",
    "t3_episodes_list = [epi for epi in test_episodes_list if len(epi)>3]\n",
    "\n",
    "episode = random.choice(t3_episodes_list)\n",
    "reward_all = 0\n",
    "for utter in episode:\n",
    "    role = utter['role']\n",
    "    for k in keys:\n",
    "        if k in utter:\n",
    "            if k=='reward':\n",
    "                reward_all += utter[k]\n",
    "            if role=='user':\n",
    "                print(k.ljust(15,' '),':',utter[k])\n",
    "            else:\n",
    "                print(k.rjust(35,' '),':',utter[k])\n",
    "    print(\"---------------------------------------------------\")\n",
    "print(\"total reward:  \", reward_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "45d52fd7-b087-4d31-afa9-0d118d425c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t3_episodes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "c4a3325f-6438-4e87-99ba-f22ff22bb5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"FAMILY PETS are improving recovery rates of patients at Columbia Hospital, Milwaukee. Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more receptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\nTIRED OF TRIMMING?\",\n",
       "  'target': 'receptive',\n",
       "  'substitutes': [('acceptant', 0.7),\n",
       "   ('welcoming', 0.7),\n",
       "   ('approachable', 0.6),\n",
       "   ('acceptive', 0.5),\n",
       "   ('open', 0.5),\n",
       "   ('responsive', 0.4),\n",
       "   ('open to suggestions', 0.3),\n",
       "   ('favorable', 0.3),\n",
       "   ('open-minded', 0.3),\n",
       "   ('open to new ideas', 0.3),\n",
       "   ('persuadable', 0.2),\n",
       "   ('suggestible', 0.2),\n",
       "   ('hospitable', 0.2),\n",
       "   ('influenceable', 0.1),\n",
       "   ('accessible', 0.1),\n",
       "   ('friendly', 0.1),\n",
       "   ('amenable', 0.1),\n",
       "   ('ready', 0.1),\n",
       "   ('quick on the uptake', 0.0),\n",
       "   ('sympathetic', 0.0),\n",
       "   ('sensitive', 0.0),\n",
       "   ('bright', 0.0),\n",
       "   ('perceptive', 0.0),\n",
       "   ('susceptible', 0.0),\n",
       "   ('swayable', 0.0),\n",
       "   ('pushover', 0.0),\n",
       "   ('well-disposed', 0.0),\n",
       "   ('alert', 0.0),\n",
       "   ('observant', 0.0),\n",
       "   ('interested', 0.0),\n",
       "   ('recipient', 0.0)],\n",
       "  'offset': 206,\n",
       "  'role': 'user',\n",
       "  'option_words': [('open', 0.991),\n",
       "   ('willing', 0.002),\n",
       "   ('responsive', 0.001),\n",
       "   ('comfortable', 0.0),\n",
       "   ('tolerant', 0.0)],\n",
       "  'mask_text': \"FAMILY PETS are improving recovery rates of patients at Columbia Hospital, Milwaukee.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more receptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more acceptant to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more welcoming to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more approachable to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more acceptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more open to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more <mask> to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\nTIRED OF TRIMMING?\"},\n",
       " {'text': '',\n",
       "  'option_words': [('open', 0.991),\n",
       "   ('willing', 0.002),\n",
       "   ('responsive', 0.001),\n",
       "   ('comfortable', 0.0),\n",
       "   ('tolerant', 0.0)],\n",
       "  'action': 0,\n",
       "  'role': 'bot'},\n",
       " {'text': ' you misunderstdood my words, I mean...',\n",
       "  'reward': -2,\n",
       "  'is_right_action': False,\n",
       "  'right_action': array([1, 2]),\n",
       "  'role': 'user',\n",
       "  'history_text': \"FAMILY PETS are improving recovery rates of patients at Columbia Hospital, Milwaukee. Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more receptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\nTIRED OF TRIMMING?</s></s> you misunderstdood my words, I mean...\"}]"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "85e65f4e-480d-4a1a-b6dc-6a8e7e72e3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'receptive'"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "31eaf8ed-5991-47cb-b70f-0118302dd594",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'episodes_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_567/4106245537.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'substitutes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'episodes_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(episodes_list[0][0]['target'])\n",
    "\n",
    "print(episodes_list[0][0]['substitutes'][:5])\n",
    "print(\"--------------------\")\n",
    "print(episodes_list[0][0]['mask_text'])\n",
    "\n",
    "print(episodes_list[0][0]['option_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "c58b5670-a4db-47ab-8063-ecd650f2618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.fill_mask.FillMaskPipeline at 0x7f067b69b760>"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.mask_model.encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "b4750d23-6a6f-472f-8953-df9959a01c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3854154944419861,\n",
       "  'token': 3714,\n",
       "  'token_str': 'know',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever know. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.15135060250759125,\n",
       "  'token': 51529,\n",
       "  'token_str': 'known',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever known. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.14298954606056213,\n",
       "  'token': 55950,\n",
       "  'token_str': 'knew',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever knew. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.025355149060487747,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.02500970847904682,\n",
       "  'token': 51592,\n",
       "  'token_str': 'seen',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever seen. At six foot two, she stood a full head taller than even her Arrallin first officer.'}]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.mask_model('''It was not an attractive face right now; her ebony\n",
    "eyes shadowed by hours on the watch, full lips pursed with frustration. She had\n",
    "the look of every leader she had ever known. She had\n",
    "the look of every leader she had ever be acquaint with. She had\n",
    "the look of every leader she had ever know. She had \n",
    "the look of every leader she had ever be acquainted with. She had\n",
    "the look of every leader she had ever have knowledge of. She had\n",
    "the look of every leader she had ever experience. She had\n",
    "the look of every leader she had ever <mask>. At six foot two, she stood a full\n",
    "head taller than even her Arrallin first officer.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "4568a300-74e4-4cde-acea-9512ac6eeacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2613705098628998,\n",
       "  'token': 3714,\n",
       "  'token_str': 'know',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever know.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.1795056164264679,\n",
       "  'token': 51529,\n",
       "  'token_str': 'known',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever known.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.1245126873254776,\n",
       "  'token': 55950,\n",
       "  'token_str': 'knew',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever knew.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.07769811153411865,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.03395156189799309,\n",
       "  'token': 1902,\n",
       "  'token_str': 'had',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever had.At six foot two, she stood a full head taller than even her Arrallin first officer.'}]"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.mask_model(episodes_list[0][0]['mask_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed81a2-a16d-454e-b25f-50c42aeb24f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\n'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eac9303b-1f4d-4631-89ef-e4514f6932d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argwhere([True,False,True,False]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0c61d6b-352a-4e76-bf74-0b1b24c0f6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.',\n",
       "  'target': 'think',\n",
       "  'substitutes': [('have in mind', 0.9),\n",
       "   ('suppose', 0.8),\n",
       "   ('presume', 0.6),\n",
       "   ('reckon', 0.6),\n",
       "   ('conclude', 0.5),\n",
       "   ('speculate', 0.5),\n",
       "   ('suspect', 0.5),\n",
       "   ('feel', 0.4),\n",
       "   ('imagine', 0.4),\n",
       "   ('suggest', 0.4),\n",
       "   ('believe', 0.4),\n",
       "   ('anticipate', 0.3),\n",
       "   ('reflect', 0.3),\n",
       "   ('surmise', 0.3),\n",
       "   ('gather', 0.3),\n",
       "   ('understand', 0.3),\n",
       "   ('foresee', 0.3),\n",
       "   ('deem', 0.3),\n",
       "   ('determine', 0.2),\n",
       "   ('expect', 0.2),\n",
       "   ('fancy', 0.2),\n",
       "   ('ponder', 0.2),\n",
       "   ('consider', 0.2),\n",
       "   ('reason', 0.2),\n",
       "   ('see', 0.2),\n",
       "   ('stop to consider', 0.2),\n",
       "   ('guess', 0.2),\n",
       "   ('intellectualize', 0.2),\n",
       "   ('envision', 0.2),\n",
       "   ('want', 0.2),\n",
       "   ('use ones head', 0.2),\n",
       "   ('estimate', 0.1),\n",
       "   ('appraise', 0.1),\n",
       "   ('sort out', 0.1),\n",
       "   ('contemplate', 0.1),\n",
       "   ('assume', 0.1),\n",
       "   ('discern', 0.1),\n",
       "   ('conceive', 0.1),\n",
       "   ('stew', 0.1),\n",
       "   ('project', 0.1),\n",
       "   ('sense', 0.1),\n",
       "   ('resolve', 0.0),\n",
       "   ('regard', 0.0),\n",
       "   ('realize', 0.0),\n",
       "   ('reminisce', 0.0),\n",
       "   ('study', 0.0),\n",
       "   ('hold', 0.0),\n",
       "   ('weigh', 0.0),\n",
       "   ('meditate', 0.0),\n",
       "   ('take', 0.0),\n",
       "   ('image', 0.0),\n",
       "   ('recall', 0.0),\n",
       "   ('visualize', 0.0),\n",
       "   ('deduce', 0.0),\n",
       "   ('comprehend', 0.0),\n",
       "   ('take under consideration', 0.0),\n",
       "   ('appreciate', 0.0),\n",
       "   ('analyze', 0.0),\n",
       "   ('muse', 0.0),\n",
       "   ('vision', 0.0),\n",
       "   ('rationalize', 0.0),\n",
       "   ('be convinced', 0.0),\n",
       "   ('judge', 0.0),\n",
       "   ('evaluate', 0.0),\n",
       "   ('plan for', 0.0),\n",
       "   ('ideate', 0.0),\n",
       "   ('examine', 0.0),\n",
       "   ('esteem', 0.0),\n",
       "   ('figure out', 0.0),\n",
       "   ('revolve', 0.0),\n",
       "   ('ruminate', 0.0),\n",
       "   ('deliberate', 0.0),\n",
       "   ('turn over', 0.0),\n",
       "   ('credit', 0.0),\n",
       "   ('envisage', 0.0),\n",
       "   ('mull over', 0.0),\n",
       "   ('brood', 0.0),\n",
       "   ('cogitate', 0.0),\n",
       "   ('infer', 0.0),\n",
       "   ('feature', 0.0),\n",
       "   ('logicalize', 0.0),\n",
       "   ('mull', 0.0),\n",
       "   ('factor', 0.0),\n",
       "   ('recollect', 0.0),\n",
       "   ('cerebrate', 0.0),\n",
       "   ('rack ones brains', 0.0),\n",
       "   ('remember call to', 0.0),\n",
       "   ('mind', 0.0)],\n",
       "  'offset': 46,\n",
       "  'role': 'user',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'mask_text': 'Nepthys turned to me.“Well, kid, what do you think?.“Well, kid, what do you have in mind?.“Well, kid, what do you suppose?.“Well, kid, what do you presume?.“Well, kid, what do you reckon?.“Well, kid, what do you conclude?.“Well, kid, what do you <mask>?Remember, this is your quest.'},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_episode_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f270f4d-aaef-492f-9996-468f8b0351c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The word payable is not clear to me. Do you mean something like due,paid,pay,payment,available ?',\n",
       " 'option_words': [('due', 0.81),\n",
       "  ('paid', 0.135),\n",
       "  ('pay', 0.009),\n",
       "  ('payment', 0.003),\n",
       "  ('available', 0.002)],\n",
       " 'action': 2,\n",
       " 'role': 'bot'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_list[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc12dec7-4de1-4de7-b238-952c54645e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# 定义一个枚举类型\n",
    "class Action(Enum):\n",
    "    NO_ACTION = 0\n",
    "    CONFIRM = 1\n",
    "    OPTION = 2\n",
    "    EXPLAIN = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4b2e781-0488-4a8b-9e97-ef0bc063d758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for action in Action:\n",
    "    print(action.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47658a3-8666-457b-bedf-e4c983ac320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "03a68d8c-4e76-4173-ba3b-536e4ded903b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 58, False: 42})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "Counter(pd.DataFrame([e[2] for e in episodes_list[-100:]])['is_right_action'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "20358fbc-4181-4462-be81-b3c3ec2046b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     hello\n"
     ]
    }
   ],
   "source": [
    "print('hello'.rjust(10, ' '))\n",
    "# 输出 '# 输出 'hello   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c6170679-2c66-4070-ac32-074f9b8590d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Months earlier, we might have sought a bed, a couch, or a\\n                    comfortable chair at this point. Instead, I asked, \"Is he handsome?\" \\n                 \"You\\'re jealous.\"',\n",
       "  'target': 'Instead',\n",
       "  'substitutes': [('alternatively', 0.6),\n",
       "   ('however', 0.6),\n",
       "   ('alternately', 0.5),\n",
       "   ('rather', 0.4),\n",
       "   ('on second thought', 0.4),\n",
       "   ('in lieu', 0.3),\n",
       "   ('as a substitute', 0.3),\n",
       "   ('alternative', 0.3),\n",
       "   ('in place of', 0.3),\n",
       "   ('on behalf of', 0.3),\n",
       "   ('rather than', 0.2),\n",
       "   ('preferably', 0.0),\n",
       "   ('in preference', 0.0),\n",
       "   ('quietly', 0.0),\n",
       "   ('actually', 0.0)],\n",
       "  'offset': 111,\n",
       "  'role': 'user'},\n",
       " {'text': 'The word Instead is not clear to me. Do you mean something like how,</s>,then,and,so ?',\n",
       "  'option_words': [('how', 0.254),\n",
       "   ('</s>', 0.131),\n",
       "   ('then', 0.025),\n",
       "   ('and', 0.022),\n",
       "   ('so', 0.021)],\n",
       "  'action': 2,\n",
       "  'role': 'bot'},\n",
       " {'text': 'none of these',\n",
       "  'reward': -1,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user'},\n",
       " {'text': 'The word Instead is not clear to me. Could you please provide me more context?',\n",
       "  'option_words': [('how', 0.254),\n",
       "   ('</s>', 0.131),\n",
       "   ('then', 0.025),\n",
       "   ('and', 0.022),\n",
       "   ('so', 0.021)],\n",
       "  'action': 3,\n",
       "  'role': 'bot'},\n",
       " {'text': 'the explain content',\n",
       "  'reward': 0.5,\n",
       "  'is_right_action': True,\n",
       "  'role': 'user'},\n",
       " {'text': '',\n",
       "  'option_words': [('how', 0.254),\n",
       "   ('</s>', 0.131),\n",
       "   ('then', 0.025),\n",
       "   ('and', 0.022),\n",
       "   ('so', 0.021)],\n",
       "  'action': 0,\n",
       "  'role': 'bot'},\n",
       " {'text': ' you misunderstdood my words, I mean...',\n",
       "  'reward': -2,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2ccbddd4-0a93-407a-a1da-96aa8357ef63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electronic theft by foreign and industrial spies and disgruntled\n",
      "\t\t\t\temployees is costing U.S. companies billions and eroding their\n",
      "\t\t\t\tinternational competitive advantage. That was the message delivered by\n",
      "\t\t\t\tgovernment and private security experts at an all-day conference on\n",
      "\t\t\t\tcorporate electronic espionage. \"Hostile and even friendly nations\n",
      "\t\t\t\troutinely steal information from U.S. companies and share it with their\n",
      "\t\t\t\town companies,\" said Noel D. Matchett, a former staffer at the federal\n",
      "\t\t\t\tNational Security Agency and now president of Information Security Inc.,\n",
      "\t\t\t\tSilver Spring, Md.\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "authority\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "official\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "state\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "government\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "official\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "turn = 0\n",
    "for his in env.history:\n",
    "    space_num = 0 if turn%2==0 else (135-len(his['text']))\n",
    "    # print(turn, space_num) \n",
    "    print(' '*space_num + his['text'])\n",
    "    print('----------------------------------')\n",
    "    turn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3726263f-0d58-46ee-a78b-8e7462ab58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526630f-1db7-49f1-98f5-33da68418946",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "76cab7a6-73b5-40ac-933f-777ec167caaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {True: {'answer': '', 'reward': 2, 'terminated': True},\n",
       "  False: {'answer': ' you misunderstdood my words, I mean...',\n",
       "   'reward': -2,\n",
       "   'terminated': True}},\n",
       " 1: {True: {'answer': 'Yes, it is', 'reward': 1.5, 'terminated': True},\n",
       "  False: {'answer': 'No, it is not ', 'reward': -1.5, 'terminated': False}},\n",
       " 2: {True: {'answer': None, 'reward': 1, 'terminated': True},\n",
       "  False: {'answer': ' none of these', 'reward': -1, 'terminated': False}},\n",
       " 3: {True: {'answer': 'the explain content',\n",
       "   'reward': 0.5,\n",
       "   'terminated': False},\n",
       "  False: {'answer': 'it is obviously, but I will try explain it too',\n",
       "   'reward': -0.5,\n",
       "   'terminated': True}}}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5c9c9504-3277-47e6-8517-b061f06114e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_action(self):\n",
    "    option_words = self.get_option_words_by_llm(self.context_id)\n",
    "    should_no_action = self.should_no_action(option_words)\n",
    "    should_confirm = self.should_confirm(option_words)\n",
    "    should_opt = self.should_opt(option_words)\n",
    "    should_explain = self.should_explain(option_words)\n",
    "\n",
    "    right_action = [should_no_action, should_confirm, should_opt, should_explain]\n",
    "    return right_action.index("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "034bd783-1f67-4274-8982-fefa36a84487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_action(env).index(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8faeee0-e1b7-4faf-8295-465d7e3a9e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option = env.get_option_words_by_llm(context_id)\n",
    "env.get_best_action()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09154a4-0ca2-472d-946d-63117b2faf80",
   "metadata": {},
   "source": [
    "## Expierment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57a7402-23e5-4b51-bbe1-13f54d3816b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info =  env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c62f8eaf-ff49-42bb-a766-574cb871eb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question(text='I imagine that people do not come here for unimportant reasons.”\\n            It hissed thoughtfully. “True, true.', target='hissed', substitutes=[('seethe', 0.4), ('jeer', 0.3), ('make buzzing sound', 0.3), ('whirr', 0.3), ('whistle', 0.2), ('sputter', 0.2), ('mock', 0.2), ('shrill', 0.1), ('boo', 0.1), ('deride', 0.0), ('blow', 0.0), ('whiz', 0.0), ('rasp', 0.0), ('hoot', 0.0), ('say', 0.0), ('wheeze', 0.0), ('disapprove', 0.0), ('damn', 0.0), ('sizzle', 0.0), ('catcall', 0.0), ('buzz', 0.0), ('sibilate', 0.0), ('revile', 0.0), ('ridicule', 0.0), ('spit', 0.0), ('sigh', 0.0), ('condemn', 0.0), ('shout down', 0.0), ('whisper', 0.0), ('decry', 0.0), ('siss', 0.0)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.history[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29e54d-87cd-4092-aa66-cdfb6a04523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "71cea31d-abae-4d73-addd-94c0822dcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = self.history[0]\n",
    "\n",
    "mask_show = ''\n",
    "solo_mask = h0.text.replace(h0.target,'<mask>',1)\n",
    "mask_text = ''\n",
    "for i,(word,score) in enumerate(h0.substitutes[:5]):\n",
    "    if len(h0.text)*6<2100:\n",
    "        text = h0.text\n",
    "    else:\n",
    "        subtract_len = len(h0.text)-350\n",
    "        index = h0.text.index(h0.target)\n",
    "        if i%2==0:\n",
    "            pre_sub_index = min(0+subtract_len,index-20)\n",
    "            text = h0.text[pre_sub_index:]\n",
    "        else:\n",
    "            post_sub_index = max(len(h0.text)-subtract_len,index+20)\n",
    "            text = h0.text[:post_sub_index]\n",
    "    text.replace(h0.target,word,1)\n",
    "    if len(self.model.tokenizer(mask_text+text+solo_mask)['input_ids'])>512:\n",
    "        break\n",
    "    mask_text += text.replace(h0.target,word,1)\n",
    "    # mask_show += text.replace(h0.target,f\"\\033[31m{word}\\033[0m\",1)+'\\033[31m<\\nnewline>\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e17ea-b523-4da8-bd83-77be6850aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "945ecfc1-ab26-4d5e-abb7-06b5a1861159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('even', 0.913),\n",
       " ('and', 0.022),\n",
       " ('particularly', 0.007),\n",
       " ('especially', 0.003),\n",
       " ('although', 0.003)]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "62620618-12bc-47b7-a9c2-c39fc99f95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "5e4b8ab4-9468-4ab5-a1b7-f822d81477d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[question(text='In its center, under a spearing, white light, was a golden table draped with a blue velvet cloth, on which lay a gray, plum-sized rock.\\n            “A marvel, isn’t it?” she said.', target='marvel', substitutes=[('wonder', 0.9), ('phenomenon', 0.6), ('miracle', 0.5), ('amazement', 0.5), ('awed', 0.2), ('be amazed be', 0.1), ('genius', 0.0), ('goggle', 0.0), ('prodigy', 0.0), ('gaze', 0.0), ('feel surprise', 0.0), ('stare', 0.0), ('stand in awe', 0.0), ('be surprised', 0.0), ('sensation', 0.0), ('gape', 0.0)])]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "ecdbb1f6-5df4-4e66-906f-9b13933066cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wonder', 0.686),\n",
       " ('miracle', 0.053),\n",
       " ('magic', 0.03),\n",
       " ('strange', 0.012),\n",
       " ('wonderful', 0.01)]"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_option_words_by_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "235af17a-cfb3-41cd-a99f-0a463ff6280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e578cb-9b1e-419e-aecd-e70796c23ba9",
   "metadata": {},
   "source": [
    "##  evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "1572c057-1a94-4853-98d2-01c1939a73fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'environment' from '/mnt/d/BaiduSyncdisk/intelligent_interactive_system/Thesis/RL/environment.py'>"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "436f4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f53d4f93-e135-4517-a934-e372ef7dc4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context_id_state_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46860cba-b183-42fa-a18a-74891ec04759",
   "metadata": {},
   "source": [
    "# Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7f524ba8-ba44-4b80-b982-b96651ecf469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [18:49<00:00,  1.48s/it]\n",
      "100%|██████████| 370/370 [09:25<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "context_id_state_mapping = {}\n",
    "context_option_mapping = {}\n",
    "for env in [train_env,test_env]:\n",
    "    for context_id in tqdm.tqdm(env.OA.context_ids):\n",
    "        # if (context_id in context_id_state_mapping) and (context_id in context_option_mapping):\n",
    "        #     continue\n",
    "        state,info = env.reset(context_id)\n",
    "        option_words = env.get_option_words_by_llm(context_id,False)\n",
    "        context_id_state_mapping[context_id] = state\n",
    "        context_option_mapping[context_id] = option_words\n",
    "    \n",
    "import pickle\n",
    "with open(\"state.pkl\",\"wb\") as f:\n",
    "    pickle.dump(context_id_state_mapping,f)\n",
    "with open(\"option.pkl\",\"wb\") as  f:\n",
    "    pickle.dump(context_option_mapping,f  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75c2b551-0653-45af-8907-58444162ef23",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have exactly one of create/read/write/append mode and at most one plus",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moption.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m    my_obj \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have exactly one of create/read/write/append mode and at most one plus"
     ]
    }
   ],
   "source": [
    " with open(\"option.pkl\",\"b\") as f:\n",
    "    my_obj = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c8a2c-0bca-4746-b3c8-c96a0b22a5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f3fb291-b69f-4654-9193-354a3c3be667",
   "metadata": {},
   "outputs": [],
   "source": [
    "del context_id_state_mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21147f5b-1cfc-4024-b4aa-c19e2068e0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.34375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(64*768*370)/(1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6799f881-61bd-4c5a-8519-1fcfe953b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_id_state_mapping['c:c28336fbaeb6942c1454706a864cdf89c4535313'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59527332-e5f1-4605-a797-714aa2282a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "265873fe-c8eb-4cd2-a5c7-b6c57a282843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_option_words_by_llm(self,context_id):\n",
    "    # state, info = test_env.reset()\n",
    "    # h0 =self.history[0]\n",
    "\n",
    "\n",
    "    def repeat_part(sent,target,substitutes,trunck=False):\n",
    "        rep_list = []\n",
    "        substitutes = [w for w,s in substitutes[:5]]\n",
    "        for sub in [target]+substitutes+['<mask>']:\n",
    "            start = offset-30 if trunck else 0\n",
    "            post_start = offset-sent.start_char+len(target)\n",
    "            post_end = post_start+30 if trunck else  100000000\n",
    "            repeat_part = f\"{sent.text[start:offset-sent.start_char]}{sub}{sent.text[post_start:post_end]}\"\n",
    "            rep_list.append(repeat_part)\n",
    "        return '.'.join(rep_list)\n",
    "\n",
    "    h0,_ = self.OA.sample(context_id)\n",
    "    # h0 = self.history[0]\n",
    "\n",
    "    offset = h0['offset']\n",
    "    mask_sentence_list = []\n",
    "    for sent in nlp(h0['text']).sents:\n",
    "        print(sent.start_char, offset ,sent.end_char)\n",
    "        if sent.start_char <= offset <sent.end_char:\n",
    "            sent_text = repeat_part(sent, h0['target'], h0['substitutes'])\n",
    "            mask_sentence_list.append(sent_text)\n",
    "        else:\n",
    "            mask_sentence_list.append(sent.text)\n",
    "\n",
    "    mask_text = ''.join(mask_sentence_list)\n",
    "    token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "\n",
    "    if token_lens>512:\n",
    "        mask_sentence_list = []\n",
    "        for sent in nlp(h0['text']).sents:\n",
    "            if sent.start_char <= offset <sent.end_char:\n",
    "                sent_text = repeat_part(sent, h0['target'], h0['substitutes'],True)\n",
    "                # print('-------------')\n",
    "                mask_sentence_list.append(sent_text)\n",
    "            else:\n",
    "                mask_sentence_list.append(sent.text)\n",
    "        mask_text = ''.join(mask_sentence_list)\n",
    "        token_lens = len(tokenizer(''.join(mask_text))['input_ids'])                \n",
    "    # words = [(token['token_str'],round(token['score'],3)) for token in self.mask_model(mask_text)]\n",
    "    return mask_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f31c0a99-ba06-4c0d-ae62-3de2c7da34d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Let’s go.”\\n            As we headed down the sidewalk, I said, “What is your name, anyway?”'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "h0['text'][h0['offset']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7fd005a-dc4a-4b37-bf68-6fd1f5605093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 128 95\n",
      "96 128 445\n",
      "446 128 499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 87, 1902, 959, 90698, 450, 87, 13648, 959, 33022, 47, 30698, 4, 1284, 47, 1992, 4745, 35978, 5, 3827, 45188, 70, 5551, 77968, 67, 28302, 23, 6, 5, 7077, 16065, 70, 5551, 77968, 67, 28302, 23, 6, 5, 107, 75161, 70, 5551, 77968, 67, 28302, 23, 6, 5, 43866, 107, 70, 5551, 77968, 67, 28302, 23, 6, 5, 3827, 38931, 70, 5551, 77968, 67, 28302, 23, 6, 5, 987, 19, 16065, 70, 5551, 77968, 67, 28302, 23, 6, 5, 250001, 70, 5551, 77968, 67, 28302, 23, 47009, 642, 23409, 1810, 100, 10, 72399, 186857, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(get_option_words_by_llm(test_env,context_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e64e23-e3a6-4a80-8eef-e7a151ce8df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4848b7ff-b2ab-4a7a-b558-6644c88b0cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': 'It was last February, after the winter break, that we moved in together. Now spring was back, under the concrete, and I could smell it even here.\\n            “Isn’t it an amazing night, Rache?',\n",
       "  'target': 'even',\n",
       "  'substitutes': [('still', 0.4),\n",
       "   ('as well as', 0.2),\n",
       "   ('so much as', 0.1),\n",
       "   ('much', 0.1),\n",
       "   ('in spite of', 0.0),\n",
       "   ('yet', 0.0),\n",
       "   ('despite', 0.0),\n",
       "   ('notwithstanding', 0.0),\n",
       "   ('indeed', 0.0),\n",
       "   ('actually', 0.0),\n",
       "   ('disregarding', 0.0),\n",
       "   ('more', 0.0),\n",
       "   ('yet all the', 0.0)],\n",
       "  'offset': 135},\n",
       " 'c:8449d1484b624c8db76ae3d9c60a000f677a244d')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.OA.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "0ec6bbc4-2192-449b-963a-dfde0704267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                   | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_142/1917932590.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 200/200 [18:37<00:00,  5.59s/it]\n"
     ]
    }
   ],
   "source": [
    "returns = 0\n",
    "action_list = []\n",
    "turns_list = []\n",
    "reward_list = []\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    context_id = test_env.OA.context_ids[i]\n",
    "    state, info = test_env.reset(context_id)\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    episode_returns = 0\n",
    "    for t in count():\n",
    "        action = select_action(state,eps_threshold=None)\n",
    "        action_list.append(action.item())\n",
    "        observation, reward, terminated, truncated, _ = test_env.step(action.item())\n",
    "        state = observation.reshape((1,-1))\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        episode_returns += reward\n",
    "        # returns += reward\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        if done:\n",
    "            turns_list.append(t)\n",
    "            reward_list.append(episode_returns)\n",
    "            # plot_durations()\n",
    "\n",
    "\n",
    "            turn = 0\n",
    "            for his in env.history:\n",
    "                space_num = 0 if turn%2==0 else (135-len(his.text))\n",
    "                role = \"User:\" if  turn%2==0 else  \"Bot:\"\n",
    "                # print(role)\n",
    "                # print(his.text)\n",
    "                # print('----------------------------------')\n",
    "                turn += 1\n",
    "            break\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "9a206ff2-7e06-4536-8f45-eae09192638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "695f4f0e-ac66-48fd-a6b0-7ce31c1db5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 919, 1: 16, 3: 21, 0: 13})"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "13494357-7186-4ac7-a1f5-3dd0510dcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "6ef6b0b9-7a14-4843-9833-b3fb9fc6a6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of occurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>options</th>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confirm</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more info</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no action</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           number of occurance\n",
       "options                    919\n",
       "confirm                     16\n",
       "more info                   21\n",
       "no action                   13"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_act = Counter(action_list) # = \n",
    "name_map = {0:'no action',1:'confirm',2:'options',3:'more info'}\n",
    "pd.DataFrame([data_act],index=['number of occurance']).rename(name_map,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "f70f76bb-0e1e-4fc6-a7dd-971d87fcb058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turns</th>\n",
       "      <th>Number of Occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   turns  Number of Occurrence\n",
       "0      5                   188\n",
       "1      2                     4\n",
       "2      3                     2\n",
       "3      1                     3\n",
       "4      4                     3"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame([Counter(turns_list)]).T.reset_index()\n",
    "df2.columns = ['turns','Number of Occurrence']\n",
    "df2['turns'] += 1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735458b7-9d8d-413e-a047-2e275cb36a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "16039882-513f-4eb2-9f22-b1c3c3f7a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0423d0f7-19db-48d2-95c4-a980273ce4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4036247594865046"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c83fc-a12d-47dd-a435-fb18daf8c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = origin_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afc7f6e2-6abf-40c1-88ad-588efc7773b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_id = random.choice(self.context_ids)\n",
    "context = self.contexts[context_id]['context']\n",
    "target = self.contexts[context_id]['targets'][0]\n",
    "target_text = target['target']\n",
    "substitutes = [(sub['substitute'],sub['label_score']) for sub in target['substitutes']]\n",
    "sorted_subs = sorted(substitutes,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55ffad1c-2582-46b8-94e3-1c1483af2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d38a4cd-c0bc-40f3-9a26-d657504ccfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.1000])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a617918-e081-4a3c-8b58-7ccea316b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_return = []\n",
    "len_avg = 10\n",
    "for i in range(len(return_list)-len_avg):\n",
    "    average_return.append(np.mean([s.item() for s in return_list[i:i + len_avg]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd4b046c-0d80-4bf4-be7a-472eb7053d24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_268/136110296.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturn_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.mean([s.item() for s in return_list[i:i+10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5101dc4a-8af9-4411-a084-fc42f316549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc207554-12b6-4aea-8d22-e32efc26c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d78b0368-9ada-42ee-9e74-3b11feb8201a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "00cabcfd-0895-4f2b-ae98-9c955fe3142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_part(sent,target,substitutes,trunck=False):\n",
    "    rep_list = []\n",
    "    substitutes = [w for w,s in substitutes[:5]]\n",
    "    for sub in [target]+substitutes+['<mask>']:\n",
    "        start = offset-30 if trunck else 0\n",
    "        repeat_part = f\"{sent.text[start:offset-sent.start_char]}{sub}{sent.text[offset-sent.start_char+len(target):]}\"\n",
    "        rep_list.append(repeat_part)\n",
    "    return '.'.join(rep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f0eeffd-4530-4993-97f0-c99033882847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f28f0698-a870-44de-9c8c-931402e76afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_origin_agent = OriginAgent(file_path='../data/swords/swords-v1.1_test.json.gz')\n",
    "test_env = environment.DialougeEnv(test_origin_agent,embedding_model,unmasker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8651b23c-b870-45ff-86b7-2ac8478b0e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 370/370 [00:34<00:00, 10.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for con in tqdm.tqdm(env.OA.context_ids):\n",
    "    state,info = env.reset(con)\n",
    "    h0 = env.history[0]\n",
    "    offset = h0['offset']\n",
    "    mask_sentence_list = []\n",
    "    for sent in nlp(h0['text']).sents:\n",
    "        if sent.start_char < offset <sent.end_char:\n",
    "            sent_text = repeat_part(sent, h0['target'], h0['substitutes'])\n",
    "            # print('-------------')\n",
    "            mask_sentence_list.append(sent_text)\n",
    "        else:\n",
    "            mask_sentence_list.append(sent.text)\n",
    "\n",
    "    mask_text = ''.join(mask_sentence_list)\n",
    "    token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "    token_lens, mask_text\n",
    "    \n",
    "    if token_lens>512:\n",
    "        mask_sentence_list = []\n",
    "        for sent in nlp(h0['text']).sents:\n",
    "            if sent.start_char < offset <sent.end_char:\n",
    "                sent_text = repeat_part(sent, h0['target'], h0['substitutes'],True)\n",
    "                # print('-------------')\n",
    "                mask_sentence_list.append(sent_text)\n",
    "            else:\n",
    "                mask_sentence_list.append(sent.text)\n",
    "        mask_text = ''.join(mask_sentence_list)\n",
    "        token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "        if token_lens>512:\n",
    "            print(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "681914b8-a4d2-4d2f-94df-a4ccfe7e11d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "The FBI cited a vivid conversation with Anissina's mother in\n",
      "which Tokhtakhounov assured her that even if her daughter \"falls,\n",
      "we will make sure she is No. 1.\"\n",
      "\n",
      "\n",
      "   After the Winter Olympics, a French judge, Marie-Reine Le\n",
      "Gougne, was suspended by the International Skating Union for not\n",
      "reporting pressure she said was put on her by Didier Gailhaguet,\n",
      "president of the French Skating Federation, to vote for the Russian\n",
      "pairs team.\n",
      "\n",
      "\n",
      "   \n",
      "-----------\n",
      "She later recanted and said that Canadian officials had\n",
      "pressured her.\n"
     ]
    }
   ],
   "source": [
    "for sent in nlp(h0['text']).sents:\n",
    "    print(\"-----------\")\n",
    "    print(sent)\n",
    "    print(sent)\n",
    "# print(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bee743a-345f-4b7f-bfd3-03744fb63efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.text[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2d9e29a-186d-4e98-b3e4-b48b3eb043cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \";1 W;2 e;3  ;4 w;5 e;6 r;7 e;8  ;9 a;10 l;11 l;12  ;13 a;14 p;15 p;16 a;17 l;18 l;"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(text[0:19]):\n",
    "    print(i,t,end=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecb0d3d8-2d9f-4daa-877c-910423c9f288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.start_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26eafd0f-24ee-43a5-8fcc-f05f4bd2dd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Span.as_doc>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.as_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "863497a7-1519-431b-adcf-1ffe8507f150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<environment.OriginAgent at 0x7fc5603b8b80>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c0ed589-045e-4fd3-ac03-6e1a18d55955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# 加载英文语言模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16c53a-1d45-4fd0-8fd8-e841a6fa6d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncat(text):\n",
    "    text_list = []\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b15f6c93-38ab-43c5-99b9-945c2560daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "034d4b53-60f4-44c3-b1ca-dce988626082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-------------------------------------\n",
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of the wise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of knowledge\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of advice\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of astuteness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of sageness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of enlightenment\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of expertise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of <mask>\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-----------wisdom--------------\n",
      "[('the wise', 0.6), ('knowledge', 0.5), ('advice', 0.5), ('astuteness', 0.5), ('sageness', 0.5), ('enlightenment', 0.4), ('expertise', 0.4), ('intelligence', 0.4), ('shrewdness', 0.4), ('wise thinking', 0.3), ('experience', 0.3), ('insight', 0.3), ('judiciousness', 0.3), ('clear thinking', 0.2), ('good judgment', 0.2), ('reason', 0.2), ('caution', 0.2), ('comprehension', 0.2), ('foresight', 0.2), ('discernment', 0.2), ('acumen', 0.2), ('perspicacity', 0.1), ('sanity', 0.1), ('prudence', 0.1), ('savvy', 0.1), ('sagacity', 0.1), ('horse sense', 0.0), ('common sense', 0.0), ('poise', 0.0), ('discrimination', 0.0), ('penetration', 0.0), ('gumption', 0.0), ('balance', 0.0), ('judgment', 0.0), ('solidity', 0.0), ('practicality', 0.0), ('savoir faire', 0.0), ('sophistication', 0.0), ('information', 0.0), ('circumspection', 0.0), ('pansophy', 0.0), ('sapience', 0.0), ('stability', 0.0), ('understanding', 0.0), ('a sage', 0.0), ('erudition', 0.0), ('learning', 0.0), ('brains', 0.0)]\n",
      "-------------------------\n",
      "[('wisdom', 0.575), ('knowledge', 0.056), ('advice', 0.051), ('inspiration', 0.029), ('confidence', 0.023)]\n",
      "-------------------------\n",
      "[('said', 0.411), ('says', 0.121), ('was', 0.071), ('replied', 0.035), ('answered', 0.029)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "mask_text_doc = nlp(h0.text)\n",
    "mask_text = ''\n",
    "# 遍历每个句子并打印\n",
    "for sentence in mask_text_doc.sents:\n",
    "    # print(sentence.text)\n",
    "    if h0.target in sentence.text:\n",
    "        words = [h0.tarnlp = spacy.load(\"en_core_web_sm\")get,*[w for w,score in h0.substitutes[:5]],'<mask>']\n",
    "        sub_sentence_text = \".\".join([sentence.text.replace(h0.target,w,1) for w in words])\n",
    "        mask_text += sub_sentence_text\n",
    "    else:\n",
    "        mask_text += sentence.text\n",
    "if len(tokenizer(mask_text)['input_ids'])>10:\n",
    "    mask_text = ''\n",
    "    # 遍历每个句子并打印\n",
    "    for sentence in mask_text_doc.sents:\n",
    "        # print(sentence.text)\n",
    "        if h0.target in sentence.text:\n",
    "            parts = sentence.text.split(\",\")\n",
    "            mask_idx = [i for i,p in enumerate(parts) if (h0.target in p)][0]\n",
    "            words = [h0.target,*[w for w,score in h0.substitutes[:7]],'<mask>']\n",
    "            sub_sentence_text = \",\".join([parts[mask_idx].replace(h0.target,w,1) for w in words])\n",
    "            parts[mask_idx] = sub_sentence_text\n",
    "            mask_text += ' '.join(parts)\n",
    "        else:\n",
    "            mask_text += sentence.text\n",
    "\n",
    "print(h0.text)\n",
    "print(\"-------------------------------------\")\n",
    "print(mask_text)\n",
    "print(f\"-----------{h0.target}--------------\")\n",
    "print(h0.substitutes)\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(mask_text)])\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(solo_mask)])\n",
    "\n",
    "len(tokenizer(h0.text)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35dabde9-234b-419a-be2a-ba1db0a9971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-------------------------------------\n",
      "list>   \n",
      "\n",
      "Words of sageness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of knowledge\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of astuteness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of <mask>\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of advice\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of the wise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of expertise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of enlightenment\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-----------wisdom--------------\n",
      "[('the wise', 0.6), ('knowledge', 0.5), ('advice', 0.5), ('astuteness', 0.5), ('sageness', 0.5), ('enlightenment', 0.4), ('expertise', 0.4), ('intelligence', 0.4), ('shrewdness', 0.4), ('wise thinking', 0.3), ('experience', 0.3), ('insight', 0.3), ('judiciousness', 0.3), ('clear thinking', 0.2), ('good judgment', 0.2), ('reason', 0.2), ('caution', 0.2), ('comprehension', 0.2), ('foresight', 0.2), ('discernment', 0.2), ('acumen', 0.2), ('perspicacity', 0.1), ('sanity', 0.1), ('prudence', 0.1), ('savvy', 0.1), ('sagacity', 0.1), ('horse sense', 0.0), ('common sense', 0.0), ('poise', 0.0), ('discrimination', 0.0), ('penetration', 0.0), ('gumption', 0.0), ('balance', 0.0), ('judgment', 0.0), ('solidity', 0.0), ('practicality', 0.0), ('savoir faire', 0.0), ('sophistication', 0.0), ('information', 0.0), ('circumspection', 0.0), ('pansophy', 0.0), ('sapience', 0.0), ('stability', 0.0), ('understanding', 0.0), ('a sage', 0.0), ('erudition', 0.0), ('learning', 0.0), ('brains', 0.0)]\n",
      "-------------------------\n",
      "[('wisdom', 0.634), ('knowledge', 0.036), ('confidence', 0.028), ('inspiration', 0.02), ('patience', 0.016)]\n",
      "-------------------------\n",
      "[('said', 0.411), ('says', 0.121), ('was', 0.071), ('replied', 0.035), ('answered', 0.029)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "mask_text_doc = nlp(h0.text)\n",
    "mask_text = ''\n",
    "# 遍历每个句子并打印\n",
    "for sentence in mask_text_doc.sents:\n",
    "    # print(sentence.text)\n",
    "    if h0.target in sentence.text:\n",
    "        words = [h0.target,*[w for w,score in h0.substitutes[:7]],'<mask>']\n",
    "        random.shuffle(words)\n",
    "        sub_sentence_text = \".\".join([sentence.text.replace(h0.target,w,1) for w in words])\n",
    "        mask_text += sub_sentence_text\n",
    "    else:\n",
    "        mask_text += sentence.text\n",
    "if len(tokenizer(mask_text)['input_ids'])>512:\n",
    "    mask_text = ''\n",
    "    # 遍历每个句子并打印\n",
    "    for sentence in mask_text_doc.sents:\n",
    "        # print(sentence.text)\n",
    "        if h0.target in sentence.text:\n",
    "            parts = sentence.text.split(\",\")\n",
    "            mask_idx = [i for i,p in enumerate(parts) if (h0.target in p)][0]\n",
    "            words = [h0.target,*[w for w,score in h0.substitutes[:5]],'<mask>']\n",
    "            random.shuffle(words)\n",
    "            sub_sentence_text = \",\".join([parts[mask_idx].replace(h0.target,w,1) for w in words])\n",
    "            parts[mask_idx] = sub_sentence_text\n",
    "            mask_text += ' '.join(parts)\n",
    "        else:\n",
    "            mask_text += sentence.text\n",
    "\n",
    "print(h0.text)\n",
    "print(\"-------------------------------------\")\n",
    "print(mask_text)\n",
    "print(f\"-----------{h0.target}--------------\")\n",
    "print(h0.substitutes)\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(mask_text)])\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(solo_mask)])\n",
    "\n",
    "len(tokenizer(h0.text)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9151c40d-be9b-4906-92bb-b90334a05081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c4ad17a1-d1c4-4cb3-98cb-b8d9130fcee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['listless', '<mask>', 'lifeless', 'empty', 'dead', 'flat', 'deathly']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16ef9b55-9816-4030-9c30-5e09ba7162c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(mask_text)['input_ids'])>512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8cf6f4-2f01-4113-a3db-cf4aa1d6626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if there is target in the top masks :\n",
    "    that means LLM could predict well, the ambiagrous is less\n",
    "    \n",
    "    No action\n",
    "\n",
    "if top mask's score is high ,and in':\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "96753649-2f02-41e3-a3ab-aa6fcafec692",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 31 3.77\n",
      "276 77 3.58\n",
      "142 41 3.46\n",
      "404 106 3.81\n",
      "258 70 3.69\n",
      "129 36 3.58\n",
      "89 20 4.45\n",
      "358 96 3.73\n",
      "294 61 4.82\n",
      "313 81 3.86\n",
      "426 119 3.58\n",
      "213 41 5.2\n",
      "292 65 4.49\n",
      "152 29 5.24\n",
      "204 62 3.29\n",
      "251 59 4.25\n",
      "425 106 4.01\n",
      "266 65 4.09\n",
      "280 61 4.59\n",
      "321 67 4.79\n",
      "65 16 4.06\n",
      "375 84 4.46\n",
      "546 116 4.71\n",
      "194 45 4.31\n",
      "148 30 4.93\n",
      "183 42 4.36\n",
      "134 31 4.32\n",
      "207 48 4.31\n",
      "510 105 4.86\n",
      "297 58 5.12\n",
      "277 64 4.33\n",
      "242 53 4.57\n",
      "219 46 4.76\n",
      "243 59 4.12\n",
      "369 87 4.24\n",
      "420 76 5.53\n",
      "226 60 3.77\n",
      "296 73 4.05\n",
      "131 35 3.74\n",
      "111 26 4.27\n",
      "192 45 4.27\n",
      "164 42 3.9\n",
      "93 28 3.32\n",
      "446 106 4.21\n",
      "336 96 3.5\n",
      "420 76 5.53\n",
      "245 61 4.02\n",
      "258 70 3.69\n",
      "290 64 4.53\n",
      "154 34 4.53\n",
      "293 69 4.25\n",
      "197 52 3.79\n",
      "224 58 3.86\n",
      "195 44 4.43\n",
      "153 35 4.37\n",
      "112 27 4.15\n",
      "129 36 3.58\n",
      "386 93 4.15\n",
      "226 47 4.81\n",
      "270 69 3.91\n",
      "343 77 4.45\n",
      "422 113 3.73\n",
      "171 45 3.8\n",
      "540 134 4.03\n",
      "335 73 4.59\n",
      "259 63 4.11\n",
      "293 69 4.25\n",
      "103 27 3.81\n",
      "185 43 4.3\n",
      "153 35 4.37\n",
      "325 79 4.11\n",
      "277 65 4.26\n",
      "73 20 3.65\n",
      "433 109 3.97\n",
      "245 61 4.02\n",
      "354 74 4.78\n",
      "129 36 3.58\n",
      "376 98 3.84\n",
      "232 58 4.0\n",
      "595 132 4.51\n",
      "267 52 5.13\n",
      "475 96 4.95\n",
      "154 34 4.53\n",
      "201 50 4.02\n",
      "259 63 4.11\n",
      "83 23 3.61\n",
      "112 22 5.09\n",
      "187 41 4.56\n",
      "327 89 3.67\n",
      "143 41 3.49\n",
      "480 108 4.44\n",
      "380 94 4.04\n",
      "391 89 4.39\n",
      "166 36 4.61\n",
      "440 118 3.73\n",
      "160 41 3.9\n",
      "123 29 4.24\n",
      "141 30 4.7\n",
      "181 40 4.53\n",
      "392 107 3.66\n"
     ]
    }
   ],
   "source": [
    "l0s = 0\n",
    "l1s=0\n",
    "for i in  range(100):\n",
    "    state,info = test_env.reset()\n",
    "    h0 = test_env.history[0]\n",
    "    l1 = len(tokenizer(h0.text)['input_ids'])\n",
    "    l0 = len(h0.text)\n",
    "    l0s+=l0\n",
    "    l1s+=l1\n",
    "    print(l0,l1,round(l0/l1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "5233ed7c-4d59-46a6-bd24-9fe5ea2e2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2502\n",
      "2502\n",
      "2502\n",
      "2502\n",
      "2502\n"
     ]
    }
   ],
   "source": [
    "state,info = test_env.reset()\n",
    "h0 = test_env.history[0]\n",
    "solo_mask = h0.text.replace(h0.target,'<mask>',1)\n",
    "mask_text = ''\n",
    "for i,(word,score) in enumerate(h0.substitutes[:5]):\n",
    "    print(len(h0.text)*6)\n",
    "    if len(h0.text)*6<2100:\n",
    "        text = h0.text\n",
    "    else:\n",
    "        subtract_len = len(h0.text)-350\n",
    "        index = h0.text.index(h0.target)\n",
    "        post_sub_index = max(len(h0.text)-subtract_len,index+20)\n",
    "        if i%2==0:\n",
    "            pre_sub_index = min(0+subtract_len,index-20)\n",
    "            text = h0.text[pre_sub_index:]\n",
    "    if len(tokenizer(mask_text+text+solo_mask)['input_ids'])>512:\n",
    "        break\n",
    "    mask_text += text\n",
    "mask_text  += solo_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "82fe1ec7-6e32-4a45-a3af-dd1ac4c72bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.The problem was that I have trouble distinguishing between\\n                    compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, <mask> only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.\""
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "a34ff1be-25f3-450e-a345-2f3e42b1f199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2084"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "92cce71c-9380-4bfb-bf49-d7d497adef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "acef1d04-5afd-491b-8882-a39718b6a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "07d3f2ac-4b8b-4503-9e36-ef8473b70c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "400e399a-712b-4bc1-878c-67fa88ce211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_text = (text*12)[:-23]+ '<mask>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "cb1ea2f5-1ae4-4cdb-809d-85a6e1e6a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer(m_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "d36a8682-3794-460b-9f02-ee20fc081ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "6f7cd642-860d-4a5d-a5f6-c5af65e6e2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8441550135612488,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,'},\n",
       " {'score': 0.11659591645002365,\n",
       "  'token': 4,\n",
       "  'token_str': ',',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,,'},\n",
       " {'score': 0.008581217378377914,\n",
       "  'token': 27,\n",
       "  'token_str': '...',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,...'},\n",
       " {'score': 0.0016685021109879017,\n",
       "  'token': 122880,\n",
       "  'token_str': 'More',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,More'},\n",
       " {'score': 0.001654961844906211,\n",
       "  'token': 19659,\n",
       "  'token_str': 'As',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,As'}]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(m_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f43a9a71-cd1b-4ce5-be49-376b1d21795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2099.2"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512*4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7e0f3d33-64be-455f-b6d8-9e29feb2848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350.0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2100/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a4836d14-a1ea-4461-a11c-476147523d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.199420569773056"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l0s/l1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "11799913-5c24-48ab-91a4-68674483d867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1559"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a3cf02aa-f675-42ed-bab0-2c43ef855d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 387)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0.text.index(h0.target),len(h0.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6e6f55e4-1516-45d2-8fd6-6fb2aaa3c438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512 - len(h0.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6faa4248-9c78-45b0-92f2-d30372e16b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3b4cd41-1196-4772-a0e5-547df069f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3f9ee-abf3-49c9-93ea-239e125c6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.AutoModelForMaskedLM("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3658acbe-810b-4309-8b68-b44b1ee0792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbe8242b-0ea8-499c-a7f0-e1481ceec8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe3d9fe6-ff6e-465b-b5f5-8ca8c458e9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea3f62a5-5adf-4a81-87a3-26692355288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# forward pass\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b19e111f-be61-47dc-b9c9-5f1cc09850f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ 6.4861e+01,  1.6882e-02,  3.7656e+01,  ...,  2.1584e+01,\n",
       "           1.4380e+01,  1.8790e+01],\n",
       "         [ 2.7493e+01, -1.4091e+00,  6.4847e+01,  ...,  4.0234e+01,\n",
       "           1.6296e+01,  3.0925e+01],\n",
       "         [ 1.9604e+01, -1.2597e+00,  4.8981e+01,  ...,  3.5830e+01,\n",
       "           1.7145e+01,  2.7173e+01],\n",
       "         ...,\n",
       "         [ 2.2920e+01, -1.4657e+00,  5.1211e+01,  ...,  3.8495e+01,\n",
       "           1.6508e+01,  2.7687e+01],\n",
       "         [ 2.8598e+01, -1.2868e+00,  6.7706e+01,  ...,  4.4857e+01,\n",
       "           1.8004e+01,  3.5004e+01],\n",
       "         [ 4.4955e+01, -2.1554e-01,  4.9643e+01,  ...,  2.8253e+01,\n",
       "           1.6841e+01,  2.3610e+01]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5db2c37a-a78d-49d1-9a6b-f9f3ab131b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForMaskedLM"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e735b-0ede-4ec2-be41-1da2b2ffca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    predictions = outputs.logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "65983169-e35a-422e-8062-6df8d1f9398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 16:07:54.349083: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-17 16:07:54.349119: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import FillMaskPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a8f49495-ce6e-4f29-80ea-6a75bbb84950",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EmbeddingModel' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142/1315868084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFillMaskPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, image_processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m     ):\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_framework_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EmbeddingModel' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "mask_pipeline = FillMaskPipeline(model=env.model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d0b98934-a79b-4ddd-b4a9-5685596f5cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.07687385380268097,\n",
       "  'token': 34923,\n",
       "  'token_str': 'beautiful',\n",
       "  'sequence': 'this is a beautiful car'},\n",
       " {'score': 0.04615773260593414,\n",
       "  'token': 29681,\n",
       "  'token_str': 'sports',\n",
       "  'sequence': 'this is a sports car'},\n",
       " {'score': 0.03222648799419403,\n",
       "  'token': 54704,\n",
       "  'token_str': 'classic',\n",
       "  'sequence': 'this is a classic car'},\n",
       " {'score': 0.031460631638765335,\n",
       "  'token': 6782,\n",
       "  'token_str': 'great',\n",
       "  'sequence': 'this is a great car'},\n",
       " {'score': 0.030774081125855446,\n",
       "  'token': 26267,\n",
       "  'token_str': 'nice',\n",
       "  'sequence': 'this is a nice car'}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_pipeline(\"this is a <mask> car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db5c451f-564e-43aa-aeb2-6dfaa73e9c45",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaModel(\n",
       "  (embeddings): XLMRobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): XLMRobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): XLMRobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a481806c-5179-4fdf-aaec-d99a73a87260",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForMaskedLM(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): XLMRobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=250002, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ace047-ea17-4956-9370-fec2002d8018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
