{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0ce38283-09c8-447a-9693-bde6760a5848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gymnasium as gym\n",
    "from imp import reload\n",
    "\n",
    "import rl_dqn\n",
    "import environment\n",
    "import embedding\n",
    "import rl_utils\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "from rl_dqn import ReplayMemory, DQN, Transition, RLModel\n",
    "from embedding import EmbeddingModel\n",
    "from environment import Dataset, DialougeEnv, User, Agent\n",
    "import rl_dqn\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "reload(embedding)\n",
    "from embedding import EmbeddingModel\n",
    "\n",
    "embedding_model = EmbeddingModel(device)\n",
    "\n",
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='xlm-roberta-base',framework='pt', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "100ce60b-de12-4398-9f04-04d572b68057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reload(rl_dqn)\n",
    "reload(environment)\n",
    "reload(embedding)\n",
    "\n",
    "\n",
    "import environment\n",
    "reload(environment)\n",
    "\n",
    "test_data = environment.Dataset('data/swords-v1.1_dev.json.gz')\n",
    "train_data = environment.Dataset('data/swords-v1.1_test.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7431a43e-f1ca-40c5-8217-61a11ae060c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/zhangdapao5130/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/zhangdapao5130/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "reload(environment)\n",
    "reload(rl_utils)\n",
    "\n",
    "test_env = environment.DialougeEnv(test_data,embedding_model, unmasker,device)\n",
    "train_env = environment.DialougeEnv(train_data, embedding_model, unmasker,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "73ee14b5-6f7a-4b10-ad04-a45d9673fe3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reload(rl_dqn)\n",
    "rl_model = rl_dqn.RLModel(train_env,test_env, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c92e42-6bef-4e35-ab5c-e5d95fc515c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL Training:   0%|          | 0/3000 [00:00<?, ?it/s]\n",
      "eva test::   0%|          | 0/370 [00:00<?, ?it/s]\u001b[A\n",
      "eva test::   1%|          | 2/370 [00:03<09:16,  1.51s/it]\u001b[A\n",
      "eva test::   1%|          | 4/370 [00:08<14:01,  2.30s/it]\u001b[A\n",
      "eva test::   2%|▏         | 8/370 [00:12<08:17,  1.37s/it]\u001b[A\n",
      "eva test::   3%|▎         | 11/370 [00:22<13:20,  2.23s/it]\u001b[A\n",
      "eva test::   3%|▎         | 12/370 [00:26<14:39,  2.46s/it]\u001b[A\n",
      "eva test::   4%|▍         | 14/370 [00:30<14:25,  2.43s/it]\u001b[A\n",
      "eva test::   4%|▍         | 16/370 [00:35<14:06,  2.39s/it]\u001b[A\n",
      "eva test::   5%|▍         | 18/370 [00:38<12:41,  2.16s/it]\u001b[A\n",
      "eva test::   5%|▌         | 20/370 [00:42<11:58,  2.05s/it]\u001b[A\n",
      "eva test::   6%|▌         | 22/370 [00:46<11:31,  1.99s/it]\u001b[A\n",
      "eva test::   6%|▋         | 24/370 [00:50<11:58,  2.08s/it]\u001b[A\n",
      "eva test::   7%|▋         | 26/370 [00:53<11:02,  1.93s/it]\u001b[A\n",
      "eva test::   8%|▊         | 28/370 [01:00<13:07,  2.30s/it]\u001b[A\n",
      "eva test::   8%|▊         | 30/370 [01:03<11:49,  2.09s/it]\u001b[A\n",
      "eva test::   9%|▉         | 33/370 [01:07<10:29,  1.87s/it]\u001b[A\n",
      "eva test::  10%|█         | 38/370 [01:13<08:17,  1.50s/it]\u001b[A\n",
      "eva test::  11%|█         | 40/370 [01:19<10:16,  1.87s/it]\u001b[A\n",
      "eva test::  11%|█▏        | 42/370 [01:23<09:59,  1.83s/it]\u001b[A\n",
      "eva test::  12%|█▏        | 44/370 [01:30<12:07,  2.23s/it]\u001b[A\n",
      "eva test::  12%|█▏        | 46/370 [01:36<13:39,  2.53s/it]\u001b[A\n",
      "eva test::  13%|█▎        | 49/370 [01:41<11:56,  2.23s/it]\u001b[A\n",
      "eva test::  14%|█▍        | 52/370 [01:45<09:41,  1.83s/it]\u001b[A\n",
      "eva test::  15%|█▍        | 54/370 [01:52<12:01,  2.28s/it]\u001b[A\n",
      "eva test::  15%|█▌        | 56/370 [01:56<11:33,  2.21s/it]\u001b[A\n",
      "eva test::  16%|█▌        | 58/370 [02:04<13:57,  2.68s/it]\u001b[A\n",
      "eva test::  16%|█▌        | 60/370 [02:08<12:59,  2.52s/it]\u001b[A\n",
      "eva test::  17%|█▋        | 62/370 [02:11<11:35,  2.26s/it]\u001b[A\n",
      "eva test::  17%|█▋        | 64/370 [02:15<10:48,  2.12s/it]\u001b[A\n",
      "eva test::  18%|█▊        | 66/370 [02:20<11:42,  2.31s/it]\u001b[A\n",
      "eva test::  18%|█▊        | 68/370 [02:27<13:00,  2.59s/it]\u001b[A\n",
      "eva test::  19%|█▉        | 70/370 [02:31<11:48,  2.36s/it]\u001b[A\n",
      "eva test::  20%|██        | 75/370 [02:36<08:19,  1.69s/it]\u001b[A\n",
      "eva test::  21%|██        | 78/370 [02:42<08:52,  1.82s/it]\u001b[A\n",
      "eva test::  22%|██▏       | 80/370 [02:45<08:36,  1.78s/it]\u001b[A\n",
      "eva test::  22%|██▏       | 82/370 [02:52<10:12,  2.13s/it]\u001b[A\n",
      "eva test::  23%|██▎       | 84/370 [02:56<10:05,  2.12s/it]\u001b[A\n",
      "eva test::  23%|██▎       | 86/370 [03:01<10:39,  2.25s/it]\u001b[A\n",
      "eva test::  24%|██▍       | 88/370 [03:07<11:19,  2.41s/it]\u001b[A\n",
      "eva test::  25%|██▍       | 91/370 [03:12<10:02,  2.16s/it]\u001b[A\n",
      "eva test::  25%|██▌       | 93/370 [03:16<09:30,  2.06s/it]\u001b[A\n",
      "eva test::  26%|██▌       | 95/370 [03:20<09:19,  2.03s/it]\u001b[A\n",
      "eva test::  26%|██▋       | 98/370 [03:25<08:47,  1.94s/it]\u001b[A\n",
      "eva test::  27%|██▋       | 100/370 [03:31<10:02,  2.23s/it]\u001b[A\n",
      "eva test::  28%|██▊       | 102/370 [03:35<09:42,  2.17s/it]\u001b[A\n",
      "eva test::  28%|██▊       | 104/370 [03:42<11:30,  2.59s/it]\u001b[A\n",
      "eva test::  29%|██▊       | 106/370 [03:48<11:36,  2.64s/it]\u001b[A\n",
      "eva test::  29%|██▉       | 108/370 [03:56<13:02,  2.99s/it]\u001b[A\n",
      "eva test::  30%|██▉       | 110/370 [04:01<12:48,  2.96s/it]\u001b[A\n",
      "eva test::  31%|███       | 113/370 [04:05<09:37,  2.25s/it]\u001b[A\n",
      "eva test::  31%|███       | 115/370 [04:08<08:53,  2.09s/it]\u001b[A\n",
      "eva test::  32%|███▏      | 117/370 [04:11<08:09,  1.93s/it]\u001b[A\n",
      "eva test::  32%|███▏      | 119/370 [04:18<09:54,  2.37s/it]\u001b[A\n",
      "eva test::  33%|███▎      | 121/370 [04:24<10:29,  2.53s/it]\u001b[A\n",
      "eva test::  34%|███▎      | 124/370 [04:28<08:40,  2.12s/it]\u001b[A\n",
      "eva test::  34%|███▍      | 126/370 [04:35<09:54,  2.44s/it]\u001b[A\n",
      "eva test::  35%|███▍      | 128/370 [04:39<09:33,  2.37s/it]\u001b[A\n",
      "eva test::  35%|███▌      | 130/370 [04:42<08:30,  2.13s/it]\u001b[A\n",
      "eva test::  36%|███▌      | 134/370 [04:49<07:23,  1.88s/it]\u001b[A\n",
      "eva test::  37%|███▋      | 136/370 [04:55<08:46,  2.25s/it]\u001b[A\n",
      "eva test::  37%|███▋      | 138/370 [05:03<10:03,  2.60s/it]\u001b[A\n",
      "eva test::  38%|███▊      | 142/370 [05:08<07:50,  2.06s/it]\u001b[A\n",
      "eva test::  39%|███▉      | 145/370 [05:11<06:32,  1.74s/it]\u001b[A\n",
      "eva test::  40%|███▉      | 147/370 [05:19<08:27,  2.28s/it]\u001b[A\n",
      "eva test::  40%|████      | 149/370 [05:26<09:15,  2.51s/it]\u001b[A\n",
      "eva test::  41%|████      | 151/370 [05:32<09:51,  2.70s/it]\u001b[A\n",
      "eva test::  41%|████▏     | 153/370 [05:37<09:34,  2.65s/it]\u001b[A\n",
      "eva test::  42%|████▏     | 155/370 [05:44<10:11,  2.85s/it]\u001b[A\n",
      "eva test::  42%|████▏     | 157/370 [05:47<08:56,  2.52s/it]\u001b[A\n",
      "eva test::  43%|████▎     | 159/370 [05:54<09:56,  2.83s/it]\u001b[A\n",
      "eva test::  44%|████▎     | 161/370 [05:59<09:00,  2.59s/it]\u001b[A\n",
      "eva test::  44%|████▍     | 163/370 [06:02<08:01,  2.32s/it]\u001b[A\n",
      "eva test::  45%|████▍     | 165/370 [06:06<07:39,  2.24s/it]\u001b[A\n",
      "eva test::  45%|████▌     | 167/370 [06:10<07:12,  2.13s/it]\u001b[A\n",
      "eva test::  46%|████▌     | 169/370 [06:13<06:49,  2.04s/it]\u001b[A\n",
      "eva test::  46%|████▌     | 171/370 [06:17<06:37,  2.00s/it]\u001b[A\n",
      "eva test::  47%|████▋     | 174/370 [06:22<05:50,  1.79s/it]\u001b[A\n",
      "eva test::  48%|████▊     | 176/370 [06:27<06:35,  2.04s/it]\u001b[A\n",
      "eva test::  48%|████▊     | 178/370 [06:31<06:26,  2.01s/it]\u001b[A\n",
      "eva test::  49%|████▊     | 180/370 [06:37<07:12,  2.27s/it]\u001b[A\n",
      "eva test::  49%|████▉     | 182/370 [06:44<08:18,  2.65s/it]\u001b[A\n",
      "eva test::  50%|████▉     | 184/370 [06:51<08:52,  2.86s/it]\u001b[A\n",
      "eva test::  50%|█████     | 186/370 [06:57<09:00,  2.94s/it]\u001b[A\n",
      "eva test::  51%|█████     | 188/370 [07:02<08:44,  2.88s/it]\u001b[A\n",
      "eva test::  51%|█████▏    | 190/370 [07:06<07:37,  2.54s/it]\u001b[A\n",
      "eva test::  52%|█████▏    | 192/370 [07:13<08:32,  2.88s/it]\u001b[A\n",
      "eva test::  52%|█████▏    | 194/370 [07:17<07:46,  2.65s/it]\u001b[A\n",
      "eva test::  53%|█████▎    | 196/370 [07:21<07:01,  2.43s/it]\u001b[A\n",
      "eva test::  54%|█████▎    | 198/370 [07:28<07:55,  2.77s/it]\u001b[A\n",
      "eva test::  54%|█████▍    | 200/370 [07:32<07:07,  2.51s/it]\u001b[A\n",
      "eva test::  55%|█████▍    | 203/370 [07:36<05:43,  2.05s/it]\u001b[A\n",
      "eva test::  55%|█████▌    | 205/370 [07:42<06:14,  2.27s/it]\u001b[A\n",
      "eva test::  56%|█████▌    | 207/370 [07:49<07:15,  2.67s/it]\u001b[A\n",
      "eva test::  56%|█████▋    | 209/370 [07:54<06:56,  2.59s/it]\u001b[A\n",
      "eva test::  57%|█████▋    | 211/370 [07:58<06:32,  2.47s/it]\u001b[A\n",
      "eva test::  58%|█████▊    | 213/370 [08:04<06:40,  2.55s/it]\u001b[A\n",
      "eva test::  58%|█████▊    | 215/370 [08:09<06:28,  2.50s/it]\u001b[A\n",
      "eva test::  59%|█████▊    | 217/370 [08:13<06:13,  2.44s/it]\u001b[A\n",
      "eva test::  59%|█████▉    | 219/370 [08:20<06:47,  2.70s/it]\u001b[A\n",
      "eva test::  60%|█████▉    | 221/370 [08:24<06:02,  2.43s/it]\u001b[A\n",
      "eva test::  60%|██████    | 223/370 [08:28<05:43,  2.33s/it]\u001b[A\n",
      "eva test::  61%|██████    | 225/370 [08:32<05:29,  2.27s/it]\u001b[A\n",
      "eva test::  61%|██████▏   | 227/370 [08:39<06:28,  2.72s/it]\u001b[A\n",
      "eva test::  63%|██████▎   | 232/370 [08:44<03:59,  1.74s/it]\u001b[A\n",
      "eva test::  63%|██████▎   | 234/370 [08:49<04:32,  2.00s/it]\u001b[A\n",
      "eva test::  64%|██████▍   | 236/370 [08:58<05:46,  2.59s/it]\u001b[A\n",
      "eva test::  64%|██████▍   | 238/370 [09:04<05:58,  2.72s/it]\u001b[A\n",
      "eva test::  65%|██████▍   | 240/370 [09:08<05:18,  2.45s/it]\u001b[A\n",
      "eva test::  65%|██████▌   | 242/370 [09:16<06:06,  2.87s/it]\u001b[A\n",
      "eva test::  66%|██████▌   | 244/370 [09:21<05:54,  2.81s/it]\u001b[A\n",
      "eva test::  66%|██████▋   | 246/370 [09:25<05:21,  2.59s/it]\u001b[A\n",
      "eva test::  67%|██████▋   | 248/370 [09:29<04:45,  2.34s/it]\u001b[A\n",
      "eva test::  68%|██████▊   | 251/370 [09:33<03:59,  2.02s/it]\u001b[A\n",
      "eva test::  68%|██████▊   | 253/370 [09:40<04:40,  2.40s/it]\u001b[A\n",
      "eva test::  69%|██████▉   | 255/370 [09:46<05:03,  2.64s/it]\u001b[A\n",
      "eva test::  69%|██████▉   | 257/370 [09:53<05:11,  2.76s/it]\u001b[A\n",
      "eva test::  70%|███████   | 259/370 [09:59<05:13,  2.83s/it]\u001b[A\n",
      "eva test::  71%|███████   | 262/370 [10:02<03:51,  2.14s/it]\u001b[A\n",
      "eva test::  71%|███████▏  | 264/370 [10:06<03:42,  2.10s/it]\u001b[A\n",
      "eva test::  72%|███████▏  | 266/370 [10:09<03:21,  1.94s/it]\u001b[A\n",
      "eva test::  72%|███████▏  | 268/370 [10:13<03:26,  2.02s/it]\u001b[A\n",
      "eva test::  74%|███████▎  | 272/370 [10:18<02:46,  1.70s/it]\u001b[A\n",
      "eva test::  74%|███████▍  | 274/370 [10:24<03:10,  1.98s/it]\u001b[A\n",
      "eva test::  75%|███████▍  | 276/370 [10:28<03:06,  1.98s/it]\u001b[A\n",
      "eva test::  75%|███████▌  | 278/370 [10:33<03:12,  2.09s/it]\u001b[A\n",
      "eva test::  76%|███████▌  | 280/370 [10:42<04:06,  2.74s/it]\u001b[A\n",
      "eva test::  76%|███████▌  | 282/370 [10:49<04:23,  2.99s/it]\u001b[A\n",
      "eva test::  77%|███████▋  | 284/370 [10:54<04:11,  2.93s/it]\u001b[A\n",
      "eva test::  77%|███████▋  | 286/370 [11:01<04:13,  3.01s/it]\u001b[A\n",
      "eva test::  78%|███████▊  | 288/370 [11:05<03:43,  2.72s/it]\u001b[A\n",
      "eva test::  78%|███████▊  | 290/370 [11:13<04:13,  3.16s/it]\u001b[A\n",
      "eva test::  79%|███████▉  | 292/370 [11:20<04:10,  3.21s/it]\u001b[A\n",
      "eva test::  79%|███████▉  | 294/370 [11:24<03:31,  2.79s/it]\u001b[A\n",
      "eva test::  80%|████████  | 296/370 [11:27<03:01,  2.46s/it]\u001b[A\n",
      "eva test::  81%|████████  | 298/370 [11:33<03:06,  2.59s/it]\u001b[A\n",
      "eva test::  81%|████████  | 300/370 [11:37<02:49,  2.42s/it]\u001b[A\n",
      "eva test::  82%|████████▏ | 302/370 [11:41<02:34,  2.27s/it]\u001b[A\n",
      "eva test::  82%|████████▏ | 304/370 [11:44<02:19,  2.12s/it]\u001b[A\n",
      "eva test::  83%|████████▎ | 306/370 [11:52<02:45,  2.58s/it]\u001b[A\n",
      "eva test::  83%|████████▎ | 308/370 [11:59<02:57,  2.86s/it]\u001b[A\n",
      "eva test::  84%|████████▍ | 310/370 [12:03<02:42,  2.72s/it]\u001b[A\n",
      "eva test::  84%|████████▍ | 312/370 [12:07<02:20,  2.43s/it]\u001b[A\n",
      "eva test::  85%|████████▍ | 314/370 [12:12<02:15,  2.41s/it]\u001b[A\n",
      "eva test::  85%|████████▌ | 316/370 [12:15<02:02,  2.27s/it]\u001b[A\n",
      "eva test::  86%|████████▌ | 319/370 [12:19<01:32,  1.80s/it]\u001b[A\n",
      "eva test::  87%|████████▋ | 321/370 [12:23<01:33,  1.91s/it]\u001b[A\n",
      "eva test::  87%|████████▋ | 323/370 [12:30<01:50,  2.35s/it]\u001b[A\n",
      "eva test::  88%|████████▊ | 325/370 [12:34<01:40,  2.22s/it]\u001b[A\n",
      "eva test::  88%|████████▊ | 327/370 [12:38<01:30,  2.11s/it]\u001b[A\n",
      "eva test::  89%|████████▉ | 329/370 [12:44<01:41,  2.48s/it]\u001b[A\n",
      "eva test::  89%|████████▉ | 331/370 [12:49<01:33,  2.39s/it]\u001b[A\n",
      "eva test::  90%|█████████ | 333/370 [12:52<01:22,  2.23s/it]\u001b[A\n",
      "eva test::  91%|█████████ | 335/370 [13:00<01:32,  2.65s/it]\u001b[A\n",
      "eva test::  91%|█████████ | 337/370 [13:06<01:34,  2.87s/it]\u001b[A\n",
      "eva test::  92%|█████████▏| 339/370 [13:10<01:21,  2.62s/it]\u001b[A\n",
      "eva test::  92%|█████████▏| 341/370 [13:17<01:22,  2.84s/it]\u001b[A\n",
      "eva test::  93%|█████████▎| 344/370 [13:22<01:02,  2.42s/it]\u001b[A\n",
      "eva test::  94%|█████████▎| 346/370 [13:26<00:53,  2.25s/it]\u001b[A\n",
      "eva test::  94%|█████████▍| 348/370 [13:32<00:53,  2.42s/it]\u001b[A\n",
      "eva test::  95%|█████████▍| 350/370 [13:36<00:47,  2.35s/it]\u001b[A\n",
      "eva test::  95%|█████████▌| 352/370 [13:42<00:45,  2.53s/it]\u001b[A\n",
      "eva test::  96%|█████████▌| 354/370 [13:48<00:42,  2.65s/it]\u001b[A\n",
      "eva test::  96%|█████████▌| 356/370 [13:54<00:39,  2.82s/it]\u001b[A\n",
      "eva test::  97%|█████████▋| 358/370 [13:59<00:31,  2.65s/it]\u001b[A\n",
      "eva test::  97%|█████████▋| 360/370 [14:03<00:24,  2.46s/it]\u001b[A\n",
      "eva test::  98%|█████████▊| 362/370 [14:08<00:19,  2.48s/it]\u001b[A\n",
      "eva test::  98%|█████████▊| 364/370 [14:13<00:14,  2.42s/it]\u001b[A\n",
      "eva test::  99%|█████████▉| 366/370 [14:18<00:10,  2.50s/it]\u001b[A\n",
      "eva test::  99%|█████████▉| 368/370 [14:22<00:04,  2.43s/it]\u001b[A\n",
      "eva test:: 100%|██████████| 370/370 [14:28<00:00,  2.35s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1662.7999999999633 0.09390547263681592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "eva train::   0%|          | 0/762 [00:00<?, ?it/s]\u001b[A\n",
      "eva train::   0%|          | 2/762 [00:03<24:21,  1.92s/it]\u001b[A\n",
      "eva train::   1%|          | 4/762 [00:10<34:14,  2.71s/it]\u001b[A\n",
      "eva train::   1%|          | 6/762 [00:13<27:51,  2.21s/it]\u001b[A\n",
      "eva train::   1%|          | 8/762 [00:16<24:30,  1.95s/it]\u001b[A\n",
      "eva train::   1%|▏         | 10/762 [00:23<30:29,  2.43s/it]\u001b[A\n",
      "eva train::   2%|▏         | 12/762 [00:30<36:28,  2.92s/it]\u001b[A\n",
      "eva train::   2%|▏         | 14/762 [00:37<37:20,  2.99s/it]\u001b[A\n",
      "eva train::   2%|▏         | 16/762 [00:40<31:57,  2.57s/it]\u001b[A\n",
      "eva train::   2%|▏         | 18/762 [00:46<33:20,  2.69s/it]\u001b[A\n",
      "eva train::   3%|▎         | 20/762 [00:51<31:36,  2.56s/it]\u001b[A\n",
      "eva train::   3%|▎         | 22/762 [00:59<37:03,  3.00s/it]\u001b[A\n",
      "eva train::   3%|▎         | 24/762 [01:03<34:47,  2.83s/it]\u001b[A\n",
      "eva train::   3%|▎         | 26/762 [01:09<33:42,  2.75s/it]\u001b[A\n",
      "eva train::   4%|▎         | 28/762 [01:12<29:35,  2.42s/it]\u001b[A\n",
      "eva train::   4%|▍         | 30/762 [01:17<30:16,  2.48s/it]\u001b[A\n",
      "eva train::   4%|▍         | 32/762 [01:23<31:14,  2.57s/it]\u001b[A\n",
      "eva train::   4%|▍         | 34/762 [01:28<30:58,  2.55s/it]\u001b[A\n",
      "eva train::   5%|▍         | 36/762 [01:33<30:19,  2.51s/it]\u001b[A\n",
      "eva train::   5%|▍         | 38/762 [01:40<34:35,  2.87s/it]\u001b[A\n",
      "eva train::   5%|▌         | 40/762 [01:46<35:17,  2.93s/it]\u001b[A\n",
      "eva train::   6%|▌         | 42/762 [01:51<33:18,  2.78s/it]\u001b[A\n",
      "eva train::   6%|▌         | 44/762 [01:54<29:26,  2.46s/it]\u001b[A\n",
      "eva train::   6%|▌         | 46/762 [02:00<29:45,  2.49s/it]\u001b[A\n",
      "eva train::   6%|▋         | 48/762 [02:03<27:53,  2.34s/it]\u001b[A\n",
      "eva train::   7%|▋         | 50/762 [02:11<32:42,  2.76s/it]\u001b[A\n",
      "eva train::   7%|▋         | 52/762 [02:18<35:45,  3.02s/it]\u001b[A\n",
      "eva train::   7%|▋         | 55/762 [02:22<28:00,  2.38s/it]\u001b[A\n",
      "eva train::   7%|▋         | 57/762 [02:28<28:46,  2.45s/it]\u001b[A\n",
      "eva train::   8%|▊         | 59/762 [02:33<28:57,  2.47s/it]\u001b[A\n",
      "eva train::   8%|▊         | 61/762 [02:40<32:45,  2.80s/it]\u001b[A\n",
      "eva train::   8%|▊         | 63/762 [02:43<28:34,  2.45s/it]\u001b[A\n",
      "eva train::   9%|▊         | 65/762 [02:46<25:22,  2.18s/it]\u001b[A\n",
      "eva train::   9%|▉         | 67/762 [02:53<29:55,  2.58s/it]\u001b[A\n",
      "eva train::   9%|▉         | 69/762 [02:58<28:23,  2.46s/it]\u001b[A\n",
      "eva train::   9%|▉         | 72/762 [03:01<22:24,  1.95s/it]\u001b[A\n",
      "eva train::  10%|▉         | 74/762 [03:06<24:07,  2.10s/it]\u001b[A\n",
      "eva train::  10%|█         | 77/762 [03:12<22:46,  2.00s/it]\u001b[A\n",
      "eva train::  10%|█         | 80/762 [03:17<21:46,  1.92s/it]\u001b[A\n",
      "eva train::  11%|█         | 82/762 [03:24<26:17,  2.32s/it]\u001b[A\n",
      "eva train::  11%|█         | 84/762 [03:28<24:42,  2.19s/it]\u001b[A\n",
      "eva train::  11%|█▏        | 86/762 [03:32<24:22,  2.16s/it]\u001b[A\n",
      "eva train::  12%|█▏        | 88/762 [03:38<27:16,  2.43s/it]\u001b[A\n",
      "eva train::  12%|█▏        | 90/762 [03:43<28:17,  2.53s/it]\u001b[A\n",
      "eva train::  12%|█▏        | 92/762 [03:47<25:53,  2.32s/it]\u001b[A\n",
      "eva train::  12%|█▏        | 94/762 [03:53<28:16,  2.54s/it]\u001b[A\n",
      "eva train::  13%|█▎        | 96/762 [04:01<32:06,  2.89s/it]\u001b[A\n",
      "eva train::  13%|█▎        | 99/762 [04:08<29:19,  2.65s/it]\u001b[A\n",
      "eva train::  13%|█▎        | 101/762 [04:16<33:55,  3.08s/it]\u001b[A\n",
      "eva train::  14%|█▎        | 103/762 [04:20<30:57,  2.82s/it]\u001b[A\n",
      "eva train::  14%|█▍        | 105/762 [04:24<27:34,  2.52s/it]\u001b[A\n",
      "eva train::  14%|█▍        | 107/762 [04:28<25:56,  2.38s/it]\u001b[A\n",
      "eva train::  14%|█▍        | 109/762 [04:33<26:41,  2.45s/it]\u001b[A\n",
      "eva train::  15%|█▍        | 111/762 [04:40<29:58,  2.76s/it]\u001b[A\n",
      "eva train::  15%|█▍        | 113/762 [04:46<30:10,  2.79s/it]\u001b[A\n",
      "eva train::  15%|█▌        | 115/762 [04:50<27:46,  2.58s/it]\u001b[A\n",
      "eva train::  15%|█▌        | 117/762 [04:56<28:43,  2.67s/it]\u001b[A\n",
      "eva train::  16%|█▌        | 119/762 [05:03<31:08,  2.91s/it]\u001b[A\n",
      "eva train::  16%|█▌        | 121/762 [05:08<30:57,  2.90s/it]\u001b[A\n",
      "eva train::  16%|█▌        | 123/762 [05:14<30:07,  2.83s/it]\u001b[A\n",
      "eva train::  16%|█▋        | 125/762 [05:21<31:54,  3.01s/it]\u001b[A\n",
      "eva train::  17%|█▋        | 127/762 [05:28<33:37,  3.18s/it]\u001b[A\n",
      "eva train::  17%|█▋        | 129/762 [05:33<30:55,  2.93s/it]\u001b[A\n",
      "eva train::  17%|█▋        | 131/762 [05:37<28:10,  2.68s/it]\u001b[A\n",
      "eva train::  17%|█▋        | 133/762 [05:42<27:20,  2.61s/it]\u001b[A\n",
      "eva train::  18%|█▊        | 135/762 [05:47<27:18,  2.61s/it]\u001b[A\n",
      "eva train::  18%|█▊        | 137/762 [05:52<26:22,  2.53s/it]\u001b[A\n",
      "eva train::  18%|█▊        | 139/762 [05:59<29:36,  2.85s/it]\u001b[A\n",
      "eva train::  19%|█▊        | 141/762 [06:02<26:03,  2.52s/it]\u001b[A\n",
      "eva train::  19%|█▉        | 143/762 [06:09<29:13,  2.83s/it]\u001b[A\n",
      "eva train::  19%|█▉        | 145/762 [06:15<28:42,  2.79s/it]\u001b[A\n",
      "eva train::  19%|█▉        | 147/762 [06:22<30:44,  3.00s/it]\u001b[A\n",
      "eva train::  20%|█▉        | 149/762 [06:27<29:39,  2.90s/it]\u001b[A\n",
      "eva train::  20%|█▉        | 151/762 [06:30<25:31,  2.51s/it]\u001b[A\n",
      "eva train::  20%|██        | 153/762 [06:37<27:55,  2.75s/it]\u001b[A\n",
      "eva train::  20%|██        | 156/762 [06:43<24:39,  2.44s/it]\u001b[A\n",
      "eva train::  21%|██        | 158/762 [06:47<23:42,  2.36s/it]\u001b[A\n",
      "eva train::  21%|██        | 160/762 [06:51<22:15,  2.22s/it]\u001b[A\n",
      "eva train::  21%|██▏       | 162/762 [06:55<21:15,  2.13s/it]\u001b[A\n",
      "eva train::  22%|██▏       | 164/762 [06:58<19:39,  1.97s/it]\u001b[A\n",
      "eva train::  22%|██▏       | 166/762 [07:05<23:56,  2.41s/it]\u001b[A\n",
      "eva train::  22%|██▏       | 168/762 [07:08<21:53,  2.21s/it]\u001b[A\n",
      "eva train::  22%|██▏       | 170/762 [07:11<20:10,  2.04s/it]\u001b[A\n",
      "eva train::  23%|██▎       | 173/762 [07:17<18:52,  1.92s/it]\u001b[A\n",
      "eva train::  23%|██▎       | 175/762 [07:21<19:25,  1.99s/it]\u001b[A\n",
      "eva train::  23%|██▎       | 177/762 [07:28<23:50,  2.44s/it]\u001b[A\n",
      "eva train::  24%|██▍       | 181/762 [07:33<18:52,  1.95s/it]\u001b[A\n",
      "eva train::  24%|██▍       | 185/762 [07:38<15:23,  1.60s/it]\u001b[A\n",
      "eva train::  25%|██▍       | 187/762 [07:43<17:50,  1.86s/it]\u001b[A\n",
      "eva train::  25%|██▍       | 189/762 [07:50<21:14,  2.22s/it]\u001b[A\n",
      "eva train::  25%|██▌       | 191/762 [07:57<23:43,  2.49s/it]\u001b[A\n",
      "eva train::  25%|██▌       | 193/762 [08:03<25:39,  2.71s/it]\u001b[A\n",
      "eva train::  26%|██▌       | 195/762 [08:09<25:36,  2.71s/it]\u001b[A\n",
      "eva train::  26%|██▌       | 197/762 [08:13<24:11,  2.57s/it]\u001b[A\n",
      "eva train::  26%|██▌       | 199/762 [08:18<24:15,  2.59s/it]\u001b[A\n",
      "eva train::  26%|██▋       | 201/762 [08:25<25:30,  2.73s/it]\u001b[A\n",
      "eva train::  27%|██▋       | 203/762 [08:29<23:51,  2.56s/it]\u001b[A\n",
      "eva train::  27%|██▋       | 205/762 [08:37<27:25,  2.95s/it]\u001b[A\n",
      "eva train::  27%|██▋       | 207/762 [08:43<28:14,  3.05s/it]\u001b[A\n",
      "eva train::  27%|██▋       | 209/762 [08:52<32:05,  3.48s/it]\u001b[A\n",
      "eva train::  28%|██▊       | 211/762 [08:55<26:49,  2.92s/it]\u001b[A\n",
      "eva train::  28%|██▊       | 213/762 [09:03<28:42,  3.14s/it]\u001b[A\n",
      "eva train::  28%|██▊       | 215/762 [09:07<26:22,  2.89s/it]\u001b[A\n",
      "eva train::  28%|██▊       | 217/762 [09:14<27:03,  2.98s/it]\u001b[A\n",
      "eva train::  29%|██▊       | 219/762 [09:17<23:20,  2.58s/it]\u001b[A\n",
      "eva train::  29%|██▉       | 221/762 [09:22<22:30,  2.50s/it]\u001b[A\n",
      "eva train::  29%|██▉       | 223/762 [09:26<21:09,  2.36s/it]\u001b[A\n",
      "eva train::  30%|██▉       | 225/762 [09:32<22:52,  2.56s/it]\u001b[A\n",
      "eva train::  30%|██▉       | 227/762 [09:35<20:56,  2.35s/it]\u001b[A\n",
      "eva train::  30%|███       | 229/762 [09:39<20:02,  2.26s/it]\u001b[A\n",
      "eva train::  30%|███       | 231/762 [09:43<18:54,  2.14s/it]\u001b[A\n",
      "eva train::  31%|███       | 233/762 [09:47<17:39,  2.00s/it]\u001b[A\n",
      "eva train::  31%|███       | 235/762 [09:50<17:07,  1.95s/it]\u001b[A\n",
      "eva train::  31%|███       | 237/762 [09:57<20:52,  2.39s/it]\u001b[A\n",
      "eva train::  31%|███▏      | 239/762 [10:01<19:19,  2.22s/it]\u001b[A\n",
      "eva train::  32%|███▏      | 241/762 [10:07<22:05,  2.54s/it]\u001b[A\n",
      "eva train::  32%|███▏      | 244/762 [10:12<18:27,  2.14s/it]\u001b[A\n",
      "eva train::  32%|███▏      | 246/762 [10:16<18:23,  2.14s/it]\u001b[A\n",
      "eva train::  33%|███▎      | 248/762 [10:21<19:34,  2.29s/it]\u001b[A\n",
      "eva train::  33%|███▎      | 250/762 [10:29<22:55,  2.69s/it]\u001b[A\n",
      "eva train::  33%|███▎      | 252/762 [10:32<20:17,  2.39s/it]\u001b[A\n",
      "eva train::  33%|███▎      | 254/762 [10:36<18:47,  2.22s/it]\u001b[A\n",
      "eva train::  34%|███▎      | 256/762 [10:39<17:04,  2.02s/it]\u001b[A\n",
      "eva train::  34%|███▍      | 258/762 [10:43<17:38,  2.10s/it]\u001b[A\n",
      "eva train::  34%|███▍      | 260/762 [10:48<18:04,  2.16s/it]\u001b[A\n",
      "eva train::  34%|███▍      | 262/762 [10:54<20:32,  2.46s/it]\u001b[A\n",
      "eva train::  35%|███▍      | 264/762 [11:01<22:06,  2.66s/it]\u001b[A\n",
      "eva train::  35%|███▍      | 266/762 [11:08<24:34,  2.97s/it]\u001b[A\n",
      "eva train::  35%|███▌      | 268/762 [11:14<24:30,  2.98s/it]\u001b[A\n",
      "eva train::  35%|███▌      | 270/762 [11:21<25:41,  3.13s/it]\u001b[A\n",
      "eva train::  36%|███▌      | 271/762 [11:24<25:59,  3.18s/it]\u001b[A\n",
      "eva train::  36%|███▌      | 272/762 [11:28<27:04,  3.31s/it]\u001b[A\n",
      "eva train::  36%|███▌      | 274/762 [11:31<21:56,  2.70s/it]\u001b[A\n",
      "eva train::  36%|███▌      | 276/762 [11:35<19:43,  2.43s/it]\u001b[A\n",
      "eva train::  36%|███▋      | 278/762 [11:42<22:26,  2.78s/it]\u001b[A\n",
      "eva train::  37%|███▋      | 280/762 [11:46<19:34,  2.44s/it]\u001b[A\n",
      "eva train::  37%|███▋      | 284/762 [11:52<16:04,  2.02s/it]\u001b[A\n",
      "eva train::  38%|███▊      | 286/762 [11:56<16:11,  2.04s/it]\u001b[A\n",
      "eva train::  38%|███▊      | 288/762 [12:03<19:12,  2.43s/it]\u001b[A\n",
      "eva train::  38%|███▊      | 290/762 [12:08<19:25,  2.47s/it]\u001b[A\n",
      "eva train::  38%|███▊      | 292/762 [12:15<20:48,  2.66s/it]\u001b[A\n",
      "eva train::  39%|███▊      | 294/762 [12:21<22:19,  2.86s/it]\u001b[A\n",
      "eva train::  39%|███▉      | 296/762 [12:25<20:22,  2.62s/it]\u001b[A\n",
      "eva train::  39%|███▉      | 298/762 [12:33<22:31,  2.91s/it]\u001b[A\n",
      "eva train::  39%|███▉      | 300/762 [12:36<19:24,  2.52s/it]\u001b[A\n",
      "eva train::  40%|███▉      | 302/762 [12:40<18:43,  2.44s/it]\u001b[A\n",
      "eva train::  40%|███▉      | 304/762 [12:45<18:35,  2.44s/it]\u001b[A\n",
      "eva train::  40%|████      | 307/762 [12:50<16:24,  2.16s/it]\u001b[A\n",
      "eva train::  41%|████      | 309/762 [12:55<16:46,  2.22s/it]\u001b[A\n",
      "eva train::  41%|████      | 311/762 [13:00<17:17,  2.30s/it]\u001b[A\n",
      "eva train::  41%|████      | 313/762 [13:07<19:29,  2.60s/it]\u001b[A\n",
      "eva train::  41%|████▏     | 316/762 [13:11<16:16,  2.19s/it]\u001b[A\n",
      "eva train::  42%|████▏     | 319/762 [13:17<14:56,  2.02s/it]\u001b[A\n",
      "eva train::  42%|████▏     | 321/762 [13:26<19:58,  2.72s/it]\u001b[A\n",
      "eva train::  42%|████▏     | 323/762 [13:34<22:29,  3.07s/it]\u001b[A\n",
      "eva train::  43%|████▎     | 325/762 [13:38<20:16,  2.78s/it]\u001b[A\n",
      "eva train::  43%|████▎     | 327/762 [13:43<19:25,  2.68s/it]\u001b[A\n",
      "eva train::  43%|████▎     | 329/762 [13:48<18:18,  2.54s/it]\u001b[A\n",
      "eva train::  43%|████▎     | 331/762 [13:55<20:56,  2.92s/it]\u001b[A\n",
      "eva train::  44%|████▎     | 333/762 [14:03<22:27,  3.14s/it]\u001b[A\n",
      "eva train::  44%|████▍     | 335/762 [14:07<20:53,  2.94s/it]\u001b[A\n",
      "eva train::  44%|████▍     | 337/762 [14:16<23:05,  3.26s/it]\u001b[A\n",
      "eva train::  44%|████▍     | 338/762 [14:20<24:16,  3.44s/it]\u001b[A\n",
      "eva train::  44%|████▍     | 339/762 [14:23<23:38,  3.35s/it]\u001b[A\n",
      "eva train::  45%|████▍     | 340/762 [14:27<24:28,  3.48s/it]\u001b[A\n",
      "eva train::  45%|████▍     | 342/762 [14:32<21:31,  3.08s/it]\u001b[A\n",
      "eva train::  45%|████▌     | 343/762 [14:35<22:06,  3.17s/it]\u001b[A\n",
      "eva train::  45%|████▌     | 345/762 [14:41<21:34,  3.10s/it]\u001b[A\n",
      "eva train::  46%|████▌     | 347/762 [14:45<19:13,  2.78s/it]\u001b[A\n",
      "eva train::  46%|████▌     | 349/762 [14:49<16:25,  2.39s/it]\u001b[A\n",
      "eva train::  46%|████▌     | 351/762 [14:57<19:52,  2.90s/it]\u001b[A\n",
      "eva train::  46%|████▋     | 353/762 [15:05<22:18,  3.27s/it]\u001b[A\n",
      "eva train::  47%|████▋     | 355/762 [15:12<22:40,  3.34s/it]\u001b[A\n",
      "eva train::  47%|████▋     | 357/762 [15:15<19:25,  2.88s/it]\u001b[A\n",
      "eva train::  47%|████▋     | 359/762 [15:20<17:48,  2.65s/it]\u001b[A\n",
      "eva train::  47%|████▋     | 361/762 [15:26<18:33,  2.78s/it]\u001b[A\n",
      "eva train::  48%|████▊     | 363/762 [15:29<16:31,  2.49s/it]\u001b[A\n",
      "eva train::  48%|████▊     | 365/762 [15:33<15:26,  2.33s/it]\u001b[A\n",
      "eva train::  48%|████▊     | 367/762 [15:37<14:11,  2.16s/it]\u001b[A\n",
      "eva train::  49%|████▊     | 370/762 [15:43<14:06,  2.16s/it]\u001b[A\n",
      "eva train::  49%|████▉     | 372/762 [15:48<14:09,  2.18s/it]\u001b[A\n",
      "eva train::  49%|████▉     | 374/762 [15:56<17:22,  2.69s/it]\u001b[A\n",
      "eva train::  49%|████▉     | 376/762 [15:59<15:29,  2.41s/it]\u001b[A\n",
      "eva train::  50%|████▉     | 378/762 [16:07<18:12,  2.84s/it]\u001b[A\n",
      "eva train::  50%|████▉     | 380/762 [16:12<17:01,  2.68s/it]\u001b[A\n",
      "eva train::  50%|█████     | 382/762 [16:17<17:24,  2.75s/it]\u001b[A\n",
      "eva train::  50%|█████     | 384/762 [16:25<18:54,  3.00s/it]\u001b[A\n",
      "eva train::  51%|█████     | 386/762 [16:32<19:43,  3.15s/it]\u001b[A\n",
      "eva train::  51%|█████     | 388/762 [16:40<21:03,  3.38s/it]\u001b[A\n",
      "eva train::  51%|█████     | 390/762 [16:45<20:11,  3.26s/it]\u001b[A\n",
      "eva train::  51%|█████▏    | 391/762 [16:49<19:59,  3.23s/it]\u001b[A\n",
      "eva train::  52%|█████▏    | 394/762 [16:53<15:03,  2.46s/it]\u001b[A\n",
      "eva train::  52%|█████▏    | 396/762 [16:56<13:34,  2.23s/it]\u001b[A\n",
      "eva train::  52%|█████▏    | 398/762 [17:02<14:40,  2.42s/it]\u001b[A\n",
      "eva train::  52%|█████▏    | 400/762 [17:06<14:03,  2.33s/it]\u001b[A\n",
      "eva train::  53%|█████▎    | 402/762 [17:13<15:47,  2.63s/it]\u001b[A\n",
      "eva train::  53%|█████▎    | 404/762 [17:19<16:10,  2.71s/it]\u001b[A\n",
      "eva train::  53%|█████▎    | 406/762 [17:25<16:27,  2.77s/it]\u001b[A\n",
      "eva train::  54%|█████▎    | 408/762 [17:31<17:22,  2.95s/it]\u001b[A\n",
      "eva train::  54%|█████▍    | 411/762 [17:36<14:19,  2.45s/it]\u001b[A\n",
      "eva train::  54%|█████▍    | 413/762 [17:42<15:17,  2.63s/it]\u001b[A\n",
      "eva train::  54%|█████▍    | 415/762 [17:49<16:00,  2.77s/it]\u001b[A\n",
      "eva train::  55%|█████▍    | 417/762 [17:54<16:05,  2.80s/it]\u001b[A\n",
      "eva train::  55%|█████▍    | 419/762 [18:00<15:44,  2.75s/it]\u001b[A\n",
      "eva train::  55%|█████▌    | 421/762 [18:04<14:46,  2.60s/it]\u001b[A\n",
      "eva train::  56%|█████▌    | 423/762 [18:11<15:49,  2.80s/it]\u001b[A\n",
      "eva train::  56%|█████▌    | 425/762 [18:17<16:14,  2.89s/it]\u001b[A\n",
      "eva train::  56%|█████▌    | 427/762 [18:22<15:43,  2.82s/it]\u001b[A\n",
      "eva train::  56%|█████▋    | 429/762 [18:26<14:00,  2.52s/it]\u001b[A\n",
      "eva train::  57%|█████▋    | 431/762 [18:33<15:51,  2.87s/it]\u001b[A\n",
      "eva train::  57%|█████▋    | 433/762 [18:41<17:15,  3.15s/it]\u001b[A\n",
      "eva train::  57%|█████▋    | 435/762 [18:46<16:32,  3.04s/it]\u001b[A\n",
      "eva train::  57%|█████▋    | 437/762 [18:54<17:32,  3.24s/it]\u001b[A\n",
      "eva train::  57%|█████▋    | 438/762 [18:58<18:27,  3.42s/it]\u001b[A\n",
      "eva train::  58%|█████▊    | 439/762 [19:02<19:13,  3.57s/it]\u001b[A\n",
      "eva train::  58%|█████▊    | 441/762 [19:06<16:06,  3.01s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "test_episodes_list, train_episodes_list = rl_model.train(3000,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7cefb97a-444f-4f01-9a81-c080df30e4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.022, 'sing')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.agent.option_words.smallest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da7bf9d9-f6be-4f4d-80af-6303c002e52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Meridian National Corp. said it sold 750,000 shares of its common stock to the McAlpine family interests, for $1 million, or $1.35 a share. The sale represents 10.2% of Meridian's shares outstanding.  \\n\\nThe McAlpine family, which operates a number of multinational companies, including a London-based engineering and construction company, also lent to Meridian National $500,000.\",\n",
       "  'target': 'outstanding',\n",
       "  'lemma_target': 'outstanding',\n",
       "  'substitutes': [('remaining', 0.6),\n",
       "   ('unclaimed', 0.4),\n",
       "   ('payable', 0.4),\n",
       "   ('uncollected', 0.4),\n",
       "   ('owing', 0.4)],\n",
       "  'lemma_subs': [('remaining', 0.6),\n",
       "   ('unclaimed', 0.4),\n",
       "   ('payable', 0.4),\n",
       "   ('uncollected', 0.4),\n",
       "   ('owing', 0.4)],\n",
       "  'offset': 187,\n",
       "  'role': 'user',\n",
       "  'option_words': [('to', 0.113),\n",
       "   ('and', 0.052),\n",
       "   ('interest', 0.033),\n",
       "   ('or', 0.025),\n",
       "   ('of', 0.025),\n",
       "   ('for', 0.022),\n",
       "   ('debt', 0.016),\n",
       "   ('on', 0.013),\n",
       "   ('asset', 0.011),\n",
       "   ('tax', 0.01)],\n",
       "  'mask_text': 'Meridian National Corp. said it sold 750,000 shares of its common stock to the McAlpine family interests, for $1 million, or $1.35 a share.outstanding.  \\n\\n remaining.  \\n\\n unclaimed.  \\n\\n payable.  \\n\\n uncollected.  \\n\\n owing.  \\n\\n <mask>.  \\n\\nThe McAlpine family, which operates a number of multinational companies, including a London-based engineering and construction company, also lent to Meridian National $500,000.'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,info = train_env.reset()\n",
    "train_env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fc0c53d-40e2-4ada-b27d-696f02058383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'At Christie\\'s, a folio of 21 prints from Alfred Stieglitz\\'s \"Equivalents\" series sold for $396,000, a single-lot record. Other works also have been exceeding price estimates. In part, prices reflect development of a market structure based on such variables as the number of prints.',\n",
       "  'target': 'works',\n",
       "  'lemma_target': 'work',\n",
       "  'substitutes': [('item', 0.6),\n",
       "   ('print', 0.6),\n",
       "   ('creation', 0.4),\n",
       "   ('product', 0.4),\n",
       "   ('object', 0.4)],\n",
       "  'lemma_subs': [('item', 0.6),\n",
       "   ('print', 0.6),\n",
       "   ('creation', 0.4),\n",
       "   ('product', 0.4),\n",
       "   ('object', 0.4)],\n",
       "  'offset': 127,\n",
       "  'role': 'user',\n",
       "  'option_words': [('object', 0.29),\n",
       "   ('item', 0.182),\n",
       "   ('product', 0.108),\n",
       "   ('item', 0.04),\n",
       "   ('product', 0.023),\n",
       "   ('creation', 0.018),\n",
       "   ('creator', 0.013),\n",
       "   ('collection', 0.008),\n",
       "   ('project', 0.008),\n",
       "   ('it', 0.008)],\n",
       "  'mask_text': 'At Christie\\'s, a folio of 21 prints from Alfred Stieglitz\\'s \"Equivalents\" series sold for $396,000, a single-lot record.works also have been exceeding pric item also have been exceeding pric print also have been exceeding pric creation also have been exceeding pric product also have been exceeding pric object also have been exceeding pric <mask> also have been exceeding pricIn part, prices reflect development of a market structure based on such variables as the number of prints.'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,info = train_env.reset()\n",
    "train_env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d86b026-3a4d-4125-9453-2023613a99bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 370/370 [01:39<00:00,  3.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-149.99999999999855, 0.2938775510204082, 0.3489795918367347)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_list, Rewards, accurate_match_rate, loose_match_rate = rl_model.evaluate(env)\n",
    "Rewards, accurate_match_rate, loose_match_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af5830fe-bc38-4a77-abf2-ac896924d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c19cee1-e050-4d62-a044-81f24589ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    for i in tqdm.tqdm(range(100),desc='get nothing',mininterval=3):\n",
    "        i +1\n",
    "        time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7b8098db-03cc-474a-a213-41a707987a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>', '.', '..', '?', 's', \"''\", '!”', '.”', '”', 'nos', 'mr', 've']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_words = '''</s>\n",
    ".\n",
    "..\n",
    "?\n",
    "s\n",
    "''\n",
    "!”\n",
    ".”\n",
    "”\n",
    "nos\n",
    "mr\n",
    "ve\n",
    "'''.split()\n",
    "filter_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8acae861-99fb-4476-bfb8-db9edc2ff361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['said', 'explained', 'reveal', 'announced', 'say']        ['state', 'report', 'declare', 'reveal', 'announce', 'disclose', 'claim', 'note']\n",
      "['crawl', 'slide', 'move', 'climb', 'jump']        ['wriggle', 'slide', 'crawl', 'scoot', 'move', 'glide', 'slip', 'coast']\n",
      "['reasonable', 'sensible', 'rational', 'clear', 'coherent']        ['rational', 'justifiable', 'sensible', 'reasonable', 'clear', 'relevant', 'plausible', 'legit']\n",
      "['producer', 'director', 'manager', 'critic', 'actor']        ['maker', 'producer', 'supervisor', 'controller', 'exec', 'executive', 'key player', 'overseer']\n",
      "['buy', 'get', 'pay', 'find', 'give']        ['secure', 'attain', 'gain', 'procure', 'obtain', 'acquire', 'get hands on', 'be given']\n",
      "['strong', 'powerful', 'big', 'huge', 'certain']        ['big', 'sturdy', 'certain', 'well-established', 'powerful', 'secure', 'firm', 'substantial']\n",
      "['happened', 'happen', 'occur', 'come', 'happens']        ['happen', 'occur', 'come about', 'transpire', 'materialize', 'occure', 'come to pass', 'become of']\n",
      "['society', 'country', 'culture', 'community', 'world']        ['social order', 'culture', 'nation', 'community', 'general public', 'population', 'civilization', 'world']\n",
      "['said', 'declare', 'explained', 'says', 'say']        ['assert', 'remark', 'declare', 'tell', 'mention', 'claim', 'reveal', 'comment']\n",
      "['propose', 'suggest', 'recommend', 'present', 'recommended']        ['suggest', 'advocate', 'present', 'make a proposal', 'recommend', 'proposition', 'put forward', 'make a pitch']\n",
      "['complaint', 'charge', 'investigation', 'charges', 'report']        ['objection', 'allegation', 'charge', 'grievance', 'criticism', 'statement of disagreement', 'protest', 'accusation']\n",
      "['look', 'looked', 'stare', 'gaze', 'smile']        ['gaze', 'glance', 'peer', 'stare', 'eye', 'watch', 'glare', 'gawk']\n",
      "['here', 'this', 'there', 'to', 'in']        ['in this place', 'to this place', 'on this spot', 'hereabouts', 'at this place', 'in this spot', 'around', 'in this direction']\n",
      "['allowed', 'allow', 'permit', 'admit', 'accept']        ['allow', 'authorize', 'give access', 'admit', 'accept', 'let', 'grant', 'let pass']\n",
      "['method', 'way', 'means', 'mode', 'manner']        ['means', 'mode', 'process', 'manner', 'course', 'method', 'form', 'path']\n",
      "['gem', 'rock', 'earth', 'gold', 'seal']        ['pebble', 'rock', 'gem', 'ore', 'hard piece of earths surface', 'mineral', 'gravel', 'stonework']\n",
      "['pub', 'restaurant', 'bar', 'cafe', 'pool']        ['drinking area', 'bartender station', 'pub', 'cocktail lounge', 'barroom', 'beer garden', 'lounge', 'obstacle']\n",
      "['shake', 'move', 'lift', 'roll', 'stroke']        ['jerk', 'flap', 'flitter', 'wave', 'move', 'make waves', 'flutter', 'jolt']\n",
      "['extremely', 'truly', 'incredibly', 'very', 'really']        ['incredibly', 'really', 'extremely', 'highly', 'truly', 'extraordinarily', 'greatly', 'exceedingly']\n",
      "['finish', 'conclude', 'start', 'continue', 'begin']        ['begin', 'initiate', 'go ahead', 'get under way', 'commence', 'set out', 'get going', 'take first step']\n",
      "['food', 'fat', 'fish', 'gluten', 'chicken']        ['red meat', 'flesh of animal consumed as food', 'flesh', 'grub', 'chow', 'subsistence', 'brawn', 'ration']\n",
      "['cook', 'chef', 'cooking', 'producer', 'Chef']        ['gourmet chef', 'culinary artist', 'cook', 'sous chef', 'cuisinier', 'hash slinger', 'cook chief cook and bottle', 'washer']\n",
      "['knows', 'know', 'can', 'say', 'see']        ['can tell', 'can say', 'be sure', 'identify', 'can perceive', 'fathom', 'comprehend', 'be learned']\n",
      "['all', 'al', 'just', 'not', 'good']        ['ok', 'fine', 'alright', 'all right', 'good', 'adequate', 'tolerable', 'satisfactory']\n",
      "['range', 'area', 'size', 'distance', 'scale']        ['proportions', 'area', 'range', 'scope', 'expanse', 'extent', 'magnitude', 'dimensions']\n",
      "['vegetables', 'dressing', 'soup', 'rice', 'chicken']        ['tossed salad', 'dish of vegetables', 'greens', 'mixed greens', 'toss salad', 'mix', 'fruit salad', 'medley']\n",
      "['properly', 'fully', 'effectively', 'clearly', 'seriously']        ['sufficiently', 'satisfactorily', 'thoroughly', 'appropriately', 'properly', 'acceptably', 'completely', 'suitably']\n",
      "['said', 'declare', 'explained', 'says', 'say']        ['assert', 'remark', 'declare', 'tell', 'mention', 'claim', 'reveal', 'comment']\n",
      "['sometimes', 'odd', 'often', 'regular', 'unusual']        ['sometimes', 'infrequent', 'unfrequent', 'sporadic', 'off and on', 'rare', 'intermittent', 'uncommon']\n",
      "['buy', 'get', 'pay', 'find', 'give']        ['secure', 'attain', 'gain', 'procure', 'obtain', 'acquire', 'get hands on', 'be given']\n",
      "['know', 'learn', 'understand', 'comprehend', 'hear']        ['have knowledge of', 'hear', 'learn', 'understand', 'comprehend', 'get the idea', 'be learned', 'be cognizant']\n",
      "['hair', 'head', 'face', 'skull', 'skin']        ['scalp', 'skull', 'hair', 'dome', 'noggin', 'cranium', 'top story', 'forefront']\n",
      "['dead', 'flat', 'empty', 'death', 'cold']        ['dead', 'deathly', 'listless', 'empty', 'flat', 'dull', 'cold', 'spiritless']\n",
      "['idiot', 'stupid', 'racist', 'mean', 'fool']        ['imbecile', 'moron', 'nincompoop', 'simpleton', 'numskull', 'fool', 'blockhead', 'twit']\n",
      "['lecture', 'taught', 'teach', 'teaching', 'learned']        ['instruct', 'lecture on', 'lecture', 'instruct in', 'be a professor of', 'teach', 'tutor', 'give instruction']\n",
      "['said', 'stop', 'call', 'say', 'all']        ['exclaim', 'yell', 'holler', 'scream', 'call out', 'bellow', 'cry out loudly', 'call']\n",
      "['record', 'monitor', 'keep', 'kept', 'check']        ['track', 'under surveillance', 'check', 'observe', 'keep track of', 'record', 'listen to', 'supervise']\n",
      "['turn', 'move', 'turned', 'lean', 'walk']        ['rotate', 'swivel', 'move', 'spin', 'pivot', 'veer', 'swerve', 'shift']\n",
      "['area', 'region', 'section', 'sector', 'district']        ['sector', 'district', 'area', 'region', 'section', 'range', 'strip', 'ground']\n",
      "['few', 'couple', 'some', 'several', 'par']        ['matter of', 'couple', 'not many', 'some', 'scarcely any', 'not too many', 'little', 'hardly any']\n",
      "['dark', 'black', 'white', 'light', 'brown']        ['pitchblack', 'shady', 'gloomy', 'shadowy', 'lightless', 'darkened', 'blackish', 'black']\n"
     ]
    }
   ],
   "source": [
    "for context_id in test_env.OA.context_ids[:50]:\n",
    "    context_id = random.choice(test_env.OA.context_ids)\n",
    "    option_words,prompt_sentence = test_env.get_option_words_by_llm(context_id=context_id,use_cache=True)\n",
    "    state,info = test_env.reset(context_id)\n",
    "    subs = test_env.history[0]['substitutes']\n",
    "    words = [s for s,score in option_words]\n",
    "    if not set(words) & set(filter_words):\n",
    "        print(words,'      ',[s for s,score in subs[:8]])\n",
    "# print('--------------------------------------------------------------------------')\n",
    "# print(subs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cfb825-7394-43fe-a4ea-1ca59ead436c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ac566c99-38e7-4db0-bb81-0e7d05fa3655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/xu_zhang01/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "809809bf-9b4c-4e45-9153-686f57353dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat were chasing mouse\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sentence = \"The cats were chasing mice\"\n",
    "words = sentence.split()\n",
    "\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "lemmatized_sentence = \" \".join(lemmatized_words)\n",
    "\n",
    "print(lemmatized_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63323b-ba5b-4686-8082-61045ef2107b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c0c638d1-8fcd-4d34-b45f-e7c2aaafaec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "# import these modules\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
    "\n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e4fae8d4-aeef-45aa-a853-9f77f16703db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/xu_zhang01/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0b00047d-30b6-4a2f-912c-e94eb8381a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pull', 0.4),\n",
       " ('bring', 0.4),\n",
       " ('have', 0.3),\n",
       " ('secure', 0.3),\n",
       " ('draw', 0.3),\n",
       " ('capture', 0.3),\n",
       " ('hustle', 0.3),\n",
       " ('acquire', 0.3),\n",
       " ('win', 0.3),\n",
       " ('defeat', 0.3)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,info = test_env.reset(context_id)\n",
    "test_env.history[0]['substitutes'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05420967-0b10-4c39-846b-a63a97918798",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_action    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a64e3e75-f23f-4d8d-b399-0a5873bdc892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 580 0.3017241379310345\n"
     ]
    }
   ],
   "source": [
    "right_action_match = []\n",
    "for eps in eval_episode_list:\n",
    "    for i,utter in enumerate(eps):\n",
    "        if 'right_action' in utter:\n",
    "            right_action_match.append(utter['right_action'][0] == eps[i-1]['action'])\n",
    "cnt_right = np.array(right_action_match).sum()\n",
    "len_right = len(right_action_match)\n",
    "print(cnt_right,len_right,cnt_right/len_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3dac1bf4-af82-4c27-a1ed-d0f48df4558a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_episode_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_episode_list\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_episode_list' is not defined"
     ]
    }
   ],
   "source": [
    "eval_episode_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c3aa5-6657-4612-96c9-0c9a8c0e01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_action_matcht3_episodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a7b9f-d734-4bcf-a8e5-9ad2741b53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[eval_episode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0799c04b-0383-40f1-8911-dde225b30668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "53c5bb96-3ffd-425a-9510-c9799ae6bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9177eecc-a409-4435-994c-739dd6f00c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role            : user\n",
      "text            : “I …I noticed him from across the room when I was looking around for Rachel. He was standing right in front of some blue lights, so I couldn’t see him very well, but I noticed the way that the light set off his pale skin. It almost looked like the light bent around him without actually touching him directly.\n",
      "target          : very\n",
      "option_words    : [('very', 0.275), ('really', 0.258), ('quite', 0.196), ('particularly', 0.135), ('extremely', 0.047), ('rather', 0.023), ('incredibly', 0.007), ('fairly', 0.007), ('especially', 0.006), ('truly', 0.004)]\n",
      "---------------------------------------------------\n",
      "                               role : bot\n",
      "                               text : The word very is not clear to me. Do you mean something like very,really,quite,particularly,extremely,rather,incredibly,fairly,especially,truly ?\n",
      "                       option_words : [('very', 0.275), ('really', 0.258), ('quite', 0.196), ('particularly', 0.135), ('extremely', 0.047), ('rather', 0.023), ('incredibly', 0.007), ('fairly', 0.007), ('especially', 0.006), ('truly', 0.004)]\n",
      "                             action : 2\n",
      "---------------------------------------------------\n",
      "role            : user\n",
      "text            : none of these\n",
      "reward          : -1\n",
      "is_right_action : False\n",
      "loose_right_actions : [0 2]\n",
      "---------------------------------------------------\n",
      "                               role : bot\n",
      "                               text : \n",
      "                       option_words : [('very', 0.275), ('really', 0.258), ('quite', 0.196), ('particularly', 0.135), ('extremely', 0.047), ('rather', 0.023), ('incredibly', 0.007), ('fairly', 0.007), ('especially', 0.006), ('truly', 0.004)]\n",
      "                             action : 0\n",
      "---------------------------------------------------\n",
      "role            : user\n",
      "text            : \n",
      "reward          : 2\n",
      "is_right_action : True\n",
      "loose_right_actions : [0 2]\n",
      "---------------------------------------------------\n",
      "total reward:   1\n"
     ]
    }
   ],
   "source": [
    "keys = ['role','text','target','option_words','reward','is_right_action','action']\n",
    "t3_episodes_list = [epi for epi in test_episodes_list if len(epi)>3]\n",
    "\n",
    "episode = random.choice(t3_episodes_list)\n",
    "reward_all = 0\n",
    "for utter in episode:\n",
    "    role = utter['role']\n",
    "    for k in keys:\n",
    "        if k in utter:\n",
    "            if k=='reward':\n",
    "                reward_all += utter[k]\n",
    "            if role=='user':\n",
    "                print(k.ljust(15,' '),':',utter[k])\n",
    "            else:\n",
    "                print(k.rjust(35,' '),':',utter[k])\n",
    "    print(\"---------------------------------------------------\")\n",
    "print(\"total reward:  \", reward_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "45d52fd7-b087-4d31-afa9-0d118d425c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t3_episodes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "c4a3325f-6438-4e87-99ba-f22ff22bb5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"FAMILY PETS are improving recovery rates of patients at Columbia Hospital, Milwaukee. Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more receptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\nTIRED OF TRIMMING?\",\n",
       "  'target': 'receptive',\n",
       "  'substitutes': [('acceptant', 0.7),\n",
       "   ('welcoming', 0.7),\n",
       "   ('approachable', 0.6),\n",
       "   ('acceptive', 0.5),\n",
       "   ('open', 0.5),\n",
       "   ('responsive', 0.4),\n",
       "   ('open to suggestions', 0.3),\n",
       "   ('favorable', 0.3),\n",
       "   ('open-minded', 0.3),\n",
       "   ('open to new ideas', 0.3),\n",
       "   ('persuadable', 0.2),\n",
       "   ('suggestible', 0.2),\n",
       "   ('hospitable', 0.2),\n",
       "   ('influenceable', 0.1),\n",
       "   ('accessible', 0.1),\n",
       "   ('friendly', 0.1),\n",
       "   ('amenable', 0.1),\n",
       "   ('ready', 0.1),\n",
       "   ('quick on the uptake', 0.0),\n",
       "   ('sympathetic', 0.0),\n",
       "   ('sensitive', 0.0),\n",
       "   ('bright', 0.0),\n",
       "   ('perceptive', 0.0),\n",
       "   ('susceptible', 0.0),\n",
       "   ('swayable', 0.0),\n",
       "   ('pushover', 0.0),\n",
       "   ('well-disposed', 0.0),\n",
       "   ('alert', 0.0),\n",
       "   ('observant', 0.0),\n",
       "   ('interested', 0.0),\n",
       "   ('recipient', 0.0)],\n",
       "  'offset': 206,\n",
       "  'role': 'user',\n",
       "  'option_words': [('open', 0.991),\n",
       "   ('willing', 0.002),\n",
       "   ('responsive', 0.001),\n",
       "   ('comfortable', 0.0),\n",
       "   ('tolerant', 0.0)],\n",
       "  'mask_text': \"FAMILY PETS are improving recovery rates of patients at Columbia Hospital, Milwaukee.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more receptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more acceptant to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more welcoming to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more approachable to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more acceptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more open to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\n.Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more <mask> to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\nTIRED OF TRIMMING?\"},\n",
       " {'text': '',\n",
       "  'option_words': [('open', 0.991),\n",
       "   ('willing', 0.002),\n",
       "   ('responsive', 0.001),\n",
       "   ('comfortable', 0.0),\n",
       "   ('tolerant', 0.0)],\n",
       "  'action': 0,\n",
       "  'role': 'bot'},\n",
       " {'text': ' you misunderstdood my words, I mean...',\n",
       "  'reward': -2,\n",
       "  'is_right_action': False,\n",
       "  'right_action': array([1, 2]),\n",
       "  'role': 'user',\n",
       "  'history_text': \"FAMILY PETS are improving recovery rates of patients at Columbia Hospital, Milwaukee. Patients who receive canine or feline visitors are found to have lower blood pressure and improved appetite and be more receptive to therapy, says Mary Ann O'Loughlin, program coordinator.  \\n\\nTIRED OF TRIMMING?</s></s> you misunderstdood my words, I mean...\"}]"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "85e65f4e-480d-4a1a-b6dc-6a8e7e72e3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'receptive'"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_env.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "31eaf8ed-5991-47cb-b70f-0118302dd594",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'episodes_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_567/4106245537.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'substitutes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'episodes_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(episodes_list[0][0]['target'])\n",
    "\n",
    "print(episodes_list[0][0]['substitutes'][:5])\n",
    "print(\"--------------------\")\n",
    "print(episodes_list[0][0]['mask_text'])\n",
    "\n",
    "print(episodes_list[0][0]['option_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "c58b5670-a4db-47ab-8063-ecd650f2618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.fill_mask.FillMaskPipeline at 0x7f067b69b760>"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.mask_model.encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "b4750d23-6a6f-472f-8953-df9959a01c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3854154944419861,\n",
       "  'token': 3714,\n",
       "  'token_str': 'know',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever know. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.15135060250759125,\n",
       "  'token': 51529,\n",
       "  'token_str': 'known',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever known. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.14298954606056213,\n",
       "  'token': 55950,\n",
       "  'token_str': 'knew',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever knew. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.025355149060487747,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever. At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.02500970847904682,\n",
       "  'token': 51592,\n",
       "  'token_str': 'seen',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration. She had the look of every leader she had ever known. She had the look of every leader she had ever be acquaint with. She had the look of every leader she had ever know. She had the look of every leader she had ever be acquainted with. She had the look of every leader she had ever have knowledge of. She had the look of every leader she had ever experience. She had the look of every leader she had ever seen. At six foot two, she stood a full head taller than even her Arrallin first officer.'}]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.mask_model('''It was not an attractive face right now; her ebony\n",
    "eyes shadowed by hours on the watch, full lips pursed with frustration. She had\n",
    "the look of every leader she had ever known. She had\n",
    "the look of every leader she had ever be acquaint with. She had\n",
    "the look of every leader she had ever know. She had \n",
    "the look of every leader she had ever be acquainted with. She had\n",
    "the look of every leader she had ever have knowledge of. She had\n",
    "the look of every leader she had ever experience. She had\n",
    "the look of every leader she had ever <mask>. At six foot two, she stood a full\n",
    "head taller than even her Arrallin first officer.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "4568a300-74e4-4cde-acea-9512ac6eeacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2613705098628998,\n",
       "  'token': 3714,\n",
       "  'token_str': 'know',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever know.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.1795056164264679,\n",
       "  'token': 51529,\n",
       "  'token_str': 'known',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever known.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.1245126873254776,\n",
       "  'token': 55950,\n",
       "  'token_str': 'knew',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever knew.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.07769811153411865,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever.At six foot two, she stood a full head taller than even her Arrallin first officer.'},\n",
       " {'score': 0.03395156189799309,\n",
       "  'token': 1902,\n",
       "  'token_str': 'had',\n",
       "  'sequence': 'It was not an attractive face right now; her ebony eyes shadowed by hours on the watch, full lips pursed with frustration.She had the look of every leader she had ever known..She had the look of every leader she had ever be acquaint with..She had the look of every leader she had ever know..She had the look of every leader she had ever be acquainted with..She had the look of every leader she had ever have knowledge of..She had the look of every leader she had ever experience..She had the look of every leader she had ever had.At six foot two, she stood a full head taller than even her Arrallin first officer.'}]"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.mask_model(episodes_list[0][0]['mask_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed81a2-a16d-454e-b25f-50c42aeb24f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\n'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eac9303b-1f4d-4631-89ef-e4514f6932d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argwhere([True,False,True,False]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0c61d6b-352a-4e76-bf74-0b1b24c0f6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.',\n",
       "  'target': 'think',\n",
       "  'substitutes': [('have in mind', 0.9),\n",
       "   ('suppose', 0.8),\n",
       "   ('presume', 0.6),\n",
       "   ('reckon', 0.6),\n",
       "   ('conclude', 0.5),\n",
       "   ('speculate', 0.5),\n",
       "   ('suspect', 0.5),\n",
       "   ('feel', 0.4),\n",
       "   ('imagine', 0.4),\n",
       "   ('suggest', 0.4),\n",
       "   ('believe', 0.4),\n",
       "   ('anticipate', 0.3),\n",
       "   ('reflect', 0.3),\n",
       "   ('surmise', 0.3),\n",
       "   ('gather', 0.3),\n",
       "   ('understand', 0.3),\n",
       "   ('foresee', 0.3),\n",
       "   ('deem', 0.3),\n",
       "   ('determine', 0.2),\n",
       "   ('expect', 0.2),\n",
       "   ('fancy', 0.2),\n",
       "   ('ponder', 0.2),\n",
       "   ('consider', 0.2),\n",
       "   ('reason', 0.2),\n",
       "   ('see', 0.2),\n",
       "   ('stop to consider', 0.2),\n",
       "   ('guess', 0.2),\n",
       "   ('intellectualize', 0.2),\n",
       "   ('envision', 0.2),\n",
       "   ('want', 0.2),\n",
       "   ('use ones head', 0.2),\n",
       "   ('estimate', 0.1),\n",
       "   ('appraise', 0.1),\n",
       "   ('sort out', 0.1),\n",
       "   ('contemplate', 0.1),\n",
       "   ('assume', 0.1),\n",
       "   ('discern', 0.1),\n",
       "   ('conceive', 0.1),\n",
       "   ('stew', 0.1),\n",
       "   ('project', 0.1),\n",
       "   ('sense', 0.1),\n",
       "   ('resolve', 0.0),\n",
       "   ('regard', 0.0),\n",
       "   ('realize', 0.0),\n",
       "   ('reminisce', 0.0),\n",
       "   ('study', 0.0),\n",
       "   ('hold', 0.0),\n",
       "   ('weigh', 0.0),\n",
       "   ('meditate', 0.0),\n",
       "   ('take', 0.0),\n",
       "   ('image', 0.0),\n",
       "   ('recall', 0.0),\n",
       "   ('visualize', 0.0),\n",
       "   ('deduce', 0.0),\n",
       "   ('comprehend', 0.0),\n",
       "   ('take under consideration', 0.0),\n",
       "   ('appreciate', 0.0),\n",
       "   ('analyze', 0.0),\n",
       "   ('muse', 0.0),\n",
       "   ('vision', 0.0),\n",
       "   ('rationalize', 0.0),\n",
       "   ('be convinced', 0.0),\n",
       "   ('judge', 0.0),\n",
       "   ('evaluate', 0.0),\n",
       "   ('plan for', 0.0),\n",
       "   ('ideate', 0.0),\n",
       "   ('examine', 0.0),\n",
       "   ('esteem', 0.0),\n",
       "   ('figure out', 0.0),\n",
       "   ('revolve', 0.0),\n",
       "   ('ruminate', 0.0),\n",
       "   ('deliberate', 0.0),\n",
       "   ('turn over', 0.0),\n",
       "   ('credit', 0.0),\n",
       "   ('envisage', 0.0),\n",
       "   ('mull over', 0.0),\n",
       "   ('brood', 0.0),\n",
       "   ('cogitate', 0.0),\n",
       "   ('infer', 0.0),\n",
       "   ('feature', 0.0),\n",
       "   ('logicalize', 0.0),\n",
       "   ('mull', 0.0),\n",
       "   ('factor', 0.0),\n",
       "   ('recollect', 0.0),\n",
       "   ('cerebrate', 0.0),\n",
       "   ('rack ones brains', 0.0),\n",
       "   ('remember call to', 0.0),\n",
       "   ('mind', 0.0)],\n",
       "  'offset': 46,\n",
       "  'role': 'user',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'mask_text': 'Nepthys turned to me.“Well, kid, what do you think?.“Well, kid, what do you have in mind?.“Well, kid, what do you suppose?.“Well, kid, what do you presume?.“Well, kid, what do you reckon?.“Well, kid, what do you conclude?.“Well, kid, what do you <mask>?Remember, this is your quest.'},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '},\n",
       " {'text': 'The word think is not clear to me. Do you mean something like think by this?',\n",
       "  'option_words': [('think', 0.169),\n",
       "   ('conclude', 0.151),\n",
       "   ('?', 0.063),\n",
       "   ('say', 0.039),\n",
       "   ('do', 0.035)],\n",
       "  'action': 1,\n",
       "  'role': 'bot'},\n",
       " {'text': 'No, it is not ',\n",
       "  'reward': -1.5,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user',\n",
       "  'history_text': 'Nepthys turned to me. “Well, kid, what do you think? Remember, this is your quest.</s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not </s>The word think is not clear to me. Do you mean something like think by this?</s>No, it is not '}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_episode_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f270f4d-aaef-492f-9996-468f8b0351c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The word payable is not clear to me. Do you mean something like due,paid,pay,payment,available ?',\n",
       " 'option_words': [('due', 0.81),\n",
       "  ('paid', 0.135),\n",
       "  ('pay', 0.009),\n",
       "  ('payment', 0.003),\n",
       "  ('available', 0.002)],\n",
       " 'action': 2,\n",
       " 'role': 'bot'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_list[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc12dec7-4de1-4de7-b238-952c54645e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# 定义一个枚举类型\n",
    "class Action(Enum):\n",
    "    NO_ACTION = 0\n",
    "    CONFIRM = 1\n",
    "    OPTION = 2\n",
    "    EXPLAIN = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4b2e781-0488-4a8b-9e97-ef0bc063d758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for action in Action:\n",
    "    print(action.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47658a3-8666-457b-bedf-e4c983ac320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "03a68d8c-4e76-4173-ba3b-536e4ded903b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 58, False: 42})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "Counter(pd.DataFrame([e[2] for e in episodes_list[-100:]])['is_right_action'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "20358fbc-4181-4462-be81-b3c3ec2046b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     hello\n"
     ]
    }
   ],
   "source": [
    "print('hello'.rjust(10, ' '))\n",
    "# 输出 '# 输出 'hello   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c6170679-2c66-4070-ac32-074f9b8590d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Months earlier, we might have sought a bed, a couch, or a\\n                    comfortable chair at this point. Instead, I asked, \"Is he handsome?\" \\n                 \"You\\'re jealous.\"',\n",
       "  'target': 'Instead',\n",
       "  'substitutes': [('alternatively', 0.6),\n",
       "   ('however', 0.6),\n",
       "   ('alternately', 0.5),\n",
       "   ('rather', 0.4),\n",
       "   ('on second thought', 0.4),\n",
       "   ('in lieu', 0.3),\n",
       "   ('as a substitute', 0.3),\n",
       "   ('alternative', 0.3),\n",
       "   ('in place of', 0.3),\n",
       "   ('on behalf of', 0.3),\n",
       "   ('rather than', 0.2),\n",
       "   ('preferably', 0.0),\n",
       "   ('in preference', 0.0),\n",
       "   ('quietly', 0.0),\n",
       "   ('actually', 0.0)],\n",
       "  'offset': 111,\n",
       "  'role': 'user'},\n",
       " {'text': 'The word Instead is not clear to me. Do you mean something like how,</s>,then,and,so ?',\n",
       "  'option_words': [('how', 0.254),\n",
       "   ('</s>', 0.131),\n",
       "   ('then', 0.025),\n",
       "   ('and', 0.022),\n",
       "   ('so', 0.021)],\n",
       "  'action': 2,\n",
       "  'role': 'bot'},\n",
       " {'text': 'none of these',\n",
       "  'reward': -1,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user'},\n",
       " {'text': 'The word Instead is not clear to me. Could you please provide me more context?',\n",
       "  'option_words': [('how', 0.254),\n",
       "   ('</s>', 0.131),\n",
       "   ('then', 0.025),\n",
       "   ('and', 0.022),\n",
       "   ('so', 0.021)],\n",
       "  'action': 3,\n",
       "  'role': 'bot'},\n",
       " {'text': 'the explain content',\n",
       "  'reward': 0.5,\n",
       "  'is_right_action': True,\n",
       "  'role': 'user'},\n",
       " {'text': '',\n",
       "  'option_words': [('how', 0.254),\n",
       "   ('</s>', 0.131),\n",
       "   ('then', 0.025),\n",
       "   ('and', 0.022),\n",
       "   ('so', 0.021)],\n",
       "  'action': 0,\n",
       "  'role': 'bot'},\n",
       " {'text': ' you misunderstdood my words, I mean...',\n",
       "  'reward': -2,\n",
       "  'is_right_action': False,\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2ccbddd4-0a93-407a-a1da-96aa8357ef63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electronic theft by foreign and industrial spies and disgruntled\n",
      "\t\t\t\temployees is costing U.S. companies billions and eroding their\n",
      "\t\t\t\tinternational competitive advantage. That was the message delivered by\n",
      "\t\t\t\tgovernment and private security experts at an all-day conference on\n",
      "\t\t\t\tcorporate electronic espionage. \"Hostile and even friendly nations\n",
      "\t\t\t\troutinely steal information from U.S. companies and share it with their\n",
      "\t\t\t\town companies,\" said Noel D. Matchett, a former staffer at the federal\n",
      "\t\t\t\tNational Security Agency and now president of Information Security Inc.,\n",
      "\t\t\t\tSilver Spring, Md.\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "authority\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "official\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "state\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "government\n",
      "----------------------------------\n",
      "                   The word government is not clear to me. Do you mean something like government,state,authority,official,authorities ?\n",
      "----------------------------------\n",
      "official\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "turn = 0\n",
    "for his in env.history:\n",
    "    space_num = 0 if turn%2==0 else (135-len(his['text']))\n",
    "    # print(turn, space_num) \n",
    "    print(' '*space_num + his['text'])\n",
    "    print('----------------------------------')\n",
    "    turn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3726263f-0d58-46ee-a78b-8e7462ab58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526630f-1db7-49f1-98f5-33da68418946",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "76cab7a6-73b5-40ac-933f-777ec167caaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {True: {'answer': '', 'reward': 2, 'terminated': True},\n",
       "  False: {'answer': ' you misunderstdood my words, I mean...',\n",
       "   'reward': -2,\n",
       "   'terminated': True}},\n",
       " 1: {True: {'answer': 'Yes, it is', 'reward': 1.5, 'terminated': True},\n",
       "  False: {'answer': 'No, it is not ', 'reward': -1.5, 'terminated': False}},\n",
       " 2: {True: {'answer': None, 'reward': 1, 'terminated': True},\n",
       "  False: {'answer': ' none of these', 'reward': -1, 'terminated': False}},\n",
       " 3: {True: {'answer': 'the explain content',\n",
       "   'reward': 0.5,\n",
       "   'terminated': False},\n",
       "  False: {'answer': 'it is obviously, but I will try explain it too',\n",
       "   'reward': -0.5,\n",
       "   'terminated': True}}}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5c9c9504-3277-47e6-8517-b061f06114e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_action(self):\n",
    "    option_words = self.get_option_words_by_llm(self.context_id)\n",
    "    should_no_action = self.should_no_action(option_words)\n",
    "    should_confirm = self.should_confirm(option_words)\n",
    "    should_opt = self.should_opt(option_words)\n",
    "    should_explain = self.should_explain(option_words)\n",
    "\n",
    "    right_action = [should_no_action, should_confirm, should_opt, should_explain]\n",
    "    return right_action.index("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "034bd783-1f67-4274-8982-fefa36a84487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_action(env).index(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8faeee0-e1b7-4faf-8295-465d7e3a9e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option = env.get_option_words_by_llm(context_id)\n",
    "env.get_best_action()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09154a4-0ca2-472d-946d-63117b2faf80",
   "metadata": {},
   "source": [
    "## Expierment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57a7402-23e5-4b51-bbe1-13f54d3816b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info =  env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c62f8eaf-ff49-42bb-a766-574cb871eb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question(text='I imagine that people do not come here for unimportant reasons.”\\n            It hissed thoughtfully. “True, true.', target='hissed', substitutes=[('seethe', 0.4), ('jeer', 0.3), ('make buzzing sound', 0.3), ('whirr', 0.3), ('whistle', 0.2), ('sputter', 0.2), ('mock', 0.2), ('shrill', 0.1), ('boo', 0.1), ('deride', 0.0), ('blow', 0.0), ('whiz', 0.0), ('rasp', 0.0), ('hoot', 0.0), ('say', 0.0), ('wheeze', 0.0), ('disapprove', 0.0), ('damn', 0.0), ('sizzle', 0.0), ('catcall', 0.0), ('buzz', 0.0), ('sibilate', 0.0), ('revile', 0.0), ('ridicule', 0.0), ('spit', 0.0), ('sigh', 0.0), ('condemn', 0.0), ('shout down', 0.0), ('whisper', 0.0), ('decry', 0.0), ('siss', 0.0)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.history[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29e54d-87cd-4092-aa66-cdfb6a04523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "71cea31d-abae-4d73-addd-94c0822dcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = self.history[0]\n",
    "\n",
    "mask_show = ''\n",
    "solo_mask = h0.text.replace(h0.target,'<mask>',1)\n",
    "mask_text = ''\n",
    "for i,(word,score) in enumerate(h0.substitutes[:5]):\n",
    "    if len(h0.text)*6<2100:\n",
    "        text = h0.text\n",
    "    else:\n",
    "        subtract_len = len(h0.text)-350\n",
    "        index = h0.text.index(h0.target)\n",
    "        if i%2==0:\n",
    "            pre_sub_index = min(0+subtract_len,index-20)\n",
    "            text = h0.text[pre_sub_index:]\n",
    "        else:\n",
    "            post_sub_index = max(len(h0.text)-subtract_len,index+20)\n",
    "            text = h0.text[:post_sub_index]\n",
    "    text.replace(h0.target,word,1)\n",
    "    if len(self.model.tokenizer(mask_text+text+solo_mask)['input_ids'])>512:\n",
    "        break\n",
    "    mask_text += text.replace(h0.target,word,1)\n",
    "    # mask_show += text.replace(h0.target,f\"\\033[31m{word}\\033[0m\",1)+'\\033[31m<\\nnewline>\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e17ea-b523-4da8-bd83-77be6850aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "945ecfc1-ab26-4d5e-abb7-06b5a1861159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('even', 0.913),\n",
       " ('and', 0.022),\n",
       " ('particularly', 0.007),\n",
       " ('especially', 0.003),\n",
       " ('although', 0.003)]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "62620618-12bc-47b7-a9c2-c39fc99f95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "5e4b8ab4-9468-4ab5-a1b7-f822d81477d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[question(text='In its center, under a spearing, white light, was a golden table draped with a blue velvet cloth, on which lay a gray, plum-sized rock.\\n            “A marvel, isn’t it?” she said.', target='marvel', substitutes=[('wonder', 0.9), ('phenomenon', 0.6), ('miracle', 0.5), ('amazement', 0.5), ('awed', 0.2), ('be amazed be', 0.1), ('genius', 0.0), ('goggle', 0.0), ('prodigy', 0.0), ('gaze', 0.0), ('feel surprise', 0.0), ('stare', 0.0), ('stand in awe', 0.0), ('be surprised', 0.0), ('sensation', 0.0), ('gape', 0.0)])]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "ecdbb1f6-5df4-4e66-906f-9b13933066cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wonder', 0.686),\n",
       " ('miracle', 0.053),\n",
       " ('magic', 0.03),\n",
       " ('strange', 0.012),\n",
       " ('wonderful', 0.01)]"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_option_words_by_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "235af17a-cfb3-41cd-a99f-0a463ff6280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e578cb-9b1e-419e-aecd-e70796c23ba9",
   "metadata": {},
   "source": [
    "##  evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "1572c057-1a94-4853-98d2-01c1939a73fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'environment' from '/mnt/d/BaiduSyncdisk/intelligent_interactive_system/Thesis/RL/environment.py'>"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "436f4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f53d4f93-e135-4517-a934-e372ef7dc4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context_id_state_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46860cba-b183-42fa-a18a-74891ec04759",
   "metadata": {},
   "source": [
    "# Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7f524ba8-ba44-4b80-b982-b96651ecf469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 762/762 [18:49<00:00,  1.48s/it]\n",
      "100%|██████████| 370/370 [09:25<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "context_id_state_mapping = {}\n",
    "context_option_mapping = {}\n",
    "for env in [train_env,test_env]:\n",
    "    for context_id in tqdm.tqdm(env.OA.context_ids):\n",
    "        # if (context_id in context_id_state_mapping) and (context_id in context_option_mapping):\n",
    "        #     continue\n",
    "        state,info = env.reset(context_id)\n",
    "        option_words = env.get_option_words_by_llm(context_id,False)\n",
    "        context_id_state_mapping[context_id] = state\n",
    "        context_option_mapping[context_id] = option_words\n",
    "    \n",
    "import pickle\n",
    "with open(\"state.pkl\",\"wb\") as f:\n",
    "    pickle.dump(context_id_state_mapping,f)\n",
    "with open(\"option.pkl\",\"wb\") as  f:\n",
    "    pickle.dump(context_option_mapping,f  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75c2b551-0653-45af-8907-58444162ef23",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have exactly one of create/read/write/append mode and at most one plus",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moption.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m    my_obj \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have exactly one of create/read/write/append mode and at most one plus"
     ]
    }
   ],
   "source": [
    " with open(\"option.pkl\",\"b\") as f:\n",
    "    my_obj = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c8a2c-0bca-4746-b3c8-c96a0b22a5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f3fb291-b69f-4654-9193-354a3c3be667",
   "metadata": {},
   "outputs": [],
   "source": [
    "del context_id_state_mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21147f5b-1cfc-4024-b4aa-c19e2068e0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.34375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(64*768*370)/(1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6799f881-61bd-4c5a-8519-1fcfe953b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_id_state_mapping['c:c28336fbaeb6942c1454706a864cdf89c4535313'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59527332-e5f1-4605-a797-714aa2282a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "265873fe-c8eb-4cd2-a5c7-b6c57a282843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_option_words_by_llm(self,context_id):\n",
    "    # state, info = test_env.reset()\n",
    "    # h0 =self.history[0]\n",
    "\n",
    "\n",
    "    def repeat_part(sent,target,substitutes,trunck=False):\n",
    "        rep_list = []\n",
    "        substitutes = [w for w,s in substitutes[:5]]\n",
    "        for sub in [target]+substitutes+['<mask>']:\n",
    "            start = offset-30 if trunck else 0\n",
    "            post_start = offset-sent.start_char+len(target)\n",
    "            post_end = post_start+30 if trunck else  100000000\n",
    "            repeat_part = f\"{sent.text[start:offset-sent.start_char]}{sub}{sent.text[post_start:post_end]}\"\n",
    "            rep_list.append(repeat_part)\n",
    "        return '.'.join(rep_list)\n",
    "\n",
    "    h0,_ = self.OA.sample(context_id)\n",
    "    # h0 = self.history[0]\n",
    "\n",
    "    offset = h0['offset']\n",
    "    mask_sentence_list = []\n",
    "    for sent in nlp(h0['text']).sents:\n",
    "        print(sent.start_char, offset ,sent.end_char)\n",
    "        if sent.start_char <= offset <sent.end_char:\n",
    "            sent_text = repeat_part(sent, h0['target'], h0['substitutes'])\n",
    "            mask_sentence_list.append(sent_text)\n",
    "        else:\n",
    "            mask_sentence_list.append(sent.text)\n",
    "\n",
    "    mask_text = ''.join(mask_sentence_list)\n",
    "    token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "\n",
    "    if token_lens>512:\n",
    "        mask_sentence_list = []\n",
    "        for sent in nlp(h0['text']).sents:\n",
    "            if sent.start_char <= offset <sent.end_char:\n",
    "                sent_text = repeat_part(sent, h0['target'], h0['substitutes'],True)\n",
    "                # print('-------------')\n",
    "                mask_sentence_list.append(sent_text)\n",
    "            else:\n",
    "                mask_sentence_list.append(sent.text)\n",
    "        mask_text = ''.join(mask_sentence_list)\n",
    "        token_lens = len(tokenizer(''.join(mask_text))['input_ids'])                \n",
    "    # words = [(token['token_str'],round(token['score'],3)) for token in self.mask_model(mask_text)]\n",
    "    return mask_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f31c0a99-ba06-4c0d-ae62-3de2c7da34d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Let’s go.”\\n            As we headed down the sidewalk, I said, “What is your name, anyway?”'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "h0['text'][h0['offset']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7fd005a-dc4a-4b37-bf68-6fd1f5605093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 128 95\n",
      "96 128 445\n",
      "446 128 499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 87, 1902, 959, 90698, 450, 87, 13648, 959, 33022, 47, 30698, 4, 1284, 47, 1992, 4745, 35978, 5, 3827, 45188, 70, 5551, 77968, 67, 28302, 23, 6, 5, 7077, 16065, 70, 5551, 77968, 67, 28302, 23, 6, 5, 107, 75161, 70, 5551, 77968, 67, 28302, 23, 6, 5, 43866, 107, 70, 5551, 77968, 67, 28302, 23, 6, 5, 3827, 38931, 70, 5551, 77968, 67, 28302, 23, 6, 5, 987, 19, 16065, 70, 5551, 77968, 67, 28302, 23, 6, 5, 250001, 70, 5551, 77968, 67, 28302, 23, 47009, 642, 23409, 1810, 100, 10, 72399, 186857, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(get_option_words_by_llm(test_env,context_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e64e23-e3a6-4a80-8eef-e7a151ce8df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4848b7ff-b2ab-4a7a-b558-6644c88b0cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': 'It was last February, after the winter break, that we moved in together. Now spring was back, under the concrete, and I could smell it even here.\\n            “Isn’t it an amazing night, Rache?',\n",
       "  'target': 'even',\n",
       "  'substitutes': [('still', 0.4),\n",
       "   ('as well as', 0.2),\n",
       "   ('so much as', 0.1),\n",
       "   ('much', 0.1),\n",
       "   ('in spite of', 0.0),\n",
       "   ('yet', 0.0),\n",
       "   ('despite', 0.0),\n",
       "   ('notwithstanding', 0.0),\n",
       "   ('indeed', 0.0),\n",
       "   ('actually', 0.0),\n",
       "   ('disregarding', 0.0),\n",
       "   ('more', 0.0),\n",
       "   ('yet all the', 0.0)],\n",
       "  'offset': 135},\n",
       " 'c:8449d1484b624c8db76ae3d9c60a000f677a244d')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.OA.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "0ec6bbc4-2192-449b-963a-dfde0704267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                   | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_142/1917932590.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 200/200 [18:37<00:00,  5.59s/it]\n"
     ]
    }
   ],
   "source": [
    "returns = 0\n",
    "action_list = []\n",
    "turns_list = []\n",
    "reward_list = []\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    context_id = test_env.OA.context_ids[i]\n",
    "    state, info = test_env.reset(context_id)\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    episode_returns = 0\n",
    "    for t in count():\n",
    "        action = select_action(state,eps_threshold=None)\n",
    "        action_list.append(action.item())\n",
    "        observation, reward, terminated, truncated, _ = test_env.step(action.item())\n",
    "        state = observation.reshape((1,-1))\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        episode_returns += reward\n",
    "        # returns += reward\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        if done:\n",
    "            turns_list.append(t)\n",
    "            reward_list.append(episode_returns)\n",
    "            # plot_durations()\n",
    "\n",
    "\n",
    "            turn = 0\n",
    "            for his in env.history:\n",
    "                space_num = 0 if turn%2==0 else (135-len(his.text))\n",
    "                role = \"User:\" if  turn%2==0 else  \"Bot:\"\n",
    "                # print(role)\n",
    "                # print(his.text)\n",
    "                # print('----------------------------------')\n",
    "                turn += 1\n",
    "            break\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "9a206ff2-7e06-4536-8f45-eae09192638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "695f4f0e-ac66-48fd-a6b0-7ce31c1db5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 919, 1: 16, 3: 21, 0: 13})"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "13494357-7186-4ac7-a1f5-3dd0510dcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "6ef6b0b9-7a14-4843-9833-b3fb9fc6a6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of occurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>options</th>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confirm</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more info</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no action</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           number of occurance\n",
       "options                    919\n",
       "confirm                     16\n",
       "more info                   21\n",
       "no action                   13"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_act = Counter(action_list) # = \n",
    "name_map = {0:'no action',1:'confirm',2:'options',3:'more info'}\n",
    "pd.DataFrame([data_act],index=['number of occurance']).rename(name_map,axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "f70f76bb-0e1e-4fc6-a7dd-971d87fcb058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turns</th>\n",
       "      <th>Number of Occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   turns  Number of Occurrence\n",
       "0      5                   188\n",
       "1      2                     4\n",
       "2      3                     2\n",
       "3      1                     3\n",
       "4      4                     3"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame([Counter(turns_list)]).T.reset_index()\n",
    "df2.columns = ['turns','Number of Occurrence']\n",
    "df2['turns'] += 1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735458b7-9d8d-413e-a047-2e275cb36a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "16039882-513f-4eb2-9f22-b1c3c3f7a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0423d0f7-19db-48d2-95c4-a980273ce4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4036247594865046"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c83fc-a12d-47dd-a435-fb18daf8c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = origin_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afc7f6e2-6abf-40c1-88ad-588efc7773b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_id = random.choice(self.context_ids)\n",
    "context = self.contexts[context_id]['context']\n",
    "target = self.contexts[context_id]['targets'][0]\n",
    "target_text = target['target']\n",
    "substitutes = [(sub['substitute'],sub['label_score']) for sub in target['substitutes']]\n",
    "sorted_subs = sorted(substitutes,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55ffad1c-2582-46b8-94e3-1c1483af2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d38a4cd-c0bc-40f3-9a26-d657504ccfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.1000])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a617918-e081-4a3c-8b58-7ccea316b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_return = []\n",
    "len_avg = 10\n",
    "for i in range(len(return_list)-len_avg):\n",
    "    average_return.append(np.mean([s.item() for s in return_list[i:i + len_avg]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd4b046c-0d80-4bf4-be7a-472eb7053d24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_268/136110296.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturn_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.mean([s.item() for s in return_list[i:i+10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5101dc4a-8af9-4411-a084-fc42f316549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc207554-12b6-4aea-8d22-e32efc26c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d78b0368-9ada-42ee-9e74-3b11feb8201a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "00cabcfd-0895-4f2b-ae98-9c955fe3142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_part(sent,target,substitutes,trunck=False):\n",
    "    rep_list = []\n",
    "    substitutes = [w for w,s in substitutes[:5]]\n",
    "    for sub in [target]+substitutes+['<mask>']:\n",
    "        start = offset-30 if trunck else 0\n",
    "        repeat_part = f\"{sent.text[start:offset-sent.start_char]}{sub}{sent.text[offset-sent.start_char+len(target):]}\"\n",
    "        rep_list.append(repeat_part)\n",
    "    return '.'.join(rep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f0eeffd-4530-4993-97f0-c99033882847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f28f0698-a870-44de-9c8c-931402e76afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_origin_agent = OriginAgent(file_path='../data/swords/swords-v1.1_test.json.gz')\n",
    "test_env = environment.DialougeEnv(test_origin_agent,embedding_model,unmasker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8651b23c-b870-45ff-86b7-2ac8478b0e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 370/370 [00:34<00:00, 10.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for con in tqdm.tqdm(env.OA.context_ids):\n",
    "    state,info = env.reset(con)\n",
    "    h0 = env.history[0]\n",
    "    offset = h0['offset']\n",
    "    mask_sentence_list = []\n",
    "    for sent in nlp(h0['text']).sents:\n",
    "        if sent.start_char < offset <sent.end_char:\n",
    "            sent_text = repeat_part(sent, h0['target'], h0['substitutes'])\n",
    "            # print('-------------')\n",
    "            mask_sentence_list.append(sent_text)\n",
    "        else:\n",
    "            mask_sentence_list.append(sent.text)\n",
    "\n",
    "    mask_text = ''.join(mask_sentence_list)\n",
    "    token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "    token_lens, mask_text\n",
    "    \n",
    "    if token_lens>512:\n",
    "        mask_sentence_list = []\n",
    "        for sent in nlp(h0['text']).sents:\n",
    "            if sent.start_char < offset <sent.end_char:\n",
    "                sent_text = repeat_part(sent, h0['target'], h0['substitutes'],True)\n",
    "                # print('-------------')\n",
    "                mask_sentence_list.append(sent_text)\n",
    "            else:\n",
    "                mask_sentence_list.append(sent.text)\n",
    "        mask_text = ''.join(mask_sentence_list)\n",
    "        token_lens = len(tokenizer(''.join(mask_text))['input_ids'])\n",
    "        if token_lens>512:\n",
    "            print(token_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "681914b8-a4d2-4d2f-94df-a4ccfe7e11d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "The FBI cited a vivid conversation with Anissina's mother in\n",
      "which Tokhtakhounov assured her that even if her daughter \"falls,\n",
      "we will make sure she is No. 1.\"\n",
      "\n",
      "\n",
      "   After the Winter Olympics, a French judge, Marie-Reine Le\n",
      "Gougne, was suspended by the International Skating Union for not\n",
      "reporting pressure she said was put on her by Didier Gailhaguet,\n",
      "president of the French Skating Federation, to vote for the Russian\n",
      "pairs team.\n",
      "\n",
      "\n",
      "   \n",
      "-----------\n",
      "She later recanted and said that Canadian officials had\n",
      "pressured her.\n"
     ]
    }
   ],
   "source": [
    "for sent in nlp(h0['text']).sents:\n",
    "    print(\"-----------\")\n",
    "    print(sent)\n",
    "    print(sent)\n",
    "# print(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bee743a-345f-4b7f-bfd3-03744fb63efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.text[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2d9e29a-186d-4e98-b3e4-b48b3eb043cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \";1 W;2 e;3  ;4 w;5 e;6 r;7 e;8  ;9 a;10 l;11 l;12  ;13 a;14 p;15 p;16 a;17 l;18 l;"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(text[0:19]):\n",
    "    print(i,t,end=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecb0d3d8-2d9f-4daa-877c-910423c9f288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.start_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26eafd0f-24ee-43a5-8fcc-f05f4bd2dd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Span.as_doc>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.as_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "863497a7-1519-431b-adcf-1ffe8507f150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<environment.OriginAgent at 0x7fc5603b8b80>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c0ed589-045e-4fd3-ac03-6e1a18d55955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# 加载英文语言模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16c53a-1d45-4fd0-8fd8-e841a6fa6d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncat(text):\n",
    "    text_list = []\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b15f6c93-38ab-43c5-99b9-945c2560daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state,info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "034d4b53-60f4-44c3-b1ca-dce988626082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-------------------------------------\n",
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of the wise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of knowledge\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of advice\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of astuteness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of sageness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of enlightenment\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of expertise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.,list>   \n",
      "\n",
      "Words of <mask>\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-----------wisdom--------------\n",
      "[('the wise', 0.6), ('knowledge', 0.5), ('advice', 0.5), ('astuteness', 0.5), ('sageness', 0.5), ('enlightenment', 0.4), ('expertise', 0.4), ('intelligence', 0.4), ('shrewdness', 0.4), ('wise thinking', 0.3), ('experience', 0.3), ('insight', 0.3), ('judiciousness', 0.3), ('clear thinking', 0.2), ('good judgment', 0.2), ('reason', 0.2), ('caution', 0.2), ('comprehension', 0.2), ('foresight', 0.2), ('discernment', 0.2), ('acumen', 0.2), ('perspicacity', 0.1), ('sanity', 0.1), ('prudence', 0.1), ('savvy', 0.1), ('sagacity', 0.1), ('horse sense', 0.0), ('common sense', 0.0), ('poise', 0.0), ('discrimination', 0.0), ('penetration', 0.0), ('gumption', 0.0), ('balance', 0.0), ('judgment', 0.0), ('solidity', 0.0), ('practicality', 0.0), ('savoir faire', 0.0), ('sophistication', 0.0), ('information', 0.0), ('circumspection', 0.0), ('pansophy', 0.0), ('sapience', 0.0), ('stability', 0.0), ('understanding', 0.0), ('a sage', 0.0), ('erudition', 0.0), ('learning', 0.0), ('brains', 0.0)]\n",
      "-------------------------\n",
      "[('wisdom', 0.575), ('knowledge', 0.056), ('advice', 0.051), ('inspiration', 0.029), ('confidence', 0.023)]\n",
      "-------------------------\n",
      "[('said', 0.411), ('says', 0.121), ('was', 0.071), ('replied', 0.035), ('answered', 0.029)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "mask_text_doc = nlp(h0.text)\n",
    "mask_text = ''\n",
    "# 遍历每个句子并打印\n",
    "for sentence in mask_text_doc.sents:\n",
    "    # print(sentence.text)\n",
    "    if h0.target in sentence.text:\n",
    "        words = [h0.tarnlp = spacy.load(\"en_core_web_sm\")get,*[w for w,score in h0.substitutes[:5]],'<mask>']\n",
    "        sub_sentence_text = \".\".join([sentence.text.replace(h0.target,w,1) for w in words])\n",
    "        mask_text += sub_sentence_text\n",
    "    else:\n",
    "        mask_text += sentence.text\n",
    "if len(tokenizer(mask_text)['input_ids'])>10:\n",
    "    mask_text = ''\n",
    "    # 遍历每个句子并打印\n",
    "    for sentence in mask_text_doc.sents:\n",
    "        # print(sentence.text)\n",
    "        if h0.target in sentence.text:\n",
    "            parts = sentence.text.split(\",\")\n",
    "            mask_idx = [i for i,p in enumerate(parts) if (h0.target in p)][0]\n",
    "            words = [h0.target,*[w for w,score in h0.substitutes[:7]],'<mask>']\n",
    "            sub_sentence_text = \",\".join([parts[mask_idx].replace(h0.target,w,1) for w in words])\n",
    "            parts[mask_idx] = sub_sentence_text\n",
    "            mask_text += ' '.join(parts)\n",
    "        else:\n",
    "            mask_text += sentence.text\n",
    "\n",
    "print(h0.text)\n",
    "print(\"-------------------------------------\")\n",
    "print(mask_text)\n",
    "print(f\"-----------{h0.target}--------------\")\n",
    "print(h0.substitutes)\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(mask_text)])\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(solo_mask)])\n",
    "\n",
    "len(tokenizer(h0.text)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35dabde9-234b-419a-be2a-ba1db0a9971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-------------------------------------\n",
      "list>   \n",
      "\n",
      "Words of sageness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of wisdom\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of knowledge\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of astuteness\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of <mask>\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of advice\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of the wise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of expertise\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has..list>   \n",
      "\n",
      "Words of enlightenment\n",
      "\n",
      "\n",
      "   Julia Child doesn't have much use for fads and trends -- never\n",
      "has.\n",
      "-----------wisdom--------------\n",
      "[('the wise', 0.6), ('knowledge', 0.5), ('advice', 0.5), ('astuteness', 0.5), ('sageness', 0.5), ('enlightenment', 0.4), ('expertise', 0.4), ('intelligence', 0.4), ('shrewdness', 0.4), ('wise thinking', 0.3), ('experience', 0.3), ('insight', 0.3), ('judiciousness', 0.3), ('clear thinking', 0.2), ('good judgment', 0.2), ('reason', 0.2), ('caution', 0.2), ('comprehension', 0.2), ('foresight', 0.2), ('discernment', 0.2), ('acumen', 0.2), ('perspicacity', 0.1), ('sanity', 0.1), ('prudence', 0.1), ('savvy', 0.1), ('sagacity', 0.1), ('horse sense', 0.0), ('common sense', 0.0), ('poise', 0.0), ('discrimination', 0.0), ('penetration', 0.0), ('gumption', 0.0), ('balance', 0.0), ('judgment', 0.0), ('solidity', 0.0), ('practicality', 0.0), ('savoir faire', 0.0), ('sophistication', 0.0), ('information', 0.0), ('circumspection', 0.0), ('pansophy', 0.0), ('sapience', 0.0), ('stability', 0.0), ('understanding', 0.0), ('a sage', 0.0), ('erudition', 0.0), ('learning', 0.0), ('brains', 0.0)]\n",
      "-------------------------\n",
      "[('wisdom', 0.634), ('knowledge', 0.036), ('confidence', 0.028), ('inspiration', 0.02), ('patience', 0.016)]\n",
      "-------------------------\n",
      "[('said', 0.411), ('says', 0.121), ('was', 0.071), ('replied', 0.035), ('answered', 0.029)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = env.history[0]\n",
    "mask_text_doc = nlp(h0.text)\n",
    "mask_text = ''\n",
    "# 遍历每个句子并打印\n",
    "for sentence in mask_text_doc.sents:\n",
    "    # print(sentence.text)\n",
    "    if h0.target in sentence.text:\n",
    "        words = [h0.target,*[w for w,score in h0.substitutes[:7]],'<mask>']\n",
    "        random.shuffle(words)\n",
    "        sub_sentence_text = \".\".join([sentence.text.replace(h0.target,w,1) for w in words])\n",
    "        mask_text += sub_sentence_text\n",
    "    else:\n",
    "        mask_text += sentence.text\n",
    "if len(tokenizer(mask_text)['input_ids'])>512:\n",
    "    mask_text = ''\n",
    "    # 遍历每个句子并打印\n",
    "    for sentence in mask_text_doc.sents:\n",
    "        # print(sentence.text)\n",
    "        if h0.target in sentence.text:\n",
    "            parts = sentence.text.split(\",\")\n",
    "            mask_idx = [i for i,p in enumerate(parts) if (h0.target in p)][0]\n",
    "            words = [h0.target,*[w for w,score in h0.substitutes[:5]],'<mask>']\n",
    "            random.shuffle(words)\n",
    "            sub_sentence_text = \",\".join([parts[mask_idx].replace(h0.target,w,1) for w in words])\n",
    "            parts[mask_idx] = sub_sentence_text\n",
    "            mask_text += ' '.join(parts)\n",
    "        else:\n",
    "            mask_text += sentence.text\n",
    "\n",
    "print(h0.text)\n",
    "print(\"-------------------------------------\")\n",
    "print(mask_text)\n",
    "print(f\"-----------{h0.target}--------------\")\n",
    "print(h0.substitutes)\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(mask_text)])\n",
    "print(\"-------------------------\")\n",
    "print([(token['token_str'],round(token['score'],3)) for token in unmasker(solo_mask)])\n",
    "\n",
    "len(tokenizer(h0.text)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9151c40d-be9b-4906-92bb-b90334a05081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c4ad17a1-d1c4-4cb3-98cb-b8d9130fcee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['listless', '<mask>', 'lifeless', 'empty', 'dead', 'flat', 'deathly']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16ef9b55-9816-4030-9c30-5e09ba7162c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(mask_text)['input_ids'])>512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8cf6f4-2f01-4113-a3db-cf4aa1d6626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if there is target in the top masks :\n",
    "    that means LLM could predict well, the ambiagrous is less\n",
    "    \n",
    "    No action\n",
    "\n",
    "if top mask's score is high ,and in':\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "96753649-2f02-41e3-a3ab-aa6fcafec692",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 31 3.77\n",
      "276 77 3.58\n",
      "142 41 3.46\n",
      "404 106 3.81\n",
      "258 70 3.69\n",
      "129 36 3.58\n",
      "89 20 4.45\n",
      "358 96 3.73\n",
      "294 61 4.82\n",
      "313 81 3.86\n",
      "426 119 3.58\n",
      "213 41 5.2\n",
      "292 65 4.49\n",
      "152 29 5.24\n",
      "204 62 3.29\n",
      "251 59 4.25\n",
      "425 106 4.01\n",
      "266 65 4.09\n",
      "280 61 4.59\n",
      "321 67 4.79\n",
      "65 16 4.06\n",
      "375 84 4.46\n",
      "546 116 4.71\n",
      "194 45 4.31\n",
      "148 30 4.93\n",
      "183 42 4.36\n",
      "134 31 4.32\n",
      "207 48 4.31\n",
      "510 105 4.86\n",
      "297 58 5.12\n",
      "277 64 4.33\n",
      "242 53 4.57\n",
      "219 46 4.76\n",
      "243 59 4.12\n",
      "369 87 4.24\n",
      "420 76 5.53\n",
      "226 60 3.77\n",
      "296 73 4.05\n",
      "131 35 3.74\n",
      "111 26 4.27\n",
      "192 45 4.27\n",
      "164 42 3.9\n",
      "93 28 3.32\n",
      "446 106 4.21\n",
      "336 96 3.5\n",
      "420 76 5.53\n",
      "245 61 4.02\n",
      "258 70 3.69\n",
      "290 64 4.53\n",
      "154 34 4.53\n",
      "293 69 4.25\n",
      "197 52 3.79\n",
      "224 58 3.86\n",
      "195 44 4.43\n",
      "153 35 4.37\n",
      "112 27 4.15\n",
      "129 36 3.58\n",
      "386 93 4.15\n",
      "226 47 4.81\n",
      "270 69 3.91\n",
      "343 77 4.45\n",
      "422 113 3.73\n",
      "171 45 3.8\n",
      "540 134 4.03\n",
      "335 73 4.59\n",
      "259 63 4.11\n",
      "293 69 4.25\n",
      "103 27 3.81\n",
      "185 43 4.3\n",
      "153 35 4.37\n",
      "325 79 4.11\n",
      "277 65 4.26\n",
      "73 20 3.65\n",
      "433 109 3.97\n",
      "245 61 4.02\n",
      "354 74 4.78\n",
      "129 36 3.58\n",
      "376 98 3.84\n",
      "232 58 4.0\n",
      "595 132 4.51\n",
      "267 52 5.13\n",
      "475 96 4.95\n",
      "154 34 4.53\n",
      "201 50 4.02\n",
      "259 63 4.11\n",
      "83 23 3.61\n",
      "112 22 5.09\n",
      "187 41 4.56\n",
      "327 89 3.67\n",
      "143 41 3.49\n",
      "480 108 4.44\n",
      "380 94 4.04\n",
      "391 89 4.39\n",
      "166 36 4.61\n",
      "440 118 3.73\n",
      "160 41 3.9\n",
      "123 29 4.24\n",
      "141 30 4.7\n",
      "181 40 4.53\n",
      "392 107 3.66\n"
     ]
    }
   ],
   "source": [
    "l0s = 0\n",
    "l1s=0\n",
    "for i in  range(100):\n",
    "    state,info = test_env.reset()\n",
    "    h0 = test_env.history[0]\n",
    "    l1 = len(tokenizer(h0.text)['input_ids'])\n",
    "    l0 = len(h0.text)\n",
    "    l0s+=l0\n",
    "    l1s+=l1\n",
    "    print(l0,l1,round(l0/l1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "5233ed7c-4d59-46a6-bd24-9fe5ea2e2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2502\n",
      "2502\n",
      "2502\n",
      "2502\n",
      "2502\n"
     ]
    }
   ],
   "source": [
    "state,info = test_env.reset()\n",
    "h0 = test_env.history[0]\n",
    "solo_mask = h0.text.replace(h0.target,'<mask>',1)\n",
    "mask_text = ''\n",
    "for i,(word,score) in enumerate(h0.substitutes[:5]):\n",
    "    print(len(h0.text)*6)\n",
    "    if len(h0.text)*6<2100:\n",
    "        text = h0.text\n",
    "    else:\n",
    "        subtract_len = len(h0.text)-350\n",
    "        index = h0.text.index(h0.target)\n",
    "        post_sub_index = max(len(h0.text)-subtract_len,index+20)\n",
    "        if i%2==0:\n",
    "            pre_sub_index = min(0+subtract_len,index-20)\n",
    "            text = h0.text[pre_sub_index:]\n",
    "    if len(tokenizer(mask_text+text+solo_mask)['input_ids'])>512:\n",
    "        break\n",
    "    mask_text += text\n",
    "mask_text  += solo_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "82fe1ec7-6e32-4a45-a3af-dd1ac4c72bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.            compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, slowing only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.The problem was that I have trouble distinguishing between\\n                    compromise and capitulation, between symbols and substance. Shortly before noon,\\n                    I climbed the sandy path to Dream's End, rehearsing my apology, <mask> only to\\n                    pluck burrs from between my sandals and my feet. \\n                 Malaquez answered the door in blood-red pajamas and a black silk robe.\""
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "a34ff1be-25f3-450e-a345-2f3e42b1f199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2084"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "92cce71c-9380-4bfb-bf49-d7d497adef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "acef1d04-5afd-491b-8882-a39718b6a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "07d3f2ac-4b8b-4503-9e36-ef8473b70c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "400e399a-712b-4bc1-878c-67fa88ce211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_text = (text*12)[:-23]+ '<mask>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "cb1ea2f5-1ae4-4cdb-809d-85a6e1e6a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer(m_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "d36a8682-3794-460b-9f02-ee20fc081ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "6f7cd642-860d-4a5d-a5f6-c5af65e6e2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8441550135612488,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,'},\n",
       " {'score': 0.11659591645002365,\n",
       "  'token': 4,\n",
       "  'token_str': ',',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,,'},\n",
       " {'score': 0.008581217378377914,\n",
       "  'token': 27,\n",
       "  'token_str': '...',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,...'},\n",
       " {'score': 0.0016685021109879017,\n",
       "  'token': 122880,\n",
       "  'token_str': 'More',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,More'},\n",
       " {'score': 0.001654961844906211,\n",
       "  'token': 19659,\n",
       "  'token_str': 'As',\n",
       "  'sequence': 'reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,Also spurring the move reudToy, a pillow bearing the likeness of Sigmund Freud, is marketed as a $24.95 tool for do-it-yourself analysis.,As'}]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(m_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f43a9a71-cd1b-4ce5-be49-376b1d21795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2099.2"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512*4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7e0f3d33-64be-455f-b6d8-9e29feb2848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350.0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2100/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a4836d14-a1ea-4461-a11c-476147523d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.199420569773056"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l0s/l1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "11799913-5c24-48ab-91a4-68674483d867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1559"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a3cf02aa-f675-42ed-bab0-2c43ef855d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 387)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0.text.index(h0.target),len(h0.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6e6f55e4-1516-45d2-8fd6-6fb2aaa3c438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512 - len(h0.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6faa4248-9c78-45b0-92f2-d30372e16b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3b4cd41-1196-4772-a0e5-547df069f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3f9ee-abf3-49c9-93ea-239e125c6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.AutoModelForMaskedLM("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3658acbe-810b-4309-8b68-b44b1ee0792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbe8242b-0ea8-499c-a7f0-e1481ceec8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe3d9fe6-ff6e-465b-b5f5-8ca8c458e9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea3f62a5-5adf-4a81-87a3-26692355288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# forward pass\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b19e111f-be61-47dc-b9c9-5f1cc09850f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ 6.4861e+01,  1.6882e-02,  3.7656e+01,  ...,  2.1584e+01,\n",
       "           1.4380e+01,  1.8790e+01],\n",
       "         [ 2.7493e+01, -1.4091e+00,  6.4847e+01,  ...,  4.0234e+01,\n",
       "           1.6296e+01,  3.0925e+01],\n",
       "         [ 1.9604e+01, -1.2597e+00,  4.8981e+01,  ...,  3.5830e+01,\n",
       "           1.7145e+01,  2.7173e+01],\n",
       "         ...,\n",
       "         [ 2.2920e+01, -1.4657e+00,  5.1211e+01,  ...,  3.8495e+01,\n",
       "           1.6508e+01,  2.7687e+01],\n",
       "         [ 2.8598e+01, -1.2868e+00,  6.7706e+01,  ...,  4.4857e+01,\n",
       "           1.8004e+01,  3.5004e+01],\n",
       "         [ 4.4955e+01, -2.1554e-01,  4.9643e+01,  ...,  2.8253e+01,\n",
       "           1.6841e+01,  2.3610e+01]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5db2c37a-a78d-49d1-9a6b-f9f3ab131b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForMaskedLM"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e735b-0ede-4ec2-be41-1da2b2ffca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    predictions = outputs.logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "65983169-e35a-422e-8062-6df8d1f9398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 16:07:54.349083: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-17 16:07:54.349119: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import FillMaskPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a8f49495-ce6e-4f29-80ea-6a75bbb84950",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EmbeddingModel' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142/1315868084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFillMaskPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, image_processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m     ):\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_framework_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EmbeddingModel' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "mask_pipeline = FillMaskPipeline(model=env.model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d0b98934-a79b-4ddd-b4a9-5685596f5cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.07687385380268097,\n",
       "  'token': 34923,\n",
       "  'token_str': 'beautiful',\n",
       "  'sequence': 'this is a beautiful car'},\n",
       " {'score': 0.04615773260593414,\n",
       "  'token': 29681,\n",
       "  'token_str': 'sports',\n",
       "  'sequence': 'this is a sports car'},\n",
       " {'score': 0.03222648799419403,\n",
       "  'token': 54704,\n",
       "  'token_str': 'classic',\n",
       "  'sequence': 'this is a classic car'},\n",
       " {'score': 0.031460631638765335,\n",
       "  'token': 6782,\n",
       "  'token_str': 'great',\n",
       "  'sequence': 'this is a great car'},\n",
       " {'score': 0.030774081125855446,\n",
       "  'token': 26267,\n",
       "  'token_str': 'nice',\n",
       "  'sequence': 'this is a nice car'}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_pipeline(\"this is a <mask> car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db5c451f-564e-43aa-aeb2-6dfaa73e9c45",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaModel(\n",
       "  (embeddings): XLMRobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): XLMRobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): XLMRobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a481806c-5179-4fdf-aaec-d99a73a87260",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForMaskedLM(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): XLMRobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=250002, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ace047-ea17-4956-9370-fec2002d8018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
